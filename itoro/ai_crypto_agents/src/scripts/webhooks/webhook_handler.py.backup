"""
Webhook handler for Solana wallet notifications
Processes incoming webhook notifications from Helius and updates token data
"""

# Auto-reset handled by deploy/app.py - no need to duplicate here
import json
import logging
import time
import requests
import threading
import sqlite3
import pandas as pd
import base64
from typing import Dict, Any, List, Optional, Set
from flask import Flask, request, jsonify
from threading import Thread
from datetime import datetime, timedelta
import traceback
import hashlib
import queue
from concurrent.futures import ThreadPoolExecutor
from contextlib import contextmanager

# Import configuration
from src.config import (
    WEBHOOK_MODE,
    WEBHOOK_HOST,
    WEBHOOK_PORT,
    WEBHOOK_BASE_URL,
    WEBHOOK_HEALTH_CHECK_INTERVAL,
    WEBHOOK_ACTIVE_AGENTS,
    WEBHOOK_MIN_TOKEN_VALUE_USD,
    PAPER_TRADING_RESET_ON_START,
    WEBHOOK_RETRY_ATTEMPTS,
    WEBHOOK_DEBUG_MODE,
    WEBHOOK_LOG_LEVEL,
    WEBHOOK_TYPES,
    WEBHOOK_ENHANCED_MODE,
    PAPER_TRADING_ENABLED,
    PAPER_TRADING_RESET_ON_START,
    SOL_ADDRESS,
    USDC_ADDRESS,
    MAX_TOTAL_ALLOCATION_PERCENT,
    MAX_CONCURRENT_POSITIONS,
    MAX_SINGLE_POSITION_PERCENT,
    SOL_TARGET_PERCENT,
    USDC_TARGET_PERCENT
)

from src.scripts.webhooks.webhook_config import (
    HELIUS_API_KEY, 
    KNOWN_TOKENS, 
    WALLETS_TO_TRACK,
    is_personal_wallet, 
    get_personal_wallet_address,
    setup_personal_wallet_monitoring
)

# Import paper trading functionality
try:
    from src.paper_trading import (
        init_paper_trading_db,
        reset_paper_trading,
        execute_paper_trade,
        print_portfolio_status as print_paper_trading_status,
        get_portfolio_value,
        get_paper_portfolio,
        get_token_balance
    )
    paper_trading_available = True
except ImportError as e:
    print(f"Paper trading module import failed: {e}")
    paper_trading_available = False
    def print_paper_trading_status(): pass
    def init_paper_trading_db(): pass
    def reset_paper_trading(): pass
    def execute_paper_trade(*args, **kwargs): return False
    def get_paper_portfolio(): return None
    def get_token_balance(token_mint): return 0.0

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Agent Context Manager for proper attribution
class AgentContext:
    """Thread-local storage for current executing agent"""
    def __init__(self):
        self._local = threading.local()
    
    def set_agent(self, agent_name: str):
        """Set the current executing agent"""
        self._local.agent_name = agent_name
    
    def get_agent(self) -> str:
        """Get the current executing agent"""
        return getattr(self._local, 'agent_name', 'unknown')
    
    def clear_agent(self):
        """Clear the current agent context"""
        if hasattr(self._local, 'agent_name'):
            delattr(self._local, 'agent_name')

# Global agent context
_agent_context = AgentContext()

@contextmanager
def agent_context(agent_name: str):
    """Context manager for setting agent attribution"""
    old_agent = _agent_context.get_agent()
    _agent_context.set_agent(agent_name)
    try:
        yield
    finally:
        if old_agent != 'unknown':
            _agent_context.set_agent(old_agent)
        else:
            _agent_context.clear_agent()

# Import real-time portfolio monitoring
try:
    import asyncio
    import websockets
    import os
    from src.config import DEFAULT_WALLET_ADDRESS
    from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
    
    # Get WebSocket endpoint from environment - FIXED VERSION
    WEBSOCKET_ENDPOINT = os.getenv('WEBSOCKET_ENDPOINT')
    QUICKNODE_WSS_ENDPOINT = os.getenv('QUICKNODE_WSS_ENDPOINT')

    # Check if either WebSocket endpoint is available
    if WEBSOCKET_ENDPOINT or QUICKNODE_WSS_ENDPOINT:
        realtime_monitoring_available = True
        if WEBSOCKET_ENDPOINT:
            logger.info(f"‚úÖ Real-time WebSocket monitoring available: {WEBSOCKET_ENDPOINT}")
        if QUICKNODE_WSS_ENDPOINT:
            logger.info(f"‚úÖ QuickNode WebSocket backup available: {QUICKNODE_WSS_ENDPOINT}")
    else:
        realtime_monitoring_available = False
        logger.warning("‚ö†Ô∏è No WebSocket endpoints found in environment")
        logger.warning("‚ö†Ô∏è Check WEBSOCKET_ENDPOINT and QUICKNODE_WSS_ENDPOINT variables")
except ImportError as e:
    realtime_monitoring_available = False
    logger.warning(f"‚ö†Ô∏è Real-time monitoring not available: {e}")
    def start_realtime_monitoring(): pass
    def stop_realtime_monitoring(): pass

# Initialize Flask app
app = Flask(__name__)

# Real-time portfolio monitoring variables
_realtime_monitoring_active = False
_realtime_monitoring_thread = None
_portfolio_tracker_instance = None

# Global event deduplication cache
_processed_events = {}
_EVENT_CACHE_TTL = 300  # 5 minutes TTL for event deduplication
_dedup_lock = threading.Lock()

# Import harvesting startup flag from config
from src.config import HARVESTING_STARTUP_DONE

# Real-time portfolio monitoring functions
def start_realtime_portfolio_monitoring():
    """Start real-time portfolio monitoring via WebSocket"""
    global _realtime_monitoring_active, _realtime_monitoring_thread, _portfolio_tracker_instance
    
    if not realtime_monitoring_available:
        logger.warning("‚ö†Ô∏è Real-time monitoring not available")
        return False
    
    if _realtime_monitoring_active:
        logger.info("üîÑ Real-time monitoring already active")
        return True
    
    try:
        logger.info("üöÄ Starting real-time portfolio monitoring...")
        
        # Initialize portfolio tracker with error handling
        try:
            _portfolio_tracker_instance = get_portfolio_tracker()
            if _portfolio_tracker_instance is None:
                logger.error("‚ùå Failed to get portfolio tracker instance")
                return False
            logger.info("‚úÖ Portfolio tracker initialized successfully")
        except Exception as e:
            logger.error(f"‚ùå Error initializing portfolio tracker: {e}")
            return False
        
        # CRITICAL FIX: Initialize all agents during startup
        try:
            logger.info("üöÄ Initializing all trading agents for real-time monitoring...")
            success = initialize_all_agents()
            if success:
                logger.info("‚úÖ All trading agents initialized successfully")
            else:
                logger.warning("‚ö†Ô∏è Some agents failed to initialize - monitoring will continue with available agents")
        except Exception as e:
            logger.error(f"‚ùå Error initializing agents: {e}")
            # Continue with monitoring - agents can be initialized later
        
        # Start monitoring in background thread
        _realtime_monitoring_thread = threading.Thread(
            target=_run_realtime_monitoring_loop,
            daemon=True
        )
        _realtime_monitoring_thread.start()
        
        _realtime_monitoring_active = True
        logger.info("‚úÖ Real-time portfolio monitoring started successfully")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Failed to start real-time monitoring: {e}")
        return False

def stop_realtime_portfolio_monitoring():
    """Stop real-time portfolio monitoring"""
    global _realtime_monitoring_active, _realtime_monitoring_thread
    
    if not _realtime_monitoring_active:
        return
    
    try:
        logger.info("üõë Stopping real-time portfolio monitoring...")
        _realtime_monitoring_active = False
        
        if _realtime_monitoring_thread and _realtime_monitoring_thread.is_alive():
            _realtime_monitoring_thread.join(timeout=5)
        
        logger.info("‚úÖ Real-time portfolio monitoring stopped")
        
    except Exception as e:
        logger.error(f"‚ùå Error stopping real-time monitoring: {e}")

def _run_realtime_monitoring_loop():
    """Background thread for real-time portfolio monitoring via WebSocket"""
    global _realtime_monitoring_active, _portfolio_tracker_instance
    
    try:
        logger.info("üîç Real-time WebSocket monitoring loop started")
        
        # Try WebSocket first, fallback to polling if it fails
        websocket_success = _run_websocket_monitoring()
        
        if not websocket_success:
            logger.warning("‚ö†Ô∏è WebSocket failed, falling back to 10-second polling")
            _run_polling_fallback()
                
    except Exception as e:
        logger.error(f"‚ùå Fatal error in monitoring loop: {e}")
        # Fallback to polling on any error
        _run_polling_fallback()
    finally:
        logger.info("üîç Real-time monitoring loop stopped")

def _run_websocket_monitoring():
    """Real-time WebSocket monitoring for instant portfolio changes"""
    try:
        logger.info("üöÄ Starting WebSocket monitoring...")
        
        # Create event loop for this thread
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Try primary endpoint first (Helius)
        if WEBSOCKET_ENDPOINT:
            logger.info(f"üîå Attempting connection to primary endpoint: {WEBSOCKET_ENDPOINT}")
            try:
                loop.run_until_complete(_websocket_monitor(WEBSOCKET_ENDPOINT, "Helius"))
                return True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Primary WebSocket endpoint failed: {e}")
        
        # Try backup endpoint (QuickNode)
        backup_endpoint = os.getenv('QUICKNODE_WSS_ENDPOINT')
        if backup_endpoint:
            logger.info(f"üîå Attempting connection to backup endpoint: {backup_endpoint}")
            try:
                loop.run_until_complete(_websocket_monitor(backup_endpoint, "QuickNode"))
                return True
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Backup WebSocket endpoint failed: {e}")
        
        logger.error("‚ùå Both WebSocket endpoints failed")
        return False
        
    except Exception as e:
        logger.error(f"‚ùå WebSocket monitoring failed: {e}")
        return False

async def _websocket_monitor(endpoint_url, endpoint_name):
    """WebSocket monitoring coroutine for instant portfolio updates"""
    try:
        logger.info(f"üîå Connecting to {endpoint_name} WebSocket: {endpoint_url}")
        async with websockets.connect(endpoint_url) as websocket:
            logger.info(f"‚úÖ WebSocket connected successfully to {endpoint_name}")
            
            # Subscribe to account notifications for ALL tracked wallets
            tracked_wallets = get_current_wallets_to_track()
            logger.info(f"üì° Subscribing to {len(tracked_wallets)} tracked wallets via WebSocket")
            
            # Subscribe to each tracked wallet
            for i, wallet in enumerate(tracked_wallets):
                subscribe_msg = {
                    "jsonrpc": "2.0",
                    "id": i + 1,  # Unique ID for each subscription
                    "method": "accountSubscribe",
                    "params": [
                        wallet,
                        {"encoding": "jsonParsed", "commitment": "confirmed"}
                    ]
                }
                
                await websocket.send(json.dumps(subscribe_msg))
                response = await websocket.recv()
                logger.info(f"üì° WebSocket subscription {i+1}/{len(tracked_wallets)} for {wallet[:8]}...: {response}")
            
            # Monitor for account changes
            while _realtime_monitoring_active:
                try:
                    message = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                    data = json.loads(message)
                    
                    if 'params' in data and 'result' in data['params']:
                        logger.info("‚ö° Account change detected via WebSocket!")
                        
                        # Take immediate snapshot and trigger agents (but don't display to user)
                        if _portfolio_tracker_instance:
                            _portfolio_tracker_instance._take_snapshot()
                            current_snapshot = _portfolio_tracker_instance.current_snapshot
                            if current_snapshot:
                                _trigger_portfolio_change_webhook(current_snapshot)
                                logger.info("üöÄ Portfolio change webhook triggered instantly!")
                                # Don't display portfolio status here - let main.py handle 5-min updates
                    
                except asyncio.TimeoutError:
                    # No message received, continue monitoring
                    continue
                except Exception as e:
                    logger.error(f"‚ùå WebSocket message error: {e}")
                    break
                    
    except Exception as e:
        logger.error(f"‚ùå WebSocket connection error to {endpoint_name}: {e}")
        raise

def _run_polling_fallback():
    """Fallback to 10-second polling if WebSocket fails"""
    logger.info("üì° Using polling fallback (10-second intervals)")
    
    while _realtime_monitoring_active:
        try:
            if _portfolio_tracker_instance:
                _portfolio_tracker_instance._take_snapshot()
                
                # Check for significant changes
                current_snapshot = _portfolio_tracker_instance.current_snapshot
                if current_snapshot:
                    # Trigger portfolio change webhook for agents (but don't display to user)
                    _trigger_portfolio_change_webhook(current_snapshot)
                    # Don't display portfolio status here - let main.py handle 5-min updates
            
            # Sleep for 10 seconds before next check
            time.sleep(10)
            
        except Exception as e:
            logger.error(f"‚ùå Error in polling fallback: {e}")
            time.sleep(5)  # Shorter sleep on error

def _trigger_portfolio_change_webhook(snapshot):
    """Trigger portfolio change detection and agent activation"""
    try:
        # Get portfolio data
        portfolio_data = {
            'type': 'portfolio_change_detected',
            'timestamp': time.time(),
            'portfolio_data': {
                'total_value': snapshot.total_value_usd,
                'usdc_balance': snapshot.usdc_balance,
                'sol_balance': snapshot.sol_balance,
                'sol_value_usd': snapshot.sol_value_usd,
                'staked_sol_balance': getattr(snapshot, 'staked_sol_balance', 0.0),
                'staked_sol_value_usd': getattr(snapshot, 'staked_sol_value_usd', 0.0),
                'positions_value_usd': snapshot.positions_value_usd,
                'change_detected': True
            }
        }
        
        logger.info("üìä Portfolio change detected - triggering agents directly")
        
        # Trigger agents directly instead of sending webhook to avoid circular reference
        try:
            # Check for critical allocation issues that require immediate action
            _check_critical_allocation_issues(snapshot)
            
            # Trigger harvesting agent for portfolio changes
            if WEBHOOK_ACTIVE_AGENTS.get('harvesting', False) and harvesting_agent:
                logger.info("üåæ Triggering harvesting agent for portfolio change")
                try:
                    harvesting_agent.handle_webhook_trigger({
                        'type': 'portfolio_change',
                        'change_type': 'allocation_change',
                        'timestamp': time.time(),
                        'portfolio_data': portfolio_data['portfolio_data']
                    })
                    logger.info("‚úÖ Harvesting agent triggered successfully")
                except Exception as e:
                    logger.error(f"‚ùå Error triggering harvesting agent: {e}")
            
            # Trigger risk agent for portfolio changes
            if WEBHOOK_ACTIVE_AGENTS.get('risk', False) and risk_agent:
                if hasattr(risk_agent, 'is_ready') and hasattr(risk_agent, '_in_cooldown'):
                    if not risk_agent.is_ready():
                        logger.info('‚è≥ RiskAgent startup grace - skip')
                    elif risk_agent._in_cooldown():
                        logger.info('üïí RiskAgent cooldown - skip')
                    else:
                        logger.info("‚öñÔ∏è Triggering risk agent for portfolio change")
                        try:
                            risk_agent.handle_webhook_trigger({
                                'type': 'portfolio_change',
                                'change_type': 'allocation_change',
                                'timestamp': time.time(),
                                'portfolio_data': portfolio_data['portfolio_data']
                            })
                            logger.info("‚úÖ Risk agent triggered successfully")
                        except Exception as e:
                            logger.error(f"‚ùå Error triggering risk agent: {e}")
                else:
                    logger.info("‚öñÔ∏è Triggering risk agent for portfolio change")
                    try:
                        risk_agent.handle_webhook_trigger({
                            'type': 'portfolio_change',
                            'change_type': 'allocation_change',
                            'timestamp': time.time(),
                            'portfolio_data': portfolio_data['portfolio_data']
                        })
                        logger.info("‚úÖ Risk agent triggered successfully")
                    except Exception as e:
                        logger.error(f"‚ùå Error triggering risk agent: {e}")
                    
        except Exception as e:
            logger.error(f"‚ùå Error triggering agents: {e}")
            
    except Exception as e:
        logger.error(f"‚ùå Error triggering portfolio change webhook: {e}")
def _check_critical_allocation_issues(snapshot):
    """Check for critical allocation issues that require immediate agent action"""
    try:
        # Check USDC emergency threshold
        if snapshot.usdc_balance < 1.0:  # Less than $1 USDC
            logger.warning("üö® CRITICAL: USDC balance critically low!")
            if harvesting_agent:
                harvesting_agent.handle_webhook_trigger({
                    'type': 'emergency_allocation',
                    'portfolio_data': {
                        'usdc_balance': snapshot.usdc_balance,
                        'total_value': snapshot.total_value_usd
                    }
                })
        
        # Check SOL minimum threshold
        if snapshot.sol_value_usd < 5.0:  # Less than $5 SOL
            logger.warning("üö® CRITICAL: SOL balance critically low!")
            if harvesting_agent:
                harvesting_agent.handle_webhook_trigger({
                    'type': 'emergency_allocation',
                    'portfolio_data': {
                        'sol_balance': snapshot.sol_value_usd,
                        'total_value': snapshot.total_value_usd
                    }
                })
                
    except Exception as e:
        logger.error(f"‚ùå Error checking critical allocation issues: {e}")

# CRITICAL FIX: Add global execution lock to prevent race conditions
_execution_lock = threading.Lock()
_execution_in_progress = False
_last_execution_time = 0
_MIN_EXECUTION_INTERVAL = 2.0  # Minimum 2 seconds between executions

# CRITICAL FIX: Webhook queue system to replace 503 busy responses
_webhook_queue = queue.Queue(maxsize=20)  # Bounded queue to prevent memory issues
_webhook_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="WebhookProcessor")
_webhook_processor_running = True
_processed_signatures = set()  # Deduplicate by transaction signature

def _webhook_queue_processor():
    """Background thread that processes webhooks from the queue"""
    global _webhook_processor_running, _webhook_queue, _processed_signatures
    
    logger.info("üöÄ Webhook queue processor started")
    
    while _webhook_processor_running:
        try:
            # Get webhook data from queue (blocks until available)
            webhook_data = _webhook_queue.get(timeout=1.0)
            
            if webhook_data is None:  # Shutdown signal
                break
            
            # Extract signature for deduplication
            signature = webhook_data.get('signature', 'unknown')
            
            # Check for duplicate
            if signature != 'unknown' and signature in _processed_signatures:
                logger.debug(f"üö´ Skipping duplicate webhook with signature {signature[:16]}...")
                _webhook_queue.task_done()
                continue
            
            # Add to processed set
            if signature != 'unknown':
                _processed_signatures.add(signature)
                # Keep set size manageable
                if len(_processed_signatures) > 1000:
                    # Remove oldest 200 signatures
                    for _ in range(200):
                        _processed_signatures.pop()
            
            # Process the webhook
            try:
                logger.info(f"üì• Processing queued webhook with signature {signature[:16]}...")
                _process_webhook_data(webhook_data['data'])
                logger.info(f"‚úÖ Queued webhook {signature[:16]} processed successfully")
            except Exception as e:
                logger.error(f"‚ùå Error processing queued webhook {signature[:16]}: {e}")
            
            _webhook_queue.task_done()
            
        except queue.Empty:
            continue  # No webhook data available, keep waiting
        except Exception as e:
            logger.error(f"‚ùå Error in webhook queue processor: {e}")
            time.sleep(1)  # Brief pause on error
    
    logger.info("üõë Webhook queue processor stopped")

# Start the webhook queue processor
_webhook_processor_thread = threading.Thread(target=_webhook_queue_processor, daemon=True)
_webhook_processor_thread.start()

# CRITICAL FIX: Add transaction confirmation tracking
_confirmed_transactions = {}
_TRANSACTION_CONFIRMATION_TTL = 600  # 10 minutes TTL for confirmed transactions

# ENHANCED: Request queuing system
from collections import deque
from dataclasses import dataclass
from enum import Enum

class RequestPriority(Enum):
    HIGH = 1      # Tracked wallet transactions
    NORMAL = 2    # Regular transactions
    LOW = 3       # Portfolio updates, health checks

@dataclass
class QueuedRequest:
    request_id: str
    priority: RequestPriority
    data: dict
    timestamp: float
    retry_count: int = 0
    max_retries: int = 3
    
    def __lt__(self, other):
        """Enable priority queue comparison - lower priority value = higher priority"""
        if self.priority.value != other.priority.value:
            return self.priority.value < other.priority.value
        # If same priority, use timestamp (FIFO)
        return self.timestamp < other.timestamp
    
    def __eq__(self, other):
        """Enable equality comparison"""
        return (self.request_id == other.request_id and 
                self.priority == other.priority and 
                self.timestamp == other.timestamp)

# Request queue with priority support
_request_queue = queue.PriorityQueue()
_queue_processor_thread = None
_queue_processing = False
_queue_stats = {
    'total_queued': 0,
    'total_processed': 0,
    'total_rejected': 0,
    'total_retries': 0,
    'current_queue_size': 0
}

# Queue configuration - INCREASED for high-frequency trading
_MAX_QUEUE_SIZE = 500  # Increased from 100 to handle high-frequency wallets
_QUEUE_PROCESSING_TIMEOUT = 30  # seconds
_REQUEST_TIMEOUT = 10  # seconds

def _determine_request_priority(request_data: dict) -> RequestPriority:
    """Determine the priority of a webhook request based on its content"""
    try:
        # Check if this is a tracked wallet transaction
        if 'events' in request_data:
            for event in request_data['events']:
                if 'transaction' in event and 'message' in event['transaction']:
                    account_keys = event['transaction']['message'].get('accountKeys', [])
                    tracked_wallets = get_current_wallets_to_track()
                    
                    # Check if any tracked wallet is involved
                    for account in account_keys:
                        if account in tracked_wallets:
                            return RequestPriority.HIGH
        
        # Check if this is a portfolio change request
        if 'type' in request_data and 'portfolio_change' in request_data.get('type', ''):
            return RequestPriority.LOW
            
        # Default to normal priority
        return RequestPriority.NORMAL
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error determining request priority: {e}")
        return RequestPriority.NORMAL

def _process_queued_request(queued_request: QueuedRequest) -> bool:
    """Process a single queued request"""
    global _queue_stats
    
    try:
        logger.info(f"üîÑ Processing queued request {queued_request.request_id} (priority: {queued_request.priority.name})")
        
        # Check if request is too old
        if time.time() - queued_request.timestamp > _REQUEST_TIMEOUT:
            logger.warning(f"‚è∞ Request {queued_request.request_id} timed out")
            _queue_stats['total_rejected'] += 1
            return False
        
        # Process the request using the existing webhook logic
        result = _process_webhook_data(queued_request.data)
        
        if result:
            _queue_stats['total_processed'] += 1
            logger.info(f"‚úÖ Successfully processed queued request {queued_request.request_id}")
            return True
        else:
            # Retry logic
            if queued_request.retry_count < queued_request.max_retries:
                queued_request.retry_count += 1
                _queue_stats['total_retries'] += 1
                logger.warning(f"üîÑ Retrying request {queued_request.request_id} (attempt {queued_request.retry_count})")
                
                # Re-queue with higher priority for retries
                retry_priority = RequestPriority.HIGH if queued_request.priority == RequestPriority.NORMAL else queued_request.priority
                _queue_request(queued_request.data, retry_priority, queued_request.request_id, queued_request.retry_count)
                return False
            else:
                logger.error(f"‚ùå Failed to process request {queued_request.request_id} after {queued_request.max_retries} retries")
                _queue_stats['total_rejected'] += 1
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Error processing queued request {queued_request.request_id}: {e}")
        _queue_stats['total_rejected'] += 1
        return False

def _queue_processor():
    """Background thread that processes queued requests"""
    global _queue_processing, _queue_stats, _queue_processor_thread
    
    try:
        logger.info("üöÄ Starting request queue processor")
        _queue_processing = True
        logger.info(f"‚úÖ Queue processing flag set to: {_queue_processing}")
        
        while _queue_processing:
            try:
                # Get next request from queue with timeout
                try:
                    logger.debug("üîÑ Waiting for request from queue...")
                    # PriorityQueue returns (priority_value, item) tuple
                    priority_value, queued_request = _request_queue.get(timeout=1.0)
                    _queue_stats['current_queue_size'] = _request_queue.qsize()
                    logger.info(f"üì• Got request from queue: {queued_request.request_id}")
                    
                    # Process the request
                    _process_queued_request(queued_request)
                    
                    # Mark task as done
                    _request_queue.task_done()
                    logger.info(f"‚úÖ Completed processing request: {queued_request.request_id}")
                    
                except queue.Empty:
                    # No requests in queue, continue
                    logger.debug("‚è≥ No requests in queue, waiting...")
                    continue
                    
            except Exception as e:
                logger.error(f"‚ùå Error in queue processor: {e}")
                logger.error(f"Error type: {type(e).__name__}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
                _queue_stats['total_rejected'] += 1
                time.sleep(1)  # Brief pause before continuing
        
        logger.info("üõë Request queue processor stopped")
        
    except Exception as e:
        logger.error(f"‚ùå CRITICAL ERROR in queue processor startup: {e}")
        logger.error(f"Error type: {type(e).__name__}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        _queue_processing = False

def _start_queue_processor():
    """Start the background queue processor thread"""
    global _queue_processor_thread, _queue_processing
    
    try:
        if _queue_processor_thread is None or not _queue_processor_thread.is_alive():
            logger.info("üöÄ Creating queue processor thread...")
            _queue_processing = True
            # Make it non-daemon so it doesn't exit when main thread finishes
            _queue_processor_thread = threading.Thread(target=_queue_processor, daemon=False, name="QueueProcessor")
            _queue_processor_thread.start()
            
            # Wait a moment to ensure it starts
            import time
            time.sleep(1.0)
            
            if _queue_processor_thread.is_alive():
                logger.info("‚úÖ Request queue processor started successfully")
                logger.info(f"‚úÖ Thread ID: {_queue_processor_thread.ident}")
            else:
                logger.error("‚ùå Queue processor thread failed to start")
                
    except Exception as e:
        logger.error(f"‚ùå Error starting queue processor: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")

def _stop_queue_processor():
    """Stop the background queue processor thread"""
    global _queue_processing, _queue_processor_thread
    
    _queue_processing = False
    if _queue_processor_thread and _queue_processor_thread.is_alive():
        _queue_processor_thread.join(timeout=5)
        logger.info("üõë Request queue processor stopped")

def _queue_request(request_data: dict, priority: RequestPriority = None, request_id: str = None, retry_count: int = 0) -> str:
    """Queue a webhook request for processing"""
    global _queue_stats
    
    try:
        # Generate request ID if not provided
        if not request_id:
            request_id = hashlib.md5(f"{time.time()}_{json.dumps(request_data, sort_keys=True)}".encode()).hexdigest()[:12]
        
        # Determine priority if not provided
        if priority is None:
            priority = _determine_request_priority(request_data)
        
        # Check queue size
        if _request_queue.qsize() >= _MAX_QUEUE_SIZE:
            logger.warning(f"‚ö†Ô∏è Request queue full ({_MAX_QUEUE_SIZE}), rejecting request {request_id}")
            _queue_stats['total_rejected'] += 1
            return None
        
        # Create queued request
        queued_request = QueuedRequest(
            request_id=request_id,
            priority=priority,
            data=request_data,
            timestamp=time.time(),
            retry_count=retry_count
        )
        
        # Add to queue with priority
        _request_queue.put((priority.value, queued_request))
        _queue_stats['total_queued'] += 1
        _queue_stats['current_queue_size'] = _request_queue.qsize()
        
        logger.info(f"üì• Queued request {request_id} with priority {priority.name} (queue size: {_queue_stats['current_queue_size']})")
        return request_id
        
    except Exception as e:
        logger.error(f"‚ùå Error queuing request: {e}")
        logger.error(f"Request data: {request_data}")
        _queue_stats['total_rejected'] += 1
        # Don't crash the webhook handler - return None to indicate failure
        return None

def _process_webhook_data(request_data: dict) -> bool:
    """Process webhook data (extracted from main webhook handler)"""
    try:
        # Create Flask application context for background processing
        with app.app_context():
            # This is the core webhook processing logic extracted from handle_webhook()
            # We'll implement this by calling the existing processing functions
            
            # Handle Helius webhook events (raw blockchain data)
            if 'events' in request_data:
                logger.info(f"üì• Processing Helius webhook with {len(request_data['events'])} events")
                return _process_webhook_events(request_data['events'])
            
            # Handle portfolio change webhooks
            elif 'type' in request_data and 'portfolio_change' in request_data.get('type', ''):
                logger.info("üìä Processing portfolio change webhook")
                return _process_portfolio_change(request_data)
            
            # Handle raw blockchain transaction data (direct from Helius)
            elif isinstance(request_data, list) and len(request_data) > 0:
                logger.info(f"üì• Processing raw blockchain events: {len(request_data)} events")
                return _process_webhook_events(request_data)
            
            # Handle single blockchain event
            elif 'transaction' in request_data and 'meta' in request_data:
                logger.info("üì• Processing single blockchain event")
                return _process_webhook_events([request_data])
            
            else:
                logger.warning(f"‚ö†Ô∏è Unknown request type: {type(request_data)} - {list(request_data.keys()) if isinstance(request_data, dict) else 'Not a dict'}")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Error processing webhook data: {e}")
        logger.error(f"Request data type: {type(request_data)}")
        logger.error(f"Request data keys: {list(request_data.keys()) if isinstance(request_data, dict) else 'Not a dict'}")
        return False

def _process_portfolio_change(request_data: dict) -> bool:
    """Process portfolio change webhook data"""
    try:
        logger.info("üìä Processing portfolio change webhook")
        
        # Extract portfolio change information - handle both 'type' and 'change_type' fields
        change_type = request_data.get('change_type', request_data.get('type', 'unknown'))
        wallet_address = request_data.get('wallet_address', 'unknown')
        token_changes = request_data.get('token_changes', {})
        
        logger.info(f"üìä Portfolio change: {change_type} for wallet {wallet_address[:8]}...")
        logger.info(f"üìä Token changes: {len(token_changes)} tokens affected")
        
        # Process the portfolio change
        # This would typically trigger rebalancing or other portfolio management actions
        if change_type == 'rebalancing_needed':
            logger.info("‚öñÔ∏è Rebalancing needed - triggering rebalancing agent")
            # Trigger rebalancing agent if available
            try:
                from src.agents.rebalancing import trigger_rebalancing_agent
                trigger_rebalancing_agent(wallet_address, token_changes)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to trigger rebalancing agent: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error processing portfolio change: {e}")
        return False

def _is_duplicate_event(event_data):
    """Check if this event has already been processed to prevent over-execution"""
    try:
        # CRITICAL FIX: Enhanced duplicate detection with execution lock
        global _execution_in_progress, _last_execution_time, _confirmed_transactions, _processed_events
        
        current_time = time.time()
        
        # Check if execution is already in progress
        if _execution_in_progress:
            logger.warning(f"üö´ EXECUTION IN PROGRESS - skipping to prevent race conditions")
            return True
        
        # Check minimum execution interval
        if current_time - _last_execution_time < _MIN_EXECUTION_INTERVAL:
            logger.warning(f"üö´ EXECUTION TOO SOON - {_MIN_EXECUTION_INTERVAL - (current_time - _last_execution_time):.1f}s remaining")
            return True
        
        # CRITICAL FIX: Check if transaction is already confirmed
        if 'signature' in event_data:
            signature = event_data.get('signature', '')
            if signature in _confirmed_transactions:
                last_confirmed = _confirmed_transactions[signature]
                if current_time - last_confirmed < _TRANSACTION_CONFIRMATION_TTL:
                    logger.warning(f"üö´ TRANSACTION ALREADY CONFIRMED: {signature[:8]}... - skipping to prevent over-execution")
                    return True
        
        # Create a unique hash for the event
        if 'signature' in event_data:
            event_hash = hashlib.md5(
                f"{event_data.get('signature', '')}_{event_data.get('tokenMint', '')}_{event_data.get('amount', '')}_{int(current_time/60)}".encode()
            ).hexdigest()
        else:
            event_hash = hashlib.md5(json.dumps(event_data, sort_keys=True).encode() + str(int(current_time/60)).encode()).hexdigest()

        with _dedup_lock:
            # Check if we've seen this event recently
            last_seen = _processed_events.get(event_hash)
            if last_seen is not None and current_time - last_seen < _EVENT_CACHE_TTL:
                logger.warning(f"üö´ DUPLICATE EVENT DETECTED: {event_hash[:8]}... - skipping to prevent over-execution")
                return True

            # Store this event as processed
            _processed_events[event_hash] = current_time

            # Clean up old events in-place (avoid rebinding)
            keys_to_delete = [k for k, v in _processed_events.items() if current_time - v >= _EVENT_CACHE_TTL]
            for k in keys_to_delete:
                _processed_events.pop(k, None)

            # Clean up old confirmed transactions in-place
            conf_keys_to_delete = [k for k, v in _confirmed_transactions.items() if current_time - v >= _TRANSACTION_CONFIRMATION_TTL]
            for k in conf_keys_to_delete:
                _confirmed_transactions.pop(k, None)

        return False
        
    except Exception as e:
        logger.error(f"Error in event deduplication: {e}")
        return False  # Allow processing if deduplication fails

def _mark_transaction_confirmed(signature: str):
    """Mark a transaction as confirmed to prevent re-execution"""
    global _confirmed_transactions
    _confirmed_transactions[signature] = time.time()
    logger.info(f"‚úÖ Transaction {signature[:8]}... marked as confirmed")

# Verify all routes are registered
def verify_flask_routes():
    """Verify that all Flask routes are properly registered"""
    logger.info("üîç Verifying Flask routes...")
    routes = []
    for rule in app.url_map.iter_rules():
        routes.append(f"{rule.rule} [{', '.join(rule.methods)}]")
    
    logger.info(f"üìã Registered routes ({len(routes)} total):")
    for route in routes:
        logger.info(f"  ‚Ä¢ {route}")
    
    # Check for critical routes
    critical_routes = ['/', '/webhook', '/test', '/test-status', '/test-webhook', '/test-live', '/test-solana']
    missing_routes = []
    for route in critical_routes:
        if not any(route in r for r in routes):
            missing_routes.append(route)
    
    if missing_routes:
        logger.error(f"‚ùå Missing critical routes: {missing_routes}")
        return False
    else:
        logger.info("‚úÖ All critical routes are registered")
        return True

# Use the webhook URL from config (already properly set for Render vs local)
webhook_url = f"{WEBHOOK_BASE_URL}/webhook"
logger.info(f"üåê Webhook URL configured: {webhook_url}")

# Global variables for tracking changes
wallet_changes = {}  # Track changes per wallet
last_processed_signature = None  # Track last processed transaction

# Solana constants
SPL_TOKEN_PROGRAM = "TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA"
SOL_MINT = "So11111111111111111111111111111111111111112"

def is_spl_token_transfer(instruction: Dict[str, Any], account_keys: List[str]) -> bool:
    """Check if instruction is an SPL Token transfer"""
    try:
        program_id = account_keys[instruction['programIdIndex']]
        if program_id != SPL_TOKEN_PROGRAM:
            return False
        
        # Decode instruction data with proper padding
        data_str = instruction['data']
        
        # Add padding if needed
        padding_needed = len(data_str) % 4
        if padding_needed:
            data_str += '=' * (4 - padding_needed)
        
        try:
            data = base64.b64decode(data_str)
            # 3: Transfer, 12: TransferChecked
            return data[0] in (3, 12)
        except Exception as decode_error:
            # Try alternative decoding methods
            logger.debug(f"Base64 decode failed, trying alternative methods: {decode_error}")
            
            # Method 1: Try without padding
            try:
                data = base64.b64decode(data_str, validate=False)
                return data[0] in (3, 12)
            except:
                pass
            
            # Method 2: Try with URL-safe base64
            try:
                data = base64.urlsafe_b64decode(data_str + '=' * (4 - len(data_str) % 4))
                return data[0] in (3, 12)
            except:
                pass
            
            # Method 3: Check if it's already decoded
            if len(data_str) > 0:
                try:
                    # If it's already bytes or can be converted to int
                    if isinstance(data_str, bytes):
                        return data_str[0] in (3, 12)
                    elif data_str.isdigit():
                        return int(data_str) in (3, 12)
                except:
                    pass
            
            # downgrade to debug to reduce noise
            logger.debug(f"Could not decode instruction data: {data_str[:20]}...")
            return False
            
    except Exception as e:
        logger.error(f"Error checking SPL token transfer: {e}")
        return False

def get_token_account_owner(token_account_index: int, pre_balances: List[Dict], post_balances: List[Dict]) -> tuple:
    """Get owner and mint for a token account"""
    try:
        for balance in pre_balances + post_balances:
            if balance.get('accountIndex') == token_account_index:
                return balance.get('owner'), balance.get('mint')
        return None, None
    except Exception as e:
        logger.error(f"Error getting token account owner: {e}")
        return None, None

def get_token_balance(account_index: int, mint: str, balances: List[Dict]) -> float:
    """Get token balance for an account and mint"""
    try:
        for balance in balances:
            if (balance.get('accountIndex') == account_index and 
                balance.get('mint') == mint):
                return float(balance.get('uiTokenAmount', {}).get('uiAmount', 0))
        return 0.0
    except Exception as e:
        logger.error(f"Error getting token balance: {e}")
        return 0.0

def parse_solana_transaction(event: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Parse Solana transaction to extract token transfers"""
    try:
        tx = event.get('transaction', {})
        meta = event.get('meta', {})
        
        if not tx or not meta:
            return []
        
        account_keys = tx.get('message', {}).get('accountKeys', [])
        instructions = tx.get('message', {}).get('instructions', [])
        pre_token_balances = meta.get('preTokenBalances', [])
        post_token_balances = meta.get('postTokenBalances', [])
        signature = tx.get('signatures', [''])[0]
        slot = event.get('slot')
        block_time = event.get('blockTime')
        
        logger.info(f"üîç Parsing transaction with {len(instructions)} instructions")
        
        transfers = []
        
        for i, instruction in enumerate(instructions):
            # Debug: Log instruction data for analysis
            if i < 3:  # Only log first 3 instructions to avoid spam
                logger.info(f"  üîç Instruction {i+1}: program={account_keys[instruction.get('programIdIndex', 0)]}, data={instruction.get('data', 'N/A')[:30]}...")
            
            if is_spl_token_transfer(instruction, account_keys):
                logger.info(f"  üìä Found SPL token transfer instruction {i+1}")
                
                try:
                    # Get account indices
                    accounts = instruction.get('accounts', [])
                    if len(accounts) < 2:
                        continue
                    
                    src_idx, dst_idx = accounts[0], accounts[1]
                    
                    # Get source and destination owners and mints
                    src_owner, src_mint = get_token_account_owner(src_idx, pre_token_balances, post_token_balances)
                    dst_owner, dst_mint = get_token_account_owner(dst_idx, pre_token_balances, post_token_balances)
                    
                    if not all([src_owner, src_mint, dst_owner, dst_mint]):
                        logger.warning(f"    ‚ö†Ô∏è Missing owner or mint data for transfer")
                        continue
                    
                    # Calculate amount by comparing balances
                    src_pre = get_token_balance(src_idx, src_mint, pre_token_balances)
                    src_post = get_token_balance(src_idx, src_mint, post_token_balances)
                    amount = src_pre - src_post
                    
                    if amount <= 0:
                        logger.info(f"    ‚ö†Ô∏è Non-positive transfer amount: {amount}")
                        continue
                    
                    # Get decimals for proper formatting
                    decimals = 9  # Default for most tokens
                    for balance in pre_token_balances + post_token_balances:
                        if balance.get('mint') == src_mint:
                            decimals = balance.get('uiTokenAmount', {}).get('decimals', 9)
                            break
                    
                    transfer = {
                        "tokenMint": src_mint,
                        "fromUserAccount": src_owner,
                        "toUserAccount": dst_owner,
                        "amount": str(int(amount * (10 ** decimals))),  # Convert to raw amount
                        "decimals": decimals,
                        "signature": signature,
                        "slot": slot,
                        "blockTime": block_time
                    }
                    
                    logger.info(f"    ‚úÖ Parsed transfer: {src_owner[:8]}... -> {dst_owner[:8]}... ({amount:.4f} tokens)")
                    transfers.append(transfer)
                    
                except Exception as e:
                    logger.error(f"    ‚ùå Error parsing transfer instruction {i+1}: {e}")
                    continue
        
        logger.info(f"üìä Total transfers parsed: {len(transfers)}")
        
        # If no transfers found via instructions, try meta data analysis
        if len(transfers) == 0 and (pre_token_balances or post_token_balances):
            logger.info(f"  üîç No transfers found via instructions, analyzing meta data...")
            meta_transfers = parse_transfers_from_meta(pre_token_balances, post_token_balances, account_keys, signature, slot, block_time)
            transfers.extend(meta_transfers)
            logger.info(f"  üìä Additional transfers from meta: {len(meta_transfers)}")
        
        return transfers
        
    except Exception as e:
        logger.error(f"‚ùå Error parsing Solana transaction: {e}")
        return []

def parse_transfers_from_meta(pre_balances: List[Dict], post_balances: List[Dict], account_keys: List[str], signature: str, slot: int, block_time: int) -> List[Dict[str, Any]]:
    """Parse transfers by comparing pre and post token balances - FIXED VERSION"""
    try:
        transfers = []
        
        # Create lookup for pre and post balances by owner and mint
        pre_lookup = {}
        post_lookup = {}
        
        for balance in pre_balances:
            owner = balance.get('owner')
            mint = balance.get('mint')
            if owner and mint:
                key = (owner, mint)
            pre_lookup[key] = balance
        
        for balance in post_balances:
            owner = balance.get('owner')
            mint = balance.get('mint')
            if owner and mint:
                key = (owner, mint)
            post_lookup[key] = balance
        
        # Find all accounts with balance changes
        all_keys = set(pre_lookup.keys()) | set(post_lookup.keys())
        
        for owner, mint in all_keys:
            pre_balance = pre_lookup.get((owner, mint))
            post_balance = post_lookup.get((owner, mint))
            
            if pre_balance and post_balance:
                pre_amount = float(pre_balance.get('uiTokenAmount', {}).get('uiAmount', 0))
                post_amount = float(post_balance.get('uiTokenAmount', {}).get('uiAmount', 0))
                change = post_amount - pre_amount
                
                if abs(change) > 0.000001:  # Significant change
                    decimals = pre_balance.get('uiTokenAmount', {}).get('decimals', 9)
                    
                    if change > 0:  # Received tokens (BUY)
                        # Find sender via negative change on same mint
                        found_sender = False
                        for other_owner, other_mint in all_keys:
                            if other_mint == mint and other_owner != owner:
                                other_pre = pre_lookup.get((other_owner, other_mint))
                                other_post = post_lookup.get((other_owner, other_mint))
                                if other_pre and other_post:
                                    other_change = float(other_post.get('uiTokenAmount', {}).get('uiAmount', 0)) - float(other_pre.get('uiTokenAmount', {}).get('uiAmount', 0))
                                    if other_change < -0.000001:  # Sent tokens
                                        transfer = {
                                            "tokenMint": mint,
                                            "fromUserAccount": other_owner,
                                            "toUserAccount": owner,
                                            "amount": str(int(abs(change) * (10 ** decimals))),
                                            "decimals": decimals,
                                            "signature": signature,
                                            "slot": slot,
                                            "blockTime": block_time
                                        }
                                        logger.info(f"    ‚úÖ Meta transfer: {other_owner[:8]}... -> {owner[:8]}... ({abs(change):.4f} tokens)")
                                        transfers.append(transfer)
                                        found_sender = True
                                        break
                        
                        # If no explicit sender found, create a BUY event for the owner
                        if not found_sender:
                            transfer = {
                                "tokenMint": mint,
                                "fromUserAccount": "unknown",
                                "toUserAccount": owner,
                                "amount": str(int(abs(change) * (10 ** decimals))),
                                "decimals": decimals,
                                "signature": signature,
                                "slot": slot,
                                "blockTime": block_time
                            }
                            logger.info(f"    ‚úÖ Meta BUY: -> {owner[:8]}... ({abs(change):.4f} tokens)")
                            transfers.append(transfer)
                    
                    elif change < -0.000001:  # Sent tokens (SELL)
                        # Find recipient via positive change on same mint
                        found_recipient = False
                        for other_owner, other_mint in all_keys:
                            if other_mint == mint and other_owner != owner:
                                other_pre = pre_lookup.get((other_owner, other_mint))
                                other_post = post_lookup.get((other_owner, other_mint))
                                if other_pre and other_post:
                                    other_change = float(other_post.get('uiTokenAmount', {}).get('uiAmount', 0)) - float(other_pre.get('uiTokenAmount', {}).get('uiAmount', 0))
                                    if other_change > 0.000001:  # Received tokens
                                        transfer = {
                                            "tokenMint": mint,
                                            "fromUserAccount": owner,
                                            "toUserAccount": other_owner,
                                            "amount": str(int(abs(change) * (10 ** decimals))),
                                            "decimals": decimals,
                                            "signature": signature,
                                            "slot": slot,
                                            "blockTime": block_time
                                        }
                                        logger.info(f"    ‚úÖ Meta transfer: {owner[:8]}... -> {other_owner[:8]}... ({abs(change):.4f} tokens)")
                                        transfers.append(transfer)
                                        found_recipient = True
                                        break
                        
                        # If no explicit recipient found, create a SELL event for the owner
                        if not found_recipient:
                            transfer = {
                                "tokenMint": mint,
                                "fromUserAccount": owner,
                                "toUserAccount": "unknown",
                                "amount": str(int(abs(change) * (10 ** decimals))),
                                "decimals": decimals,
                                "signature": signature,
                                "slot": slot,
                                "blockTime": block_time
                            }
                            logger.info(f"    ‚úÖ Meta SELL: {owner[:8]}... -> ({abs(change):.4f} tokens)")
                            transfers.append(transfer)
        
        return transfers
        
    except Exception as e:
        logger.error(f"‚ùå Error parsing transfers from meta: {e}")
        return []

def parse_native_sol_transfers(event: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Parse native SOL transfers from pre/post balances"""
    try:
        meta = event.get('meta', {})
        pre_balances = meta.get('preBalances', [])
        post_balances = meta.get('postBalances', [])
        account_keys = event.get('transaction', {}).get('message', {}).get('accountKeys', [])
        signature = event.get('transaction', {}).get('signatures', [''])[0]
        slot = event.get('slot')
        block_time = event.get('blockTime')
        
        if len(pre_balances) != len(post_balances) or len(pre_balances) != len(account_keys):
            return []
        
        transfers = []
        
        for i, (pre_bal, post_bal) in enumerate(zip(pre_balances, post_balances)):
            change = post_bal - pre_bal
            if abs(change) > 5000:  # Ignore small changes (fees, etc.)
                account = account_keys[i]
                
                if change > 0:  # Received SOL
                    # Find who sent it by looking for negative changes
                    for j, (other_pre, other_post) in enumerate(zip(pre_balances, post_balances)):
                        if j != i and (other_post - other_pre) < -5000:
                            sender = account_keys[j]
                            amount = abs(change) / 1e9  # Convert lamports to SOL
                            
                            transfer = {
                                "tokenMint": SOL_MINT,
                                "fromUserAccount": sender,
                                "toUserAccount": account,
                                "amount": str(int(amount * 1e9)),
                                "decimals": 9,
                                "tokenName": "Solana",
                                "tokenSymbol": "SOL",
                                "signature": signature,
                                "slot": slot,
                                "blockTime": block_time
                            }
                            
                            logger.info(f"ü™ô Parsed SOL transfer: {sender[:8]}... -> {account[:8]}... ({amount:.4f} SOL)")
                            transfers.append(transfer)
                            break
        
        return transfers
        
    except Exception as e:
        logger.error(f"‚ùå Error parsing native SOL transfers: {e}")
        return []

def detect_tracked_wallet_activity(event: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Detect when tracked wallets are involved in transactions by analyzing account keys and balance changes"""
    try:
        personal_wallet = get_personal_wallet_address()
        tracked_wallets = get_current_wallets_to_track()
        
        # Get transaction details
        transaction = event.get('transaction', {})
        account_keys = transaction.get('message', {}).get('accountKeys', [])
        meta = event.get('meta', {})
        pre_token_balances = meta.get('preTokenBalances', [])
        post_token_balances = meta.get('postTokenBalances', [])
        signature = transaction.get('signatures', [''])[0]
        slot = event.get('slot')
        block_time = event.get('blockTime')
        
        if not account_keys or not pre_token_balances or not post_token_balances:
            return []
        
        # Create lookup dictionaries for pre/post balances
        pre_lookup = {}
        post_lookup = {}
        
        for balance in pre_token_balances:
            key = (balance.get('accountIndex'), balance.get('mint'))
            pre_lookup[key] = balance
        
        for balance in post_token_balances:
            key = (balance.get('accountIndex'), balance.get('mint'))
            post_lookup[key] = balance
        
        # Find all accounts with balance changes
        all_keys = set(pre_lookup.keys()) | set(post_lookup.keys())
        
        tracked_transfers = []
        
        for account_index, mint in all_keys:
            pre_balance = pre_lookup.get((account_index, mint))
            post_balance = post_lookup.get((account_index, mint))
            
            if pre_balance and post_balance:
                pre_amount = float(pre_balance.get('uiTokenAmount', {}).get('uiAmount', 0))
                post_amount = float(post_balance.get('uiTokenAmount', {}).get('uiAmount', 0))
                change = post_amount - pre_amount
                owner = pre_balance.get('owner') or post_balance.get('owner')
                
                # Check if this account belongs to a tracked wallet
                if owner in tracked_wallets:
                    decimals = pre_balance.get('uiTokenAmount', {}).get('decimals', 9)
                    
                    if change > 0.000001:  # Received tokens (BUY)
                        transfer = {
                            "tokenMint": mint,
                            "fromUserAccount": "unknown",  # Jupiter swap - no direct sender
                            "toUserAccount": owner,
                            "amount": str(int(abs(change) * (10 ** decimals))),
                            "decimals": decimals,
                            "signature": signature,
                            "slot": slot,
                            "blockTime": block_time
                        }
                        logger.info(f"üéØ TRACKED WALLET BUY: {owner[:8]}... received {abs(change):.6f} {mint[:8]}...")
                        tracked_transfers.append(transfer)
                        
                    elif change < -0.000001:  # Sent tokens (SELL)
                        transfer = {
                            "tokenMint": mint,
                            "fromUserAccount": owner,
                            "toUserAccount": "unknown",  # Jupiter swap - no direct recipient
                            "amount": str(int(abs(change) * (10 ** decimals))),
                            "decimals": decimals,
                            "signature": signature,
                            "slot": slot,
                            "blockTime": block_time
                        }
                        logger.info(f"üéØ TRACKED WALLET SELL: {owner[:8]}... sent {abs(change):.6f} {mint[:8]}...")
                        tracked_transfers.append(transfer)
        
        return tracked_transfers
        
    except Exception as e:
        logger.error(f"‚ùå Error detecting tracked wallet activity: {e}")
        return []

# Attempt to initialize services with proper error handling
try:
    from src.scripts.database.db_cache import DatabaseCache
    token_cache = DatabaseCache()
    logger.info("Database cache initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize database cache: {e}")
    # Create a mock cache for development
    class MockCache:
        def get_price(self, *args, **kwargs): return None
        def store_price(self, *args, **kwargs): pass
    token_cache = MockCache()
    logger.info("Using mock database cache")

try:
    from src.scripts.data_processing.token_metadata_service import TokenMetadataService
    token_metadata_service = TokenMetadataService()
    logger.info("Token metadata service initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize token metadata service: {e}")
    # Create a mock metadata service
    class MockMetadataService:
        def get_metadata(self, *args, **kwargs): 
            return {"symbol": "UNK", "name": "Unknown Token", "decimals": 9}
    token_metadata_service = MockMetadataService()
    logger.info("Using mock token metadata service")

try:
    from src.scripts.shared_services.optimized_price_service import get_optimized_price_service
    price_service = get_optimized_price_service()
    logger.info("Price service initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize price service: {e}")
    # Create a mock price service
    class MockPriceService:
        def get_token_price(self, *args, **kwargs): return {"usd": 0.1, "sol": 0.001}
    price_service = MockPriceService()
    logger.info("Using mock price service")

# NO FALLBACK PRICES - If we can't get a real price, we don't trade

# Global agent variables
copybot_agent = None
risk_agent = None
harvesting_agent = None
staking_agent = None
_last_status_print_ts = 0.0

# New: Portfolio monitoring and proactive detection
_portfolio_monitoring_active = False
_last_portfolio_check = 0.0
_portfolio_check_interval = 300  # 5 minutes
_proactive_monitoring_enabled = True

def _rate_limited_status_print() -> bool:
    """Return True if we should print status now (rate-limited)."""
    try:
        import time as _t
        global _last_status_print_ts
        now = _t.time()
        if now - _last_status_print_ts < 1.0:
            return False
        _last_status_print_ts = now
        return True
    except Exception:
        return True

def get_token_balance_direct_rpc(token_mint: str, wallet_address: str) -> float:
    """Get token balance directly via RPC for most accurate results"""
    try:
        # Note: requests and json are already imported at module level
        
        rpc_endpoint = os.getenv("RPC_ENDPOINT", "https://api.mainnet-beta.solana.com")
        
        # Get token accounts by owner
        payload = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "getTokenAccountsByOwner",
            "params": [
                wallet_address,
                {"mint": token_mint},
                {"encoding": "jsonParsed"}
            ]
        }
        
        response = requests.post(rpc_endpoint, json=payload, timeout=10)
        data = response.json()
        
        if "result" in data and data["result"]["value"]:
            account_info = data["result"]["value"][0]["account"]["data"]["parsed"]["info"]
            # CRITICAL FIX: Use unified token balance parsing
            from src.nice_funcs import parse_token_balance_with_decimals
            balance, decimals = parse_token_balance_with_decimals(account_info)
            return balance
        
        return 0.0
        
    except Exception as e:
        logger.warning(f"Direct RPC balance fetch failed: {e}")
        return 0.0

def get_balance_from_portfolio(token_mint: str, wallet_address: str) -> float:
    """Get token balance from portfolio tracker"""
    try:
        from src.scripts.wallet.wallet_tracker import WalletTracker
        tracker = WalletTracker()
        token_balances = tracker.get_token_balances(wallet_address)
        
        # Find the specific token balance
        for token_data in token_balances:
            if token_data.get('mint') == token_mint:
                return float(token_data.get('amount', 0.0))
        
        return 0.0
        
    except Exception as e:
        logger.warning(f"Portfolio balance fetch failed: {e}")
        return 0.0

def get_balance_from_shared_api(token_mint: str, wallet_address: str) -> float:
    """Get token balance from shared API manager"""
    try:
        from src.scripts.shared_services.shared_api_manager import get_shared_api_manager
        api_manager = get_shared_api_manager()
        balance = api_manager.get_token_balance(wallet_address, token_mint)
        return float(balance) if balance else 0.0
        
    except Exception as e:
        logger.warning(f"Shared API balance fetch failed: {e}")
        return 0.0

def get_unified_token_balance(token_mint: str, wallet_address: str = None) -> float:
    """Unified token balance lookup that checks all available sources in priority order"""
    try:
        from src import config
        
        # Default to personal wallet if none specified
        if not wallet_address:
            wallet_address = get_personal_wallet_address()
            if not wallet_address:
                logger.warning("No wallet address available for balance lookup")
                return 0.0
        
        # In paper trading mode, check paper trading portfolio first
        if PAPER_TRADING_ENABLED:
            try:
                from src.paper_trading import get_token_balance as paper_get_token_balance
                balance = paper_get_token_balance(token_mint)
                if balance > 0:
                    logger.debug(f"Paper trading balance for {token_mint[:8]}...: {balance}")
                    return balance
            except Exception as e:
                logger.debug(f"Paper trading balance lookup failed: {e}")
        
        # Check portfolio tracker next (most reliable for recent transactions)
        try:
            from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
            tracker = get_portfolio_tracker()
            if tracker:
                summary = tracker.get_portfolio_summary()
                if summary and 'positions' in summary:
                    positions = summary['positions']
                    if token_mint in positions:
                        balance = positions[token_mint].get('balance', 0)
                        if balance > 0:
                            logger.debug(f"Portfolio tracker balance for {token_mint[:8]}...: {balance}")
                            return float(balance)
        except Exception as e:
            logger.debug(f"Portfolio tracker balance lookup failed: {e}")
        
        # Fallback balance methods in order of reliability
        balance_methods = [
            # Method 1: Direct RPC call for most accurate balance
            ("Direct RPC", lambda: get_token_balance_direct_rpc(token_mint, wallet_address)),
            # Method 2: Nice funcs balance  
            ("Nice funcs", lambda: float(__import__('src.nice_funcs', fromlist=['get_nice_funcs']).get_nice_funcs().get_token_balance(token_mint) if __import__('src.nice_funcs', fromlist=['get_nice_funcs']).get_nice_funcs() else 0.0)),
            # Method 3: Portfolio tracker fallback (different method)
            ("Portfolio tracker", lambda: get_balance_from_portfolio(token_mint, wallet_address)),
            # Method 4: Shared API manager
            ("Shared API", lambda: get_balance_from_shared_api(token_mint, wallet_address))
        ]
        
        for method_name, method in balance_methods:
            try:
                balance = method()
                if balance and balance > 0:
                    logger.debug(f"{method_name} balance for {token_mint[:8]}...: {balance}")
                    return float(balance)
            except Exception as e:
                logger.debug(f"{method_name} balance method failed: {e}")
                continue
        
        # No balance found in any source
        return 0.0
        
    except Exception as e:
        logger.error(f"Unified balance lookup failed for {token_mint}: {e}")
        return 0.0

def execute_live_copy_trade(action: str, token_mint: str, amount: float, price: float, agent: str = "copybot") -> bool:
    """Execute a live copy trade using Jupiter via nice_funcs - FIXED VERSION

    - BUY: spend POSITION_SIZE_PERCENTAGE of portfolio in USDC to buy token_mint
    - SELL: sell up to the lesser of our current balance and the event amount
    """
    # Add execution trace logging
    logger.info(f"üéØ COPYBOT EXECUTION TRACE:")
    logger.info(f"   Action: {action}")
    logger.info(f"   Token: {token_mint[:8]}...")
    logger.info(f"   Amount: {amount}")
    logger.info(f"   Price: ${price}")
    logger.info(f"   Agent: {agent}")
    
    # Log execution attempt
    try:
        from src.scripts.database.execution_tracker import log_execution
        execution_id = log_execution(
            agent_type=agent,  # Use the passed agent parameter
            wallet_address=get_personal_wallet_address(),
            action=action,
            token_mint=token_mint,
            amount=amount,
            price=price,
            usd_value=amount * price if price and amount else None,
            status="PENDING"
        )
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Failed to log execution attempt: {e}")
        execution_id = None
    
    try:
        from src import config
        from src import nice_funcs as n
        from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
        from src.scripts.data_processing.token_metadata_service import TokenMetadataService
        from src.scripts.trade_log import log_live_trade

        # Block copybot and risk agent from SOL/USDC in live trading
        if agent in ['copybot', 'risk'] and token_mint in [SOL_ADDRESS, USDC_ADDRESS]:
            logger.error(f"üö´ {agent} blocked from live trading {token_mint[:8]}...")
            return False

        # Additional validation for risk agent
        if agent == "risk" and token_mint in [SOL_ADDRESS, USDC_ADDRESS]:
            logger.error(f"üö´ Risk agent blocked from trading {token_mint[:8]}... - should only close risky positions")
            return False

        tracker = get_portfolio_tracker()
        summary = getattr(tracker, 'get_portfolio_summary', lambda: {})() or {}
        total_usd = float(summary.get('current_value', 0.0) or 0.0)

        if action == 'BUY':
            # CopyBot mirroring with risk management enforcement
            logger.info(f"üîÑ CopyBot mirroring BUY transaction for {token_mint[:8]}...")
            
            # RISK MANAGEMENT: Enforce allocation limits before buying
            from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
            summary = get_portfolio_tracker().get_portfolio_summary() or {}
            total = float(summary.get('current_value', 0.0) or 0.0)
            positions_val = float(summary.get('positions_value_usd', summary.get('positions_value', 0.0)) or 0.0)
            positions_pct = (positions_val / total) if total > 0 else 0.0
            active_positions = len([p for p in (summary.get('positions') or {}).values() if p.get('usd_value', 0) > 0])
            positions_dict = summary.get('positions') or {}
            is_new_position = token_mint not in positions_dict

            if positions_pct >= MAX_TOTAL_ALLOCATION_PERCENT:
                logger.warning(f"üö´ Live BUY blocked - total allocation at {positions_pct:.1%}")
                return False
            elif is_new_position and active_positions >= MAX_CONCURRENT_POSITIONS:
                logger.warning(f"üö´ Live BUY blocked - {active_positions} positions >= limit")
                return False

            # Single position check (adjust budget_usd calculation)
            current_position_value = float(positions_dict.get(token_mint, {}).get('usd_value', 0.0))
            max_allowed_for_position = total * MAX_SINGLE_POSITION_PERCENT - current_position_value
            if max_allowed_for_position <= 0:
                logger.warning(f"üö´ Live BUY blocked - single position cap reached")
                return False
            
            # For BUY operations, check USDC balance, not token balance
            try:
                usdc_balance = get_usdc_balance(get_personal_wallet_address())
                logger.info(f"üîç Copybot BUY: USDC balance: ${usdc_balance:.2f}")
                
                if usdc_balance <= 0:
                    logger.warning("Live copy BUY skipped: no USDC balance")
                    return False
                
                # Use either the event amount or a percentage of portfolio, whichever is smaller
                # Also respect single-position limit
                budget_usd = min(
                    usdc_balance,
                    max(0.0, total_usd * float(getattr(config, 'POSITION_SIZE_PERCENTAGE', 0.02))),
                    max_allowed_for_position
                )
                
                if budget_usd <= 0:
                    logger.warning("Live copy BUY skipped: zero USD budget")
                    return False
                
                logger.info(f"üöÄ Executing copy BUY: ${budget_usd:.2f} USDC for {token_mint}")
                usdc_minor = int(budget_usd * 1_000_000)
                sig = n.market_buy(token_mint, usdc_minor, getattr(config, 'JUPITER_DEFAULT_SLIPPAGE_BPS', 50), allow_excluded=True)
                
                if sig:
                    px = price if (isinstance(price, (int, float)) and price > 0) else 0.0
                    log_live_trade(signature=sig, side='BUY', size=usdc_minor, price_usd=px, usd_value=budget_usd, agent=agent, token=token_mint)
                    
                    # Also log to cloud database
                    try:
                        from src.scripts.database.cloud_database import get_cloud_database_manager
                        dbm = get_cloud_database_manager()
                        if dbm:
                            dbm.add_live_trade(
                                signature=sig,
                                side='BUY',
                                size=usdc_minor,
                                price_usd=px,
                                usd_value=budget_usd,
                                agent=agent,
                                token_mint=token_mint,
                                metadata={'source': 'copybot'}
                            )
                    except Exception as e:
                        logger.warning(f'Failed to replicate copybot trade to cloud: {e}')
                    
                    # CRITICAL FIX: Set entry price for unrealized gains calculation
                    try:
                        from src.scripts.database.entry_price_tracker import EntryPriceTracker
                        # Force local database usage to avoid cloud connection issues
                        import src.scripts.database.entry_price_tracker as ept
                        original_cloud_available = ept.CLOUD_DB_AVAILABLE
                        ept.CLOUD_DB_AVAILABLE = False
                        
                        entry_tracker = EntryPriceTracker()
                        # Calculate token amount from USD value and price
                        token_amount = budget_usd / px if px > 0 else 0
                        success = entry_tracker.set_entry_price(
                            mint=token_mint,
                            entry_price_usd=px,
                            entry_amount=token_amount,
                            source="live_trading_buy",
                            notes=f"Live trading BUY at ${px:.6f} via {agent}"
                        )
                        
                        # Restore original setting
                        ept.CLOUD_DB_AVAILABLE = original_cloud_available
                        
                        if success:
                            logger.debug(f"‚úÖ Entry price set for {token_mint[:8]}...: ${px:.6f}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Failed to set entry price for {token_mint[:8]}...")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Failed to set entry price for {token_mint[:8]}...: {e}")
                    
                    logger.info(f"‚úÖ Copy BUY executed successfully: {sig}")
                    return True
                else:
                    logger.error("‚ùå Copy BUY failed: no signature returned")
                    return False
                    
            except Exception as e:
                logger.error(f"‚ùå Error in copy BUY operation: {e}")
                return False

        if action == 'SELL':
            # Determine our current balance and decimals
            tms = TokenMetadataService()
            decimals = int(tms.get_token_decimals(token_mint)) if hasattr(tms, 'get_token_decimals') else 9
            
            # Use unified balance lookup for reliable balance detection
            current_balance = get_unified_token_balance(token_mint)
            
            if current_balance <= 0:
                logger.info(f"Live copy SELL skipped: no holdings to sell (balance: {current_balance:.6f})")
                return False
                
            sell_amount = max(0.0, min(current_balance, float(amount)))
            if sell_amount <= 0:
                logger.info(f"Live copy SELL skipped: no holdings to sell (balance: {current_balance:.6f}, requested: {amount:.6f})")
                return False
                
            logger.info(f"üöÄ Executing copy SELL: {sell_amount:.6f} {token_mint}")
            minor = int(sell_amount * (10 ** decimals))
            sig = n.market_sell(token_mint, minor, getattr(config, 'JUPITER_DEFAULT_SLIPPAGE_BPS', 50), allow_excluded=True)
            
            if sig:
                px = price if (isinstance(price, (int, float)) and price > 0) else 0.0
                usd_val = sell_amount * px if px > 0 else 0.0
                log_live_trade(signature=sig, side='SELL', size=minor, price_usd=px, usd_value=usd_val, agent=agent, token=token_mint)
                
                # Also log to cloud database
                try:
                    from src.scripts.database.cloud_database import get_cloud_database_manager
                    dbm = get_cloud_database_manager()
                    if dbm:
                        dbm.add_live_trade(
                            signature=sig,
                            side='SELL',
                            size=minor,
                            price_usd=px,
                            usd_value=usd_val,
                            agent=agent,
                            token_mint=token_mint,
                            metadata={'source': 'copybot'}
                        )
                except Exception as e:
                    logger.warning(f'Failed to replicate copybot trade to cloud: {e}')
                logger.info(f"‚úÖ Copy SELL executed successfully: {sig}")
                
                # Force portfolio tracker refresh after sell
                try:
                    from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
                    tracker = get_portfolio_tracker()
                    if tracker:
                        tracker.force_refresh_portfolio_data()
                except Exception as e:
                    logger.warning(f"Failed to refresh portfolio tracker after sell: {e}")
                
                return True
            else:
                logger.error("‚ùå Copy SELL failed: no signature returned")
                return False

        logger.warning(f"Unknown live action: {action}")
        # Log failed execution
        if execution_id:
            try:
                from src.scripts.execution_tracker import get_execution_tracker
                get_execution_tracker().update_execution_status(
                    execution_id, "FAILED", 
                    error_message=f"Unknown action: {action}"
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to update execution status: {e}")
        return False
        
    except Exception as e:
        logger.error(f"execute_live_copy_trade error: {e}")
        # Log failed execution
        if execution_id:
            try:
                from src.scripts.execution_tracker import get_execution_tracker
                get_execution_tracker().update_execution_status(
                    execution_id, "FAILED", 
                    error_message=str(e)
                )
            except Exception as e2:
                logger.warning(f"‚ö†Ô∏è Failed to update execution status: {e2}")
        return False
    finally:
        # Log successful execution if we have a signature
        if execution_id and 'sig' in locals() and sig:
            try:
                from src.scripts.execution_tracker import get_execution_tracker
                get_execution_tracker().update_execution_status(
                    execution_id, "SUCCESS", 
                    transaction_signature=sig
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to update execution status: {e}")

def initialize_copybot_agent():
    """Initialize CopyBot agent with timeout protection"""
    global copybot_agent
    
    try:
        if copybot_agent is None:
            logger.info("üîÑ Initializing CopyBot agent...")
            
            # Import with timeout protection using threading.Timer (Windows compatible)
            import threading
            import time
            
            def timeout_handler():
                raise TimeoutError("CopyBot initialization timed out")
            
            # Set timeout for initialization using threading.Timer
            timer = threading.Timer(30.0, timeout_handler)
            timer.start()
            
            try:
                from src.agents.copybot_agent import CopyBotAgent
                copybot_agent = CopyBotAgent()
                logger.info("‚úÖ CopyBot agent initialized successfully")
                timer.cancel()  # Cancel timeout
                return True
            except TimeoutError:
                logger.error("‚ùå CopyBot agent initialization timed out")
                timer.cancel()  # Cancel timeout
                return False
            except Exception as e:
                logger.error(f"‚ùå Error initializing CopyBot agent: {e}")
                timer.cancel()  # Cancel timeout
                return False
        else:
            logger.info("‚úÖ CopyBot agent already initialized")
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize CopyBot agent: {e}")
        return False

def initialize_risk_agent():
    """Initialize Risk agent with timeout protection"""
    global risk_agent
    
    try:
        if risk_agent is None:
            logger.info("üîÑ Initializing Risk agent...")
            
            # Import with timeout protection using threading.Timer (Windows compatible)
            import threading
            import time
            
            def timeout_handler():
                raise TimeoutError("Risk agent initialization timed out")
            
            # Set timeout for initialization using threading.Timer
            timer = threading.Timer(45.0, timeout_handler)
            timer.start()
            
            try:
                from src.agents.risk_agent import get_risk_agent
                risk_agent = get_risk_agent()
                logger.info("‚úÖ Risk agent initialized successfully")
                timer.cancel()  # Cancel timeout
                return True
            except TimeoutError:
                logger.error("‚ùå Risk agent initialization timed out")
                timer.cancel()  # Cancel timeout
                return False
            except Exception as e:
                logger.error(f"‚ùå Error initializing Risk agent: {e}")
                timer.cancel()  # Cancel timeout
                return False
        else:
            logger.info("‚úÖ Risk agent already initialized")
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Risk agent: {e}")
        return False

def initialize_harvesting_agent():
    """Initialize Harvesting agent with timeout protection"""
    global harvesting_agent
    
    try:
        if harvesting_agent is None:
            logger.info("üîÑ Initializing Harvesting agent...")
            
            # Import with timeout protection using threading.Timer (Windows compatible)
            import threading
            import time
            
            def timeout_handler():
                raise TimeoutError("Harvesting agent initialization timed out")
            
            # Set timeout for initialization using threading.Timer
            timer = threading.Timer(30.0, timeout_handler)
            timer.start()
            
            try:
                from src.agents.harvesting_agent import HarvestingAgent
                harvesting_agent = HarvestingAgent(enable_ai=True)
                logger.info("‚úÖ Harvesting agent initialized successfully")
                timer.cancel()  # Cancel timeout
                return True
            except TimeoutError:
                logger.error("‚ùå Harvesting agent initialization timed out")
                timer.cancel()  # Cancel timeout
                return False
            except Exception as e:
                logger.error(f"‚ùå Error initializing Harvesting agent: {e}")
                timer.cancel()  # Cancel timeout
                return False
        else:
            logger.info("‚úÖ Harvesting agent already initialized")
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Harvesting agent: {e}")
        return False

def initialize_staking_agent():
    """Initialize Staking agent with timeout protection"""
    global staking_agent
    
    try:
        if staking_agent is None:
            logger.info("üîÑ Initializing Staking agent...")
            
            # Import with timeout protection using threading.Timer (Windows compatible)
            import threading
            import time
            
            def timeout_handler():
                raise TimeoutError("Staking agent initialization timed out")
            
            # Set timeout for initialization using threading.Timer
            timer = threading.Timer(30.0, timeout_handler)
            timer.start()
            
            try:
                from src.agents.staking_agent import StakingAgent
                staking_agent = StakingAgent()
                logger.info("‚úÖ Staking agent initialized successfully")
                timer.cancel()  # Cancel timeout
                return True
            except TimeoutError:
                logger.error("‚ùå Staking agent initialization timed out")
                timer.cancel()  # Cancel timeout
                return False
            except Exception as e:
                logger.error(f"‚ùå Error initializing Staking agent: {e}")
                timer.cancel()  # Cancel timeout
                return False
        else:
            logger.info("‚úÖ Staking agent already initialized")
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Staking agent: {e}")
        return False

def initialize_all_agents():
    """Initialize all trading agents during system startup"""
    global copybot_agent, risk_agent, harvesting_agent, staking_agent
    
    try:
        logger.info("üöÄ Initializing all trading agents...")
        
        # Initialize agents in parallel for better performance
        import threading
        import time
        
        # Track initialization results
        init_results = {}
        
        def init_agent(agent_name, init_func):
            """Initialize a single agent and store result"""
            try:
                result = init_func()
                init_results[agent_name] = result
                if result:
                    logger.info(f"‚úÖ {agent_name} initialization completed successfully")
                else:
                    logger.error(f"‚ùå {agent_name} initialization failed")
            except Exception as e:
                logger.error(f"‚ùå {agent_name} initialization error: {e}")
                init_results[agent_name] = False
        
        # Start all agent initializations in parallel
        threads = []
        agents_to_init = [
            ("CopyBot", initialize_copybot_agent),
            ("Risk", initialize_risk_agent),
            ("Harvesting", initialize_harvesting_agent),
            ("Staking", initialize_staking_agent)
        ]
        
        for agent_name, init_func in agents_to_init:
            thread = threading.Thread(target=init_agent, args=(agent_name, init_func))
            thread.daemon = True
            thread.start()
            threads.append(thread)
        
        # Wait for all initializations to complete (with timeout)
        timeout = 60  # 60 seconds total timeout
        start_time = time.time()
        
        for thread in threads:
            thread.join(timeout=max(0, timeout - (time.time() - start_time)))
        
        # Check results
        successful_agents = [name for name, result in init_results.items() if result]
        failed_agents = [name for name, result in init_results.items() if not result]
        
        if successful_agents:
            logger.info(f"‚úÖ Successfully initialized agents: {', '.join(successful_agents)}")
        
        if failed_agents:
            logger.warning(f"‚ö†Ô∏è Failed to initialize agents: {', '.join(failed_agents)}")
        
        # CRITICAL: Ensure CopyBot agent waits for harvesting agent startup rebalancing
        if copybot_agent and init_results.get("CopyBot", False):
            try:
                logger.info("üîÑ CopyBot agent waiting for harvesting agent startup rebalancing...")
                
                # Check if harvesting agent completed startup rebalancing
                if harvesting_agent and hasattr(harvesting_agent, 'startup_rebalancing_complete'):
                    if harvesting_agent.startup_rebalancing_complete:
                        logger.info("‚úÖ Harvesting agent startup rebalancing already complete - CopyBot can proceed")
                    else:
                        logger.info("‚è≥ Waiting for harvesting agent to complete startup rebalancing...")
                        # Wait for startup rebalancing to complete (with timeout)
                        import time
                        timeout_seconds = 30  # 30 second timeout
                        start_time = time.time()
                        
                        # Check both instance flag and global flag
                        startup_complete = False
                        while not startup_complete:
                            # Check instance flag
                            if harvesting_agent.startup_rebalancing_complete:
                                startup_complete = True
                                logger.info("‚úÖ Harvesting agent startup rebalancing completed (instance flag) - CopyBot can now proceed")
                                break
                            
                            # Check global flag
                            try:
                                from src.config import HARVESTING_STARTUP_DONE
                                if HARVESTING_STARTUP_DONE:
                                    startup_complete = True
                                    logger.info("‚úÖ Harvesting agent startup rebalancing completed (global flag) - CopyBot can now proceed")
                                    break
                            except ImportError:
                                pass
                            
                            if time.time() - start_time > timeout_seconds:
                                logger.warning("‚ö†Ô∏è Timeout waiting for harvesting agent startup rebalancing - CopyBot proceeding anyway")
                                break
                            time.sleep(1)  # Check every second
                        
                        if startup_complete:
                            logger.info("‚úÖ Harvesting agent startup rebalancing completed - CopyBot can now proceed")
                        else:
                            logger.warning("‚ö†Ô∏è Harvesting agent startup rebalancing not completed - CopyBot proceeding with caution")
                else:
                    logger.info("‚ÑπÔ∏è No harvesting agent or startup rebalancing not needed - CopyBot proceeding")
                
                # Now proceed with CopyBot baseline data collection
                logger.info("üîÑ CopyBot agent fetching baseline wallet data...")
                
                # Call the baseline data collection method
                if hasattr(copybot_agent, '_collect_baseline_data_only'):
                    success = copybot_agent._collect_baseline_data_only()
                    if success:
                        logger.info("‚úÖ CopyBot baseline wallet data collection completed")
                        logger.info("üöÄ CopyBot is now ready to process webhook events")
                    else:
                        logger.warning("‚ö†Ô∏è CopyBot baseline data collection failed")
                else:
                    logger.warning("‚ö†Ô∏è CopyBot agent missing baseline data collection method")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in CopyBot baseline data collection: {e}")
        
        # Log final status
        total_agents = len(agents_to_init)
        successful_count = len(successful_agents)
        logger.info(f"üéØ Agent initialization summary: {successful_count}/{total_agents} agents ready")
        
        return len(successful_agents) > 0  # Return True if at least one agent is ready
        
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize agents: {e}")
        return False

def print_copybot_status(wallet_address, changes):
    """Print CopyBot status to console"""
    try:
        print("\nü§ñ CopyBot Activity:")
        print("--------------------------------------------------")
        print(f"Processing changes for wallet: {wallet_address[:8]}...")
        
        # Print token changes
        if "tokens" in changes:
            for token, data in changes["tokens"].items():
                symbol = data.get("symbol", "???")
                action = data.get("action", "UNKNOWN")
                amount = data.get("amount", 0)
                price = data.get("price", 0)
                usd_value = data.get("usd_value", 0)
                print(f"‚Ä¢ {action} {amount:.4f} {symbol} @ ${price:.4f} (${usd_value:.2f})")
        print("--------------------------------------------------\n")
    except Exception as e:
        logger.error(f"Error printing CopyBot status: {e}")

def print_risk_status(event):
    """Print Risk agent status to console"""
    try:
        print("\nüõ°Ô∏è Risk Agent Activity:")
        print("--------------------------------------------------")
        symbol = event.get("symbol", "???")
        action = event.get("action", "UNKNOWN")
        amount = event.get("amount", 0)
        price = event.get("price", 0)
        usd_value = event.get("usd_value", 0)
        print(f"‚Ä¢ Checking risk for {action} {amount:.4f} {symbol}")
        print(f"‚Ä¢ Value: ${usd_value:.2f} @ ${price:.4f}")
        print("--------------------------------------------------\n")
    except Exception as e:
        logger.error(f"Error printing Risk status: {e}")

def print_harvesting_status(event):
    """Print Harvesting agent status to console"""
    try:
        print("\nüåæ Harvesting Agent Activity:")
        print("--------------------------------------------------")
        symbol = event.get("symbol", "???")
        action = event.get("action", "UNKNOWN")
        amount = event.get("amount", 0)
        price = event.get("price", 0)
        usd_value = event.get("usd_value", 0)
        gain_type = event.get("gain_type", "UNKNOWN")
        print(f"‚Ä¢ {action} {amount:.4f} {symbol} for {gain_type}")
        print(f"‚Ä¢ Value: ${usd_value:.2f} @ ${price:.4f}")
        print("--------------------------------------------------\n")
    except Exception as e:
        logger.error(f"Error printing Harvesting status: {e}")

def _strip_excluded_tokens(changes: dict) -> dict:
    """Filter out excluded tokens from webhook changes before reaching CopyBot"""
    from src.config import EXCLUDED_TOKENS
    
    excluded = set(EXCLUDED_TOKENS)
    filtered_changes = {}
    
    for wallet, wallet_changes in changes.items():
        filtered_wallet_changes = {}
        
        # Handle new webhook structure: {'wallet': {'tokens': {'mint': {...}}}}
        if 'tokens' in wallet_changes:
            filtered_tokens = {mint: data for mint, data in wallet_changes['tokens'].items() 
                             if mint not in excluded}
            if filtered_tokens:
                filtered_wallet_changes['tokens'] = filtered_tokens
        
        # Handle legacy structure: {'wallet': {'new': {...}, 'removed': {...}, 'modified': {...}}}
        else:
            for change_type in ['new', 'removed', 'modified']:
                if change_type in wallet_changes:
                    filtered_tokens = {mint: data for mint, data in wallet_changes[change_type].items() 
                                     if mint not in excluded}
                    if filtered_tokens:
                        filtered_wallet_changes[change_type] = filtered_tokens
        
        if filtered_wallet_changes:
            filtered_changes[wallet] = filtered_wallet_changes
    
    return filtered_changes

def trigger_copybot_for_changes(wallet_address, changes):
    """Trigger CopyBot agent for wallet changes"""
    global copybot_agent
    
    try:
        if copybot_agent is None:
            success = initialize_copybot_agent()
            if not success:
                logger.error("Could not initialize CopyBot agent for changes")
                return False
        
        # Filter out excluded tokens before triggering CopyBot
        filtered_changes = _strip_excluded_tokens(changes)
        
        if not filtered_changes:
            logger.info("üö´ No non-excluded tokens in changes, skipping CopyBot trigger")
            return True
        
        logger.info("üîî Triggering CopyBot agent for wallet changes (filtered)")
        
        # Update last webhook time for the copybot agent
        if hasattr(copybot_agent, 'last_webhook_time'):
            copybot_agent.last_webhook_time = time.time()
        
        # Run copybot analysis in separate thread to avoid blocking webhook responses
        def run_copybot_analysis():
            try:
                # Call the webhook trigger method directly with filtered changes
                success = copybot_agent.handle_webhook_trigger({
                    'wallet_address': wallet_address,
                    'changes': filtered_changes,
                    'timestamp': datetime.now().isoformat()
                })
                
                if success:
                    logger.info("‚úÖ CopyBot agent successfully processed webhook trigger")
                else:
                    logger.warning("‚ö†Ô∏è CopyBot agent failed to process webhook trigger")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in CopyBot agent execution: {e}")
                # Don't let errors stop the copybot agent
                logger.info("üîÑ CopyBot agent continuing to monitor despite error")
        
        copybot_thread = Thread(target=run_copybot_analysis)
        copybot_thread.daemon = True
        copybot_thread.agent_name = "copybot"  # Set agent name for attribution
        copybot_thread.start()
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to trigger CopyBot agent: {e}")
        return False

def trigger_risk_agent_for_transaction(transaction_data):
    """Trigger enhanced Risk agent for personal wallet transactions with all override triggers"""
    global risk_agent
    
    try:
        if risk_agent is None:
            success = initialize_risk_agent()
            if not success:
                logger.error("Could not initialize Risk agent for transaction monitoring")
                return False
        
        logger.info("üîî Triggering enhanced Risk agent for comprehensive risk check")
        
        # Update last webhook time for the risk agent
        if hasattr(risk_agent, 'last_webhook_time'):
            risk_agent.last_webhook_time = time.time()
        
        # Run enhanced risk check in separate thread to avoid blocking webhook responses
        def run_enhanced_risk_check():
            try:
                # Use the new comprehensive webhook trigger system
                triggers = risk_agent.check_webhook_override_triggers(transaction_data)
                
                # Execute all required actions
                for action in triggers.get('actions_required', []):
                    risk_agent._execute_trigger_action(action)
                
                # Auto-convert dust if no critical breaches
                if not triggers.get('emergency_stop_triggered', False):
                    try:
                        if hasattr(risk_agent, 'auto_convert_dust_to_sol'):
                            risk_agent.auto_convert_dust_to_sol()
                        else:
                            logger.warning("Risk agent missing auto_convert_dust_to_sol method - skipping dust conversion")
                    except Exception as e:
                        logger.error(f"Error in dust conversion: {e}")
                
                # Log comprehensive status
                current_pnl = risk_agent.get_current_pnl()
                current_balance = risk_agent.get_portfolio_value()
                current_drawdown = risk_agent._calculate_drawdown()
                
                logger.info("‚úÖ Enhanced Risk agent completed comprehensive check:")
                logger.info(f"  ‚Ä¢ PnL: ${current_pnl:.2f}")
                logger.info(f"  ‚Ä¢ Balance: ${current_balance:.2f}")
                logger.info(f"  ‚Ä¢ Drawdown: {current_drawdown:.2f}%")
                logger.info(f"  ‚Ä¢ Consecutive Losses: {risk_agent.consecutive_losses}")
                logger.info(f"  ‚Ä¢ Position Size Multiplier: {risk_agent.position_size_multiplier:.2f}")
                logger.info(f"  ‚Ä¢ Triggers Activated: {len(triggers.get('actions_required', []))}")
                
            except Exception as e:
                logger.error(f"‚ùå Error in enhanced Risk agent execution: {e}")
                # Don't let errors stop the risk agent
                logger.info("üîÑ Risk agent continuing to monitor despite error")
        
        risk_thread = Thread(target=run_enhanced_risk_check)
        risk_thread.daemon = True
        risk_thread.agent_name = "risk"  # Set agent name for attribution
        risk_thread.start()
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to trigger enhanced Risk agent: {e}")
        return False

def trigger_staking_agent_for_transaction(transaction_data):
    """Trigger Staking agent for personal wallet transactions"""
    global staking_agent
    
    try:
        if staking_agent is None:
            success = initialize_staking_agent()
            if not success:
                logger.error("Could not initialize Staking agent for transaction monitoring")
                return False
        
        logger.info("üîî Triggering Staking agent for portfolio management")
        
        # Update last webhook time for the staking agent
        if hasattr(staking_agent, 'last_webhook_time'):
            staking_agent.last_webhook_time = time.time()
        
        # Run staking check in separate thread to avoid blocking webhook responses
        def run_staking_check():
            try:
                # Check if staking agent has webhook trigger method
                if hasattr(staking_agent, 'handle_webhook_trigger'):
                    success = staking_agent.handle_webhook_trigger({
                        'type': 'transaction_monitoring',
                        'timestamp': datetime.now().isoformat(),
                        'transaction_data': transaction_data
                    })
                    
                    if success:
                        logger.info("‚úÖ Staking agent successfully processed webhook trigger")
                    else:
                        logger.warning("‚ö†Ô∏è Staking agent failed to process webhook trigger")
                else:
                    logger.info("‚ÑπÔ∏è Staking agent webhook trigger method not available")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in Staking agent execution: {e}")
                # Don't let errors stop the staking agent
                logger.info("üîÑ Staking agent continuing to monitor despite error")
        
        staking_thread = Thread(target=run_staking_check)
        staking_thread.daemon = True
        staking_thread.agent_name = "staking"  # Set agent name for attribution
        staking_thread.start()
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to trigger Staking agent: {e}")
        return False

def trigger_harvesting_agent_for_transaction(transaction_data):
    """Trigger Harvesting agent for personal wallet transactions"""
    global harvesting_agent
    
    try:
        if harvesting_agent is None:
            success = initialize_harvesting_agent()
            if not success:
                logger.error("Could not initialize Harvesting agent for transaction monitoring")
                return False
        
        logger.info("üîî Triggering Harvesting agent for gain analysis")
        
        # Update last webhook time for the harvesting agent
        if hasattr(harvesting_agent, 'last_webhook_time'):
            harvesting_agent.last_webhook_time = time.time()
        
        # Run harvesting check in separate thread to avoid blocking webhook responses
        def run_harvesting_check():
            try:
                # Use the comprehensive webhook trigger system
                success = harvesting_agent.handle_webhook_trigger(transaction_data)
                
                if success:
                    logger.info("‚úÖ Harvesting agent successfully processed webhook trigger")
                else:
                    logger.warning("‚ö†Ô∏è Harvesting agent failed to process webhook trigger")
                    
            except Exception as e:
                logger.error(f"‚ùå Error in Harvesting agent execution: {e}")
                # Don't let errors stop the harvesting agent
                logger.info("üîÑ Harvesting agent continuing to monitor despite error")
        
        harvesting_thread = Thread(target=run_harvesting_check)
        harvesting_thread.daemon = True
        harvesting_thread.agent_name = "harvesting"  # Set agent name for attribution
        harvesting_thread.start()
        
        return True
        
    except Exception as e:
        logger.error(f"Failed to trigger Harvesting agent: {e}")
        return False

def should_process_transaction(transaction_data, wallet_address):
    """Smart filtering to determine if transaction should trigger agents"""
    try:
        # Get minimum value threshold from config
        min_value_usd = WEBHOOK_MIN_TOKEN_VALUE_USD
        
        # Check if this is a personal wallet transaction
        if is_personal_wallet(wallet_address):
            # For personal wallet, check transaction value
            token_transfers = transaction_data.get('tokenTransfers', [])
            native_transfers = transaction_data.get('nativeTransfers', [])
            
            # Calculate total USD value of transfers
            total_usd_value = 0
            has_significant_transfer = False
            
            # Check token transfers
            for transfer in token_transfers:
                amount = transfer.get('amount', 0)
                decimals = transfer.get('decimals', 0)
                
                if amount > 0:
                    real_amount = amount / (10 ** decimals)
                    
                    # Try to get token price for USD value calculation
                    try:
                        token_mint = transfer.get('tokenMint')
                        if token_mint:
                            token_price = price_service.get_token_price(token_mint)
                            if token_price and token_price.get('usd'):
                                total_usd_value += real_amount * token_price.get('usd')
                            else:
                                # If we can't get price, check for SOL/USDC (always significant)
                                if token_mint in [KNOWN_TOKENS.get('SOL'), KNOWN_TOKENS.get('USDC'), KNOWN_TOKENS.get('USDT')]:
                                    has_significant_transfer = True
                    except Exception:
                        # If price service fails, check if it's a major token
                        token_mint = transfer.get('tokenMint')
                        if token_mint in [KNOWN_TOKENS.get('SOL'), KNOWN_TOKENS.get('USDC'), KNOWN_TOKENS.get('USDT')]:
                            has_significant_transfer = True
            
            # Check native transfers (SOL)
            for transfer in native_transfers:
                amount = transfer.get('amount', 0)
                if amount > 0:
                    sol_amount = amount / 1e9  # Convert lamports to SOL
                    # If transferring more than 0.01 SOL, consider it significant
                    if sol_amount > 0.01:
                        has_significant_transfer = True
                        # Try to estimate USD value if SOL price available
                        try:
                            sol_price = price_service.get_token_price(KNOWN_TOKENS.get('SOL'))
                            if sol_price and sol_price.get('usd'):
                                total_usd_value += sol_amount * sol_price.get('usd')
                        except Exception:
                            pass
            
            # Process if we have calculated USD value above threshold OR significant transfer
            if total_usd_value >= min_value_usd:
                logger.info(f"Personal wallet transaction above USD threshold (${total_usd_value:.2f})")
                return True
            elif has_significant_transfer:
                logger.info(f"Personal wallet has significant transfer (SOL/USDC/USDT)")
                return True
            else:
                logger.debug(f"Personal wallet transaction below threshold (${total_usd_value:.2f})")
                return False
        
        # For copybot wallets, process all significant transactions
        return True
        
    except Exception as e:
        logger.error(f"Error in transaction filtering: {e}")
        return True  # Default to processing on error

def get_current_wallets_to_track() -> Set[str]:
    """Get current tracked wallets as the union of wallets.json, WALLETS_TO_TRACK, and personal wallet.
    Also keeps wallets.json in sync when it lags behind the config.
    """
    # Cache wallet data to avoid redundant file reads
    if not hasattr(get_current_wallets_to_track, '_cached_wallets'):
        get_current_wallets_to_track._cached_wallets = None
        get_current_wallets_to_track._cache_time = 0
    
    current_time = time.time()
    if (
        get_current_wallets_to_track._cached_wallets is not None
        and current_time - get_current_wallets_to_track._cache_time < 60
    ):
        return get_current_wallets_to_track._cached_wallets
    
    try:
        logger.info("Loading wallets from config file...")
        
        config_path = os.path.join(
            os.path.dirname(os.path.dirname(__file__)), 'data', 'wallets.json'
        )

        file_wallets: Set[str] = set()
        labels: Dict[str, Any] = {}
        try:
            with open(config_path, 'r') as f:
                wallet_data = json.load(f)
                file_wallets = set(wallet_data.get('wallets', []))
                labels = wallet_data.get('labels', {}) or {}
        except FileNotFoundError:
            # Create the file lazily
            file_wallets = set()
            labels = {}

        # Load configured wallets (best-effort, with live reload)
        try:
            import importlib
            import src.config as runtime_config
            runtime_config = importlib.reload(runtime_config)
            config_wallets: Set[str] = set(getattr(runtime_config, 'WALLETS_TO_TRACK', []))
        except Exception:
            config_wallets = set()

        # Always include personal wallet
        personal_wallet = get_personal_wallet_address()
        always_include = {personal_wallet} if personal_wallet else set()

        # FINAL LIST: Use config as source of truth + always include personal wallet
        # This enforces equality between WALLETS_TO_TRACK (config) and wallets.json 'wallets'
        final_wallets: Set[str] = (config_wallets | always_include)

        # If wallets.json differs from final, write it back to disk to keep in sync (remove extras, add missing)
        if final_wallets != file_wallets:
            try:
                with open(config_path, 'w') as f:
                    json.dump({
                        'wallets': sorted(list(final_wallets)),
                        'labels': labels if labels else {'personal_wallet': personal_wallet} if personal_wallet else {}
                    }, f, indent=2)
                logger.info(
                    f"Synchronized wallets.json with config list ({len(final_wallets)} wallets)"
                )
            except Exception as write_err:
                logger.warning(f"Could not sync wallets.json: {write_err}")

        # Cache and return
        get_current_wallets_to_track._cached_wallets = final_wallets
        get_current_wallets_to_track._cache_time = current_time
        logger.info(f"Loaded {len(final_wallets)} wallets (config + personal)")
        return final_wallets
    except Exception as e:
        logger.error(f"Error loading wallets: {e}")
        if get_current_wallets_to_track._cached_wallets is not None:
            logger.info("Using cached wallet data due to loading error")
            return get_current_wallets_to_track._cached_wallets
        return set()

def _owner_for_account(account_index, meta_data):
    """Resolve owner address from account index using meta data"""
    try:
        if not meta_data or 'message' not in meta_data or 'accountKeys' not in meta_data['message']:
            return None
        
        account_keys = meta_data['message']['accountKeys']
        if account_index < len(account_keys):
            return account_keys[account_index]
        return None
    except Exception as e:
        logger.debug(f"Error resolving owner for account {account_index}: {e}")
        return None

def process_token_transfer(transfer_data):
    """Process a token transfer event and trigger agent actions directly if appropriate"""
    try:
        logger.info(f"üîç Processing transfer: {transfer_data}")
        token_mint = transfer_data.get('tokenMint') or transfer_data.get('mint')
        # Prefer owner fields; fall back to token accounts
        from_address = transfer_data.get('fromUserAccountOwner') or transfer_data.get('fromUserAccount')
        to_address = transfer_data.get('toUserAccountOwner') or transfer_data.get('toUserAccount')
        # CRITICAL FIX: Proper decimal handling for token amounts
        # Handle both 'amount' and 'tokenAmount' fields
        raw_amount = transfer_data.get('amount', transfer_data.get('tokenAmount', 0))
        token_decimals = int(transfer_data.get('decimals', 9))
        
        # Handle different amount formats
        if isinstance(raw_amount, str):
            try:
                raw_amount = float(raw_amount)
            except ValueError:
                raw_amount = 0
        
        # Calculate human-readable amount with proper decimal handling
        if raw_amount > 0 and token_decimals >= 0:
            amount = raw_amount / (10 ** token_decimals)
            logger.info(f"üîç Amount calculation: raw={raw_amount}, decimals={token_decimals}, calculated={amount:.6f}")
        else:
            amount = 0.0
            logger.warning(f"‚ö†Ô∏è Invalid amount data: raw={raw_amount}, decimals={token_decimals}")
        logger.info(f"üìä Transfer Details:")
        logger.info(f"  Token Mint: {token_mint}")
        logger.info(f"  From Address: {from_address}")
        logger.info(f"  To Address: {to_address}")
        logger.info(f"  Amount: {amount}")
        logger.info(f"  Decimals: {transfer_data.get('decimals', 9)}")
        try:
            metadata = token_metadata_service.get_metadata(token_mint)
            token_symbol = metadata.get('symbol', 'UNK')
            token_name = metadata.get('name', 'Unknown Token')
            logger.info(f"  Token Symbol: {token_symbol}")
            logger.info(f"  Token Name: {token_name}")
        except Exception as e:
            logger.error(f"‚ùå Error getting token metadata: {e}")
            token_symbol = 'UNK'
            token_name = 'Unknown Token'
        
        # NO FALLBACK PRICES - Get real price or skip the trade
        price = 0.0
        usd_value = 0.0
        try:
            price_candidate = price_service.get_price(token_mint)
            
            # Only use the price if it's valid and greater than 0
            if price_candidate and price_candidate > 0:
                price = float(price_candidate)
                logger.info(f"  Final price for {token_mint}: ${price:.6f} (Primary price service)")
            else:
                logger.warning(f"  No valid price available for {token_mint[:8]}... - SKIPPING TRADE")
                price = 0.0
        except Exception as e:
            logger.error(f"‚ùå Price service error for {token_mint}: {e}")
            price = 0.0
        
        # CRITICAL FIX: Log unrealistic prices but preserve actual price data for testing
        if price > 1000000:  # Price over $1M per token is unrealistic
            logger.warning(f"‚ö†Ô∏è Unrealistic price detected: ${price:.2f} for {token_mint[:8]}...")
            logger.warning(f"  This could cause portfolio calculation errors. Preserving actual price for testing.")
            logger.warning(f"  Consider upgrading to paid Birdeye API tier for more reliable pricing.")
            # Keep the actual price - don't fallback to $1.00 as it would break calculations
        
        # SKIP TRADE IF NO VALID PRICE - NO FALLBACK PRICES
        if price <= 0:
            logger.warning(f"üö´ SKIPPING TRADE: No valid price available for {token_mint[:8]}... (${price})")
            return None
        
        usd_value = amount * price
        # Use scientific notation for very small prices
        price_display = f"${price:.2e}" if price < 0.001 else f"${price:.4f}"
        logger.info(f"  USD Value: ${usd_value:.4f} (amount: {amount:.4f} * price: {price_display})")
        logger.info(f"  Minimum threshold: ${WEBHOOK_MIN_TOKEN_VALUE_USD}")
        
        # CRITICAL FIX: Determine wallet involvement BEFORE applying USD gating
        personal_wallet = get_personal_wallet_address()
        tracked_wallets = get_current_wallets_to_track()
        is_sol = token_mint == 'So11111111111111111111111111111111111111112'
        is_major_token = token_mint in [
            'EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v',  # USDC
            'Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB',  # USDT
            'So11111111111111111111111111111111111111112'   # SOL
        ]
        involves_tracked = (
            (from_address in tracked_wallets) or (to_address in tracked_wallets) or 
            (from_address == personal_wallet) or (to_address == personal_wallet)
        )

        # OPTIMIZED: More lenient processing criteria to improve success rates
        threshold_check = usd_value >= (WEBHOOK_MIN_TOKEN_VALUE_USD * 0.1)  # 10x more lenient threshold
        if involves_tracked or is_major_token or threshold_check:
            if is_major_token and not involves_tracked:
                logger.info("‚úÖ Processing major token transfer (bypassing USD threshold)")
            elif not involves_tracked and threshold_check:
                logger.info(f"‚úÖ USD value ${usd_value:.4f} above reduced threshold - processing")
            elif involves_tracked:
                logger.info(f"‚úÖ Transfer involves tracked wallet - processing")
        else:
            logger.info(f"‚ùå USD value ${usd_value:.4f} below reduced threshold - skipping")
            return None
        
        # OPTIMIZED: More lenient change transaction filtering to improve success rates
        # Only filter out truly tiny transactions that are definitely change/dust
        if not involves_tracked and amount < 0.001 and usd_value < 0.01:  # Only skip micro transactions
            logger.info(f"üîÑ Skipping dust transaction: {amount:.6f} tokens, ${usd_value:.4f} USD")
            return None
        
        logger.info(f"üîç Wallet Analysis:")
        logger.info(f"  Personal Wallet: {personal_wallet}")
        logger.info(f"  Tracked Wallets: {tracked_wallets}")
        logger.info(f"  From in tracked: {from_address in tracked_wallets}")
        logger.info(f"  To in tracked: {to_address in tracked_wallets}")
        logger.info(f"  From is personal: {from_address == personal_wallet}")
        logger.info(f"  To is personal: {to_address == personal_wallet}")
        
        # Always return a result for valid transfers
        result = {
            "from": from_address,
            "to": to_address,
            "wallet": None,  # Will be set below
            "token": token_mint,
            "action": None,
            "amount": amount,
            "price": price,
            "usd_value": usd_value,
            "symbol": token_symbol,
            "name": token_name,
            "raw": transfer_data
        }
        
        # Determine action and wallet
        logger.info(f"üîç WALLET MATCHING DEBUG:")
        logger.info(f"  to_address: {to_address}")
        logger.info(f"  from_address: {from_address}")
        logger.info(f"  tracked_wallets: {list(tracked_wallets)}")
        logger.info(f"  to_address in tracked_wallets: {to_address in tracked_wallets}")
        logger.info(f"  from_address in tracked_wallets: {from_address in tracked_wallets}")
        logger.info(f"  from_address == 'unknown': {from_address == 'unknown'}")
        logger.info(f"  to_address == 'unknown': {to_address == 'unknown'}")
        
        # BUY: Tracked wallet receiving tokens (sender can be unknown for DEX swaps)
        if to_address in tracked_wallets and to_address != "unknown":
            result["wallet"] = to_address
            result["action"] = "BUY"
            logger.info(f"üü¢ BUY signal detected - tokens sent to tracked wallet {to_address[:8]}...")
            success = True  # Initialize success variable
            if PAPER_TRADING_ENABLED and paper_trading_available:
                # NEW: Validate that we actually have transfer data before executing paper trade
                # This prevents phantom trades during startup or webhook race conditions
                if not transfer_data:
                    logger.debug(f"üö´ Skipping paper BUY - no transfer data provided")
                    success = False
                elif not token_mint or not from_address or not to_address:
                    logger.debug(f"üö´ Skipping paper BUY - missing required transfer fields")
                    success = False
                elif amount <= 0:
                    logger.debug(f"üö´ Skipping paper BUY - invalid amount: {amount}")
                    success = False
                else:
                    # Apply position sizing for paper trading
                    try:
                        from src.config import POSITION_SIZE_PERCENTAGE
                        
                        # Get current portfolio value
                        portfolio_value = get_portfolio_value()
                        if portfolio_value > 0:
                            # Calculate position size based on percentage of portfolio
                            max_position_value = portfolio_value * POSITION_SIZE_PERCENTAGE
                            current_trade_value = amount * price
                            
                            if current_trade_value > max_position_value:
                                # Scale down the amount to fit within position size limit
                                scaled_amount = max_position_value / price
                                logger.info(f"üìè Position sizing: Scaling trade from {amount:.4f} to {scaled_amount:.4f} tokens (${current_trade_value:.2f} -> ${max_position_value:.2f})")
                                amount = scaled_amount
                            else:
                                logger.info(f"üìè Position sizing: Trade within limits (${current_trade_value:.2f} <= ${max_position_value:.2f})")
                        else:
                            logger.warning("‚ö†Ô∏è Could not determine portfolio value for position sizing")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error in position sizing: {e}")
                    
                    # Determine which agent is currently executing
                    current_agent = _agent_context.get_agent()
                    # Fallback to thread-based attribution if context not set
                    if current_agent == 'unknown' and hasattr(threading.current_thread(), 'agent_name'):
                        current_agent = threading.current_thread().agent_name
                    # Final fallback - determine based on context
                    if current_agent == 'unknown':
                        # This is a webhook-triggered buy from tracked wallet - should be copybot
                        current_agent = "copybot"
                        logger.info(f"üîç Determined agent as 'copybot' for tracked wallet buy")
                    
                    # RISK MANAGEMENT: Enforce allocation limits before buying
                    from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
                    summary = get_portfolio_tracker().get_portfolio_summary() or {}
                    total = float(summary.get('current_value', 0.0) or 0.0)
                    positions_val = float(summary.get('positions_value_usd', summary.get('positions_value', 0.0)) or 0.0)
                    positions_pct = (positions_val / total) if total > 0 else 0.0
                    active_positions = len([p for p in (summary.get('positions') or {}).values() if p.get('usd_value', 0) > 0])
                    positions_dict = summary.get('positions') or {}
                    is_new_position = token_mint not in positions_dict

                    # Check 1: Total allocation limit
                    if positions_pct >= MAX_TOTAL_ALLOCATION_PERCENT:
                        logger.warning(f"üö´ BUY blocked - total allocation at {positions_pct:.1%} >= limit {MAX_TOTAL_ALLOCATION_PERCENT:.1%}")
                        success = False
                    # Check 2: Max concurrent positions
                    elif is_new_position and active_positions >= MAX_CONCURRENT_POSITIONS:
                        logger.warning(f"üö´ BUY blocked - {active_positions} positions >= limit {MAX_CONCURRENT_POSITIONS}")
                        success = False
                    else:
                        # Check 3: Single position limit
                        current_position_value = float(positions_dict.get(token_mint, {}).get('usd_value', 0.0))
                        proposed_usd = amount * price
                        if total > 0:
                            new_position_pct = (current_position_value + proposed_usd) / total
                            if new_position_pct > MAX_SINGLE_POSITION_PERCENT:
                                # Cap to limit
                                max_allowed_usd = total * MAX_SINGLE_POSITION_PERCENT - current_position_value
                                if max_allowed_usd <= 0:
                                    logger.warning(f"üö´ BUY blocked - single position at {(current_position_value/total):.1%} >= limit {MAX_SINGLE_POSITION_PERCENT:.1%}")
                                    success = False
                                else:
                                    amount = max_allowed_usd / price
                                    logger.info(f"üìè BUY capped from ${proposed_usd:.2f} to ${max_allowed_usd:.2f} (single-position limit)")

                    # Only proceed with execution if risk checks passed
                    if success is not False:
                        # Determine current agent
                        current_agent = _agent_context.get_agent()
                        if current_agent == 'unknown' and hasattr(threading.current_thread(), 'agent_name'):
                            current_agent = threading.current_thread().agent_name
                        if current_agent == 'unknown':
                            current_agent = "copybot"
                        
                        # Skip USDC validation for copybot - let it trade after harvesting rebalances
                        if current_agent not in ("copybot", "copybot_agent"):
                            from src.scripts.position_validator import validate_usdc_balance
                            usdc_valid, usdc_reason = validate_usdc_balance(amount * price, current_agent)
                            if not usdc_valid:
                                logger.warning(f"üö´ Paper trade blocked - USDC validation failed: {usdc_reason}")
                                success = False
                        
                        if success is not False:
                            success = execute_paper_trade(
                                token_address=token_mint,
                                action="BUY",
                                amount=amount,
                                price=price,
                                agent=current_agent
                            )
                    if success:
                        logger.info(f"‚úÖ Paper trade executed: BUY {amount:.4f} {token_symbol} @ ${price:.4f}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Paper trade failed: BUY {amount:.4f} {token_symbol} @ ${price:.4f}")
            else:
                logger.info(f"üöÄ EXECUTING LIVE COPY BUY: {token_mint} | Amount: {amount}")
                logger.info(f"üöÄ CALLING execute_live_copy_trade with: action=BUY, token={token_mint}, amount={amount}, price={price}")
                # Determine agent for live trade
                live_agent = _agent_context.get_agent()
                if live_agent == 'unknown' and hasattr(threading.current_thread(), 'agent_name'):
                    live_agent = threading.current_thread().agent_name
                if live_agent == 'unknown':
                    live_agent = "copybot"  # Default for webhook-triggered trades
                
                # Skip USDC validation for copybot
                if live_agent not in ("copybot", "copybot_agent"):
                    from src.scripts.position_validator import validate_usdc_balance
                    usdc_valid, usdc_reason = validate_usdc_balance(amount * price, live_agent)
                    if not usdc_valid:
                        logger.warning(f"üö´ Live trade blocked - USDC validation failed: {usdc_reason}")
                        result = False
                    else:
                        result = execute_live_copy_trade('BUY', token_mint, amount, price, agent=live_agent)
                else:
                    result = execute_live_copy_trade('BUY', token_mint, amount, price, agent=live_agent)
                logger.info(f"üöÄ execute_live_copy_trade result: {result}")
        # SELL: Tracked wallet sending tokens (receiver can be unknown for DEX swaps)  
        elif from_address in tracked_wallets and from_address != "unknown":
            result["wallet"] = from_address
            result["action"] = "SELL"
            logger.info(f"üî¥ SELL signal detected - tokens sent from tracked wallet {from_address[:8]}...")
            
            # CRITICAL FIX: Validate portfolio holdings before attempting to sell
            if PAPER_TRADING_ENABLED and paper_trading_available:
                # NEW: Validate that we actually have transfer data before executing paper trade
                # This prevents phantom trades during startup or webhook race conditions
                if not transfer_data:
                    logger.debug(f"üö´ Skipping paper SELL - no transfer data provided")
                    success = False
                elif not token_mint or not from_address or not to_address:
                    logger.debug(f"üö´ Skipping paper SELL - missing required transfer fields")
                    success = False
                elif amount <= 0:
                    logger.debug(f"üö´ Skipping paper SELL - invalid amount: {amount}")
                    success = False
                else:
                    # Check if we actually hold this token in our portfolio
                    try:
                        # Use unified balance lookup for reliable balance detection
                        current_balance = get_unified_token_balance(token_mint)
                        
                        if current_balance <= 0:
                            logger.info(f"üö´ No holdings found for {token_symbol} ({token_mint[:8]}...) - skipping copybot sell")
                            result["status"] = "skipped_no_holdings"
                            return result
                        
                        # Calculate how much we should sell based on our actual holdings
                        # Use the same percentage as the tracked wallet, but cap at our actual balance
                        tracked_wallet_sell_amount = amount
                        our_balance = current_balance
                        
                        # For now, sell all of our holdings (100% mirror)
                        # TODO: Could implement partial mirroring based on tracked wallet percentage
                        sell_amount = our_balance
                        
                        # Additional safety check: ensure sell amount doesn't exceed portfolio value
                        portfolio_value = get_portfolio_value()
                        position_value = sell_amount * price
                        
                        if position_value > portfolio_value * 1.1:  # Allow 10% buffer for price fluctuations
                            logger.warning(f"üö´ Sell amount ${position_value:.2f} exceeds portfolio value ${portfolio_value:.2f} - capping sell")
                            sell_amount = (portfolio_value * 0.9) / price  # Cap at 90% of portfolio value
                        
                        logger.info(f"üìä Portfolio validation: Current balance={our_balance:.6f}, Sell amount={sell_amount:.6f}, Position value=${position_value:.2f}")
                        
                        # Determine which agent is currently executing
                        current_agent = _agent_context.get_agent()
                        # Fallback to thread-based attribution if context not set
                        if current_agent == 'unknown' and hasattr(threading.current_thread(), 'agent_name'):
                            current_agent = threading.current_thread().agent_name
                        # Final fallback - determine based on context
                        if current_agent == 'unknown':
                            # This is a webhook-triggered sell from tracked wallet - should be copybot
                            current_agent = "copybot"
                            logger.info(f"üîç Determined agent as 'copybot' for tracked wallet sell")
                        
                        # CRITICAL: Validate position exists before selling
                        from src.scripts.position_validator import validate_position_exists
                        position_valid, position_reason = validate_position_exists(token_mint, sell_amount, current_agent)
                        if not position_valid:
                            logger.warning(f"üö´ Paper trade blocked - position validation failed: {position_reason}")
                            success = False
                        else:
                            success = execute_paper_trade(
                                token_address=token_mint,
                                action="SELL",
                                amount=sell_amount,
                                price=price,
                                agent=current_agent
                            )
                        if success:
                            logger.info(f"‚úÖ Paper trade executed: SELL {sell_amount:.4f} {token_symbol} @ ${price:.4f}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Paper trade failed: SELL {sell_amount:.4f} {token_symbol} @ ${price:.4f}")
                            
                    except Exception as e:
                        logger.error(f"‚ùå SELL validation error for {token_symbol}: {e}", exc_info=True)
                        result["status"] = "error_validation"
                        return result
            else:
                # Determine agent for live trade
                live_agent = _agent_context.get_agent()
                if live_agent == 'unknown' and hasattr(threading.current_thread(), 'agent_name'):
                    live_agent = threading.current_thread().agent_name
                if live_agent == 'unknown':
                    live_agent = "copybot"  # Default for webhook-triggered trades
                
                # CRITICAL: Validate position exists before live selling
                from src.scripts.position_validator import validate_position_exists
                position_valid, position_reason = validate_position_exists(token_mint, amount, live_agent)
                if not position_valid:
                    logger.warning(f"üö´ Live trade blocked - position validation failed: {position_reason}")
                    result = False
                else:
                    result = execute_live_copy_trade('SELL', token_mint, amount, price, agent=live_agent)
        elif to_address == personal_wallet:
            result["wallet"] = personal_wallet
            result["action"] = "BUY"
            logger.info(f"üõ°Ô∏è Risk signal detected - tokens sent to personal wallet")
            if PAPER_TRADING_ENABLED and paper_trading_available:
                # Apply position sizing for paper trading
                try:
                    from src.config import POSITION_SIZE_PERCENTAGE
                    
                    # Get current portfolio value
                    portfolio_value = get_portfolio_value()
                    if portfolio_value > 0:
                        # Calculate position size based on percentage of portfolio
                        max_position_value = portfolio_value * POSITION_SIZE_PERCENTAGE
                        current_trade_value = amount * price
                        
                        if current_trade_value > max_position_value:
                            # Scale down the amount to fit within position size limit
                            scaled_amount = max_position_value / price
                            logger.info(f"üìè Position sizing: Scaling risk trade from {amount:.4f} to {scaled_amount:.4f} tokens (${current_trade_value:.2f} -> ${max_position_value:.2f})")
                            amount = scaled_amount
                        else:
                            logger.info(f"üìè Position sizing: Risk trade within limits (${current_trade_value:.2f} <= ${max_position_value:.2f})")
                    else:
                        logger.warning("‚ö†Ô∏è Could not determine portfolio value for position sizing")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error in position sizing: {e}")
                
                success = execute_paper_trade(
                    token_address=token_mint,
                    action="BUY",
                    amount=amount,
                    price=price,
                    agent="risk"
                )
                if success:
                    logger.info(f"‚úÖ Paper trade executed: BUY {amount:.4f} {token_symbol} @ ${price:.4f}")
                    print_risk_status({
                        "action": "BUY",
                        "amount": amount,
                        "price": price,
                        "symbol": token_symbol,
                        "usd_value": usd_value
                    })
                else:
                    logger.warning(f"‚ö†Ô∏è Paper trade failed: BUY {amount:.4f} {token_symbol} @ ${price:.4f}")
        elif from_address == personal_wallet:
            result["wallet"] = personal_wallet
            result["action"] = "SELL"
            logger.info(f"üõ°Ô∏è Risk signal detected - tokens sent from personal wallet")
            if PAPER_TRADING_ENABLED and paper_trading_available:
                success = execute_paper_trade(
                    token_address=token_mint,
                    action="SELL",
                    amount=amount,
                    price=price,
                    agent="risk"
                )
                if success:
                    logger.info(f"‚úÖ Paper trade executed: SELL {amount:.4f} {token_symbol} @ ${price:.4f}")
                    print_risk_status({
                        "action": "SELL",
                        "amount": amount,
                        "price": price,
                        "symbol": token_symbol,
                        "usd_value": usd_value
                    })
                else:
                    logger.warning(f"‚ö†Ô∏è Paper trade failed: SELL {amount:.4f} {token_symbol} @ ${price:.4f}")
        else:
            # OPTIMIZED: Don't skip all non-matching transfers - log and return for analysis
            logger.info(f"‚ÑπÔ∏è Transfer doesn't match tracked wallets - logging for analysis")
            logger.info(f"üîé Setting MONITOR - from={from_address[:8]} in_tracked={from_address in tracked_wallets}, "
                        f"to={to_address[:8]} in_tracked={to_address in tracked_wallets}")
            result["wallet"] = "unknown"
            result["action"] = "MONITOR"
        return result
    except Exception as e:
        logger.error(f"‚ùå Error processing token transfer: {e}")
        logger.error(f"Transfer data: {transfer_data}")
        return None

def safe_print_paper_trading_status():
    """Safely print paper trading status with proper fallback logic"""
    try:
        if PAPER_TRADING_ENABLED and paper_trading_available:
            print_paper_trading_status()
        elif PAPER_TRADING_ENABLED and not paper_trading_available:
            logger.warning("‚ö†Ô∏è Paper trading enabled but module not available - showing live data with paper mode indication")
            print("üìä Paper Trading Mode (Import Error - Using Live Data)")
            print_live_trading_status()
        else:
            print_live_trading_status()
    except Exception as e:
        logger.error(f"Error in safe_print_paper_trading_status: {e}")
        print_live_trading_status()

def print_paper_trading_status():
    """Print current paper trading status to console using cloud database for synchronization"""
    try:
        # Try to get portfolio data from cloud database first for synchronization
        from src.scripts.database.cloud_database import get_cloud_database_manager
        db_manager = get_cloud_database_manager()
        
        if db_manager:
            # Get latest portfolio data from cloud database
            cloud_portfolio = db_manager.get_latest_paper_trading_portfolio()
            if cloud_portfolio:
                logger.info("üìä Using cloud database for portfolio display (synchronized)")
                _print_cloud_portfolio_status(cloud_portfolio)
                
                # Validate sync with local data
                validate_portfolio_sync()
                return
        
        # Fallback to local database if cloud is not available
        logger.info("üìä Cloud database not available, using local database")
        from src.paper_trading import print_portfolio_status
        print_portfolio_status(include_history=True)
        
    except Exception as e:
        logger.error(f"Error printing paper trading status: {e}")
        # Final fallback to local database
        try:
            from src.paper_trading import print_portfolio_status
            print_portfolio_status(include_history=True)
        except Exception as fallback_error:
            logger.error(f"Fallback portfolio display also failed: {fallback_error}")

def _calculate_webhook_win_loss_record(limit=100):
    """Calculate win/loss record from recent paper trading transactions for webhook display"""
    try:
        from src.scripts.database.cloud_database import get_cloud_database_manager
        db_manager = get_cloud_database_manager()
        if not db_manager:
            return None, None, None
            
        # Get recent transactions
        transactions = db_manager.get_paper_trading_transactions(limit=limit)
        if not transactions:
            return None, None, None
        
        # Group trades by token to match BUY/SELL pairs
        token_trades = {}
        for trade in transactions:
            token = trade.get('token_mint', '')
            action = trade.get('transaction_type', '').upper()
            price = trade.get('price_usd', 0.0)
            amount = trade.get('amount', 0.0)
            
            if token not in token_trades:
                token_trades[token] = {'buys': [], 'sells': []}
            
            if action in ['BUY', 'buy']:
                token_trades[token]['buys'].append({'price': price, 'amount': amount})
            elif action in ['SELL', 'sell']:
                token_trades[token]['sells'].append({'price': price, 'amount': amount})
        
        # Calculate wins and losses
        wins = 0
        losses = 0
        
        for token, trades in token_trades.items():
            buys = trades['buys']
            sells = trades['sells']
            
            # Only count tokens with both buys and sells (closed positions)
            if not buys or not sells:
                continue
            
            # Calculate average buy price (weighted by amount)
            total_buy_value = sum(b['price'] * b['amount'] for b in buys)
            total_buy_amount = sum(b['amount'] for b in buys)
            avg_buy_price = total_buy_value / total_buy_amount if total_buy_amount > 0 else 0
            
            # Calculate average sell price (weighted by amount)
            total_sell_value = sum(s['price'] * s['amount'] for s in sells)
            total_sell_amount = sum(s['amount'] for s in sells)
            avg_sell_price = total_sell_value / total_sell_amount if total_sell_amount > 0 else 0
            
            # Determine if this is a win or loss
            if avg_sell_price > avg_buy_price:
                wins += 1
            else:
                losses += 1
        
        # Calculate win rate
        total_trades = wins + losses
        win_rate = (wins / total_trades * 100) if total_trades > 0 else 0.0
        
        return wins, losses, win_rate
        
    except Exception as e:
        from src.scripts.logger import debug
        debug(f"Error calculating webhook win/loss record: {e}")
        return None, None, None

def _print_cloud_portfolio_status(cloud_data):
    """Print portfolio status using cloud database data"""
    try:
        from src.paper_trading import format_price
        from src import config
        from src.scripts.shared_services.optimized_price_service import get_optimized_price_service
        
        # Extract portfolio data from cloud database
        usdc_balance = cloud_data.get('usdc_balance', 0.0)
        sol_balance = cloud_data.get('sol_balance', 0.0)
        sol_value_usd = cloud_data.get('sol_value_usd', 0.0)
        staked_sol_balance = cloud_data.get('staked_sol_balance', 0.0)
        staked_sol_value_usd = cloud_data.get('staked_sol_value_usd', 0.0)
        positions_value_usd = cloud_data.get('positions_value_usd', 0.0)
        
        # Initialize price service for current market prices
        price_service = get_optimized_price_service()
        
        # Get individual positions from metadata if available
        positions = cloud_data.get('positions', {})
        if not positions and positions_value_usd > 0:
            # Try to reconstruct positions from other data
            positions = cloud_data.get('metadata', {}).get('positions', {})
        
        # Recompute position values using current market prices
        if positions:
            for token_address, position_data in list(positions.items()):
                # Skip SOL and USDC
                if token_address in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]:
                    continue
                
                if isinstance(position_data, dict):
                    amount = position_data.get('amount', 0.0)
                    if amount > 0:
                        # Get current market price
                        current_price = price_service.get_price(token_address) or position_data.get('price', 0.0)
                        positions[token_address]['price'] = current_price
                        positions[token_address]['value'] = amount * current_price
                elif isinstance(position_data, (int, float)):
                    # Legacy format: just a value, need to fetch fresh price
                    # Cannot recompute without amount, keep as-is
                    pass
            
            # Recalculate positions_value_usd from updated prices
            positions_value_usd = sum(
                p.get('value', 0) if isinstance(p, dict) else float(p)
                for addr, p in positions.items()
                if addr not in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]
            )
        
        # CRITICAL FIX: Calculate total_value dynamically from components instead of using stale cloud value
        total_value = usdc_balance + sol_value_usd + staked_sol_value_usd + positions_value_usd
        
        # Use portfolio reset flags from config instead of time-based filtering
        if PAPER_TRADING_RESET_ON_START and not positions:
            # If reset is enabled and no positions, show empty portfolio
            positions = {}
        # Otherwise, show all available positions (no time-based filtering)
        
        # Log portfolio data sync
        # DISABLED: data_sync_logger was removed in Phase 5 cleanup
        # from src.scripts.data_sync_logger import log_sync_event
        # log_sync_event('Webhook', 'PORTFOLIO_DATA_SYNC', 'success', 
        #               {'position_count': len(positions), 'total_value': positions_value_usd})
        
        # CRITICAL FIX: Only reconstruct positions from transactions if reset is NOT enabled
        # When PAPER_TRADING_RESET_ON_START = True, we should NOT reconstruct from old transactions
        if not positions and positions_value_usd > 0 and not PAPER_TRADING_RESET_ON_START:
            try:
                from src.scripts.database.cloud_database import get_cloud_database_manager
                db_manager = get_cloud_database_manager()
                if db_manager:
                    # Get recent transactions to reconstruct positions (limit to last 10 trades only)
                    recent_trades = db_manager.get_paper_trading_transactions(limit=10)
                    if recent_trades:
                        # Group by token to calculate current positions
                        token_balances = {}
                        for trade in recent_trades:
                            token = trade['token_mint']
                            amount = trade['amount']
                            price = trade['price_usd']
                            action = trade.get('action', trade.get('transaction_type', 'unknown'))
                            
                            if token not in token_balances:
                                token_balances[token] = {'amount': 0, 'price': price}
                            
                            # Handle both string and case variations
                            if action.upper() in ['BUY', 'buy']:
                                token_balances[token]['amount'] += amount
                            elif action.upper() in ['SELL', 'sell']:
                                token_balances[token]['amount'] -= amount
                        
                        # Convert to positions format (exclude SOL and USDC)
                        for token, data in token_balances.items():
                            # Skip SOL and USDC as they're handled separately
                            if token in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]:
                                continue
                            if data['amount'] > 0:  # Only include positive balances
                                positions[token] = {
                                    'amount': data['amount'],
                                    'price': data['price'],
                                    'value': data['amount'] * data['price']
                                }
            except Exception as e:
                logger.debug(f"Could not reconstruct positions: {e}")
        elif PAPER_TRADING_RESET_ON_START:
            # When reset is enabled, ensure positions are empty regardless of positions_value_usd
            positions = {}
            logger.debug("Portfolio reset enabled - not reconstructing positions from old transactions")
        
        print("\nüìä Paper Trading Portfolio Status (Cloud Sync):")
        print("==================================================")
        
        # Display SOL
        if sol_balance > 0:
            sol_pct = (sol_value_usd / total_value * 100) if total_value > 0 else 0
            print(f"‚Ä¢ SOL: {sol_balance:.4f} (${sol_value_usd:.2f} | {sol_pct:.1f}%)")
        
        # Display USDC
        if usdc_balance > 0:
            usdc_pct = (usdc_balance / total_value * 100) if total_value > 0 else 0
            print(f"‚Ä¢ USDC: {usdc_balance:.4f} (${usdc_balance:.2f} | {usdc_pct:.1f}%)")
        
        # Display Positions summary line (aggregate of all non-SOL/USDC tokens)
        if positions and len(positions) > 0:
            # Calculate total positions metrics
            position_count = len([p for p in positions.items() if p[0] not in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]])
            total_positions_value = sum(
                p[1].get('value', 0) if isinstance(p[1], dict) else float(p[1]) 
                for p in positions.items() 
                if p[0] not in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]
            )
            
            if total_positions_value > 0 and position_count > 0:
                positions_pct = (total_positions_value / total_value * 100) if total_value > 0 else 0
                position_word = "token" if position_count == 1 else "tokens"
                print(f"‚Ä¢ Positions: {position_count} {position_word} (${total_positions_value:.2f} | {positions_pct:.1f}%)")
        
        # Display Staked SOL
        if staked_sol_balance > 0:
            staked_sol_pct = (staked_sol_value_usd / total_value * 100) if total_value > 0 else 0
            print(f"‚Ä¢ Staked SOL: {staked_sol_balance:.4f} (${staked_sol_value_usd:.2f} | {staked_sol_pct:.1f}%)")
        
        # Display individual positions (exclude SOL and USDC as they're handled separately)
        if positions:
            # Sort positions by value (highest first)
            sorted_positions = sorted(positions.items(), key=lambda x: x[1].get('value', 0) if isinstance(x[1], dict) else x[1], reverse=True)
            for token_address, position_data in sorted_positions:
                # Skip SOL and USDC as they're handled separately
                if token_address in ["So11111111111111111111111111111111111111112", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"]:
                    continue
                    
                if isinstance(position_data, dict):
                    amount = position_data.get('amount', 0.0)
                    price = position_data.get('price', 0.0)
                    value = position_data.get('value', amount * price)
                else:
                    # Handle simple value format
                    value = float(position_data)
                    amount = 0.0  # Amount not available
                    price = 0.0   # Price not available
                
                if value > 0:
                    pct = (value / total_value * 100) if total_value > 0 else 0
                    token_name = token_address[:8] + "..." if len(token_address) > 8 else token_address
                    
                    if price > 0:
                        price_str = format_price(price)
                        print(f"‚Ä¢ {token_name}: {amount:.4f} @ {price_str} = ${value:.2f} ({pct:.1f}%)")
                    else:
                        print(f"‚Ä¢ {token_name}: ${value:.2f} ({pct:.1f}%)")
        
        print("==================================================")
        print(f"Total Portfolio Value: ${total_value:.2f}")
        
        # Calculate and display PnL with percentage
        initial_balance = 1000.0  # PAPER_INITIAL_BALANCE from config
        pnl = total_value - initial_balance
        pnl_pct = (pnl / initial_balance * 100) if initial_balance > 0 else 0.0
        pnl_sign = "+" if pnl >= 0 else ""
        print(f"PnL: {pnl_sign}${pnl:.2f} ({pnl_sign}{pnl_pct:.2f}%)")
        
        # Calculate and display Win/Loss record
        try:
            wins, losses, win_rate = _calculate_webhook_win_loss_record(limit=100)
            if wins is not None and losses is not None:
                total_closed = wins + losses
                if total_closed > 0:
                    print(f"Win/Loss: {wins}W-{losses}L ({win_rate:.1f}%)")
                else:
                    print(f"Win/Loss: No closed positions yet")
            else:
                print(f"Win/Loss: Data unavailable")
        except Exception as e:
            from src.scripts.logger import debug
            debug(f"Could not display win/loss record: {e}")
        
        # Show market status
        print("\nüìä Market Status:")
        print("--------------------------------------------------")
        try:
            from src.scripts.sentiment_data_extractor import get_sentiment_data_extractor
            sentiment_extractor = get_sentiment_data_extractor()
            combined_sentiment = sentiment_extractor.get_combined_sentiment_data()
            
            # Get technical analysis sentiment
            technical_sentiment = "Neutral"
            technical_color = "white"
            if combined_sentiment.chart_sentiment:
                raw_sentiment = combined_sentiment.chart_sentiment
                # Debug: Print what we're actually getting
                logger.debug(f"Chart sentiment raw: {raw_sentiment}")
                # Handle different sentiment formats with intensity-based colors
                sentiment_lower = raw_sentiment.lower()
                if 'strong' in sentiment_lower and 'bullish' in sentiment_lower:
                    technical_sentiment = "Strong Bullish"
                    technical_color = "cyan"
                elif 'strong' in sentiment_lower and 'bearish' in sentiment_lower:
                    technical_sentiment = "Strong Bearish"
                    technical_color = "red"
                elif 'bullish' in sentiment_lower:
                    technical_sentiment = "Bullish"
                    technical_color = "blue"
                elif 'bearish' in sentiment_lower:
                    technical_sentiment = "Bearish"
                    technical_color = "red"
                else:
                    technical_sentiment = "Neutral"
                    technical_color = "white"
            
            # Get Twitter sentiment
            twitter_sentiment = "Neutral"
            twitter_color = "white"
            if combined_sentiment.twitter_classification:
                raw_sentiment = combined_sentiment.twitter_classification
                # Debug: Print what we're actually getting
                logger.debug(f"Twitter sentiment raw: {raw_sentiment}")
                # Handle different sentiment formats with intensity-based colors
                sentiment_lower = raw_sentiment.lower()
                if 'strong' in sentiment_lower and 'bullish' in sentiment_lower:
                    twitter_sentiment = "Strong Bullish"
                    twitter_color = "cyan"
                elif 'strong' in sentiment_lower and 'bearish' in sentiment_lower:
                    twitter_sentiment = "Strong Bearish"
                    twitter_color = "red"
                elif 'bullish' in sentiment_lower:
                    twitter_sentiment = "Bullish"
                    twitter_color = "blue"
                elif 'bearish' in sentiment_lower:
                    twitter_sentiment = "Bearish"
                    twitter_color = "red"
                else:
                    twitter_sentiment = "Neutral"
                    twitter_color = "white"
            
            print(f"Technical: {technical_sentiment}")
            print(f"Sentiment: {twitter_sentiment}")
            
        except Exception as e:
            logger.debug(f"Could not load market status: {e}")
            print("Technical: Neutral")
            print("Sentiment: Neutral")
        print("--------------------------------------------------")
        
        # Show allocation status
        print("\nüìà Allocation Status:")
        print("--------------------------------------------------")
        sol_pct = (sol_value_usd / total_value * 100) if total_value > 0 else 0
        staked_sol_pct = (staked_sol_value_usd / total_value * 100) if total_value > 0 else 0
        usdc_pct = (usdc_balance / total_value * 100) if total_value > 0 else 0
        print(f"SOL:  Target {SOL_TARGET_PERCENT * 100}% | Actual {sol_pct:.1f}%")
        print(f"Staked SOL: Target 5.0% | Actual {staked_sol_pct:.1f}%")
        print(f"USDC: Target {USDC_TARGET_PERCENT * 100}% | Actual {usdc_pct:.1f}%")
        print("--------------------------------------------------")
        
        # Show recent trades from cloud database
        try:
            from src.scripts.database.cloud_database import get_cloud_database_manager
            db_manager = get_cloud_database_manager()
            if db_manager:
                cloud_trades = db_manager.get_paper_trading_transactions(limit=10)
                if cloud_trades and len(cloud_trades) > 0:
                    print("\nüìú Recent Trades (Cloud Sync):")
                    
                    # Calculate agent activity counts
                    from collections import Counter
                    agent_counts = Counter([t.get('agent_name', 'unknown') for t in cloud_trades])
                    summary_parts = [f"{agent.title()}: {count}" for agent, count in sorted(agent_counts.items())]
                    summary_line = "Agent Activity (Last 10 trades): " + " | ".join(summary_parts)
                    print(summary_line)
                    
                    print("--------------------------------------------------")
                    for trade in cloud_trades:
                        # Get token symbol/name and mint address
                        token_mint = trade['token_mint']
                        if token_mint == "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v":
                            token = "USDC"
                            mint_display = token_mint[:8] + "..."
                        elif token_mint == "So11111111111111111111111111111111111111112":
                            token = "SOL"
                            mint_display = token_mint[:8] + "..."
                        else:
                            # Use token_symbol if available, otherwise use first 8 chars of mint
                            token_symbol = trade.get('token_symbol', '')
                            if token_symbol and token_symbol != token_mint:
                                token = token_symbol
                                mint_display = token_mint[:8] + "..."
                            else:
                                token = token_mint[:8] + "..."
                                mint_display = token_mint[:8] + "..."
                        
                        # Get action and format properly
                        action = trade.get('action', trade.get('transaction_type', 'UNKNOWN')).upper()
                        
                        # Get amounts and values
                        amount = float(trade.get('amount', 0))
                        price = float(trade.get('price_usd', 0))
                        value = float(trade.get('value_usd', 0))
                        
                        # Format amount properly - show decimals for small amounts, integers for large amounts
                        if amount >= 1000:
                            amount_str = f"{amount:.0f}"
                        elif amount >= 1:
                            amount_str = f"{amount:.2f}"
                        else:
                            amount_str = f"{amount:.4f}"
                        
                        # Format timestamp properly (HH:MM:SS)
                        ts = trade.get('timestamp')
                        timestamp = "Recent"
                        if ts:
                            try:
                                if hasattr(ts, 'strftime'):
                                    # It's a datetime object
                                    timestamp = ts.strftime('%H:%M:%S')
                                elif isinstance(ts, str):
                                    # It's a string, try to parse it
                                    from datetime import datetime
                                    if 'T' in ts:
                                        # ISO format
                                        dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                                        timestamp = dt.strftime('%H:%M:%S')
                                    else:
                                        # Try other formats
                                        timestamp = ts[:8] if len(ts) >= 8 else ts
                                else:
                                    timestamp = str(ts)[:8]
                            except Exception:
                                timestamp = str(ts)[:8] if ts else "Recent"
                        
                        # Get agent name - prioritize agent_name field
                        agent = trade.get('agent_name', trade.get('agent', 'unknown'))
                        
                        # Format price with proper precision
                        price_str = format_price(price)
                        
                        # Print with proper formatting, including mint address
                        print(f"{timestamp} | {action} {amount_str} {token} ({mint_display}) @ {price_str} (${value:.2f}) - {agent}")
                    print("--------------------------------------------------")
                    
                    # Add timestamp
                    from datetime import datetime
                    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    print(f"üïí {current_time}")
                else:
                    print("\nüìú Recent Trades (Cloud Sync):")
                    print("--------------------------------------------------")
                    print("No recent trades available")
                    print("--------------------------------------------------")
                    
                    # Add timestamp
                    from datetime import datetime
                    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    print(f"üïí {current_time}")
            else:
                print("\nüìú Recent Trades (Cloud Sync):")
                print("--------------------------------------------------")
                print("Cloud database not available")
                print("--------------------------------------------------")
                
                # Add timestamp
                from datetime import datetime
                current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                print(f"üïí {current_time}")
        except Exception as e:
            logger.debug(f"Could not load recent trades: {e}")
            print("\nüìú Recent Trades (Cloud Sync):")
            print("--------------------------------------------------")
            print("Error loading recent trades")
            print("--------------------------------------------------")
            
            # Add timestamp
            from datetime import datetime
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"üïí {current_time}")
            
    except Exception as e:
        logger.error(f"Error printing cloud portfolio status: {e}")
        # Fallback to basic display
        print("\nüìä Paper Trading Portfolio Status (Cloud Sync):")
        print("==================================================")
        print("Error loading portfolio data from cloud database")
        print("==================================================")

def check_cloud_database_health():
    """Check cloud database connectivity and return status"""
    try:
        from src.scripts.database.cloud_database import get_cloud_database_manager
        db_manager = get_cloud_database_manager()
        if db_manager:
            # Test a simple query
            result = db_manager.get_latest_paper_trading_portfolio()
            return True, "Connected and responsive"
        return False, "No database manager available"
    except Exception as e:
        return False, f"Connection error: {e}"

def validate_trading_mode_config():
    """Validate trading mode configuration and log status"""
    import os
    print(f"PAPER_TRADING_ENABLED: {PAPER_TRADING_ENABLED}")
    print(f"paper_trading_available: {paper_trading_available}")
    print(f"Environment: {'Render' if os.getenv('RENDER') else 'Local'}")
    
    if PAPER_TRADING_ENABLED and not paper_trading_available:
        logger.warning("‚ö†Ô∏è WARNING: Paper trading enabled but module not available - falling back to live trading")
        return False
    return True

def validate_function_calls():
    """Validate that all critical function calls have correct signatures"""
    try:
        # Test the portfolio balance function call
        test_mint = "So11111111111111111111111111111111111111112"  # SOL mint
        test_wallet = get_personal_wallet_address()
        test_balance = get_balance_from_portfolio(test_mint, test_wallet)
        logger.info(f"‚úÖ Function call validation passed: get_balance_from_portfolio")
        return True
    except Exception as e:
        logger.error(f"‚ùå Function call validation failed: {e}")
        logger.error(f"‚ùå This indicates a critical function signature issue")
        return False

def monitor_processing_rate():
    """Monitor webhook processing success rate"""
    try:
        # This would typically read from logs or maintain counters
        # For now, we'll log a status message
        logger.info("üìä Processing rate monitoring active - check logs for success/failure patterns")
        logger.info("üìä Look for: 'Parsed token transfer processed successfully' vs 'Parsed token transfer not processed'")
        return True
    except Exception as e:
        logger.error(f"‚ùå Processing rate monitoring failed: {e}")
        return False

def validate_portfolio_sync():
    """Validate that main.py and webhook server show the same portfolio data"""
    try:
        from src.scripts.database.cloud_database import get_cloud_database_manager
        from src.paper_trading import get_paper_portfolio
        
        # Get cloud data
        db_manager = get_cloud_database_manager()
        if not db_manager:
            logger.warning("‚ö†Ô∏è Cloud database not available for sync validation")
            return False
            
        cloud_data = db_manager.get_latest_paper_trading_portfolio()
        if not cloud_data:
            logger.warning("‚ö†Ô∏è No cloud portfolio data available for sync validation")
            return False
        
        # Get local data
        local_portfolio = get_paper_portfolio()
        if local_portfolio.empty:
            logger.warning("‚ö†Ô∏è No local portfolio data available for sync validation")
            return False
        
        # Calculate local totals
        local_total = 0
        local_sol_balance = 0
        local_usdc_balance = 0
        local_sol_value = 0
        
        for _, row in local_portfolio.iterrows():
            token_address = row['token_address']
            amount = row['amount']
            price = row['last_price']
            value = amount * price
            local_total += value
            
            if token_address == "So11111111111111111111111111111111111111112":
                local_sol_balance = amount
                local_sol_value = value
            elif token_address == "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v":
                local_usdc_balance = amount
        
        # Compare with cloud data
        cloud_total = cloud_data.get('total_value_usd', 0.0)
        cloud_sol_balance = cloud_data.get('sol_balance', 0.0)
        cloud_usdc_balance = cloud_data.get('usdc_balance', 0.0)
        cloud_sol_value = cloud_data.get('sol_value_usd', 0.0)
        
        # Check for significant differences (allow small floating point differences)
        total_diff = abs(local_total - cloud_total)
        sol_diff = abs(local_sol_balance - cloud_sol_balance)
        usdc_diff = abs(local_usdc_balance - cloud_usdc_balance)
        
        tolerance = 0.01  # $0.01 tolerance
        
        if total_diff > tolerance or sol_diff > 0.001 or usdc_diff > 0.001:
            logger.warning(f"‚ö†Ô∏è Portfolio sync validation failed (non-blocking):")
            logger.warning(f"   Total: Local ${local_total:.2f} vs Cloud ${cloud_total:.2f} (diff: ${total_diff:.2f})")
            logger.warning(f"   SOL: Local {local_sol_balance:.4f} vs Cloud {cloud_sol_balance:.4f} (diff: {sol_diff:.4f})")
            logger.warning(f"   USDC: Local {local_usdc_balance:.4f} vs Cloud {cloud_usdc_balance:.4f} (diff: {usdc_diff:.4f})")
            return True  # Continue anyway - non-blocking
        else:
            logger.info("‚úÖ Portfolio sync validation passed - data is synchronized")
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Error validating portfolio sync: {e}")
        return False

def print_live_trading_status(include_history: bool = True):
    """Print current live trading portfolio status using the new format that matches paper trading exactly."""
    try:
        # Use the new live trading display function that matches paper trading format
        from src.live_trading_display import print_live_trading_status_cloud_sync
        print_live_trading_status_cloud_sync(include_history)
    except Exception as e:
        logger.error(f"Error printing live trading status: {e}")
        print("\nüìä Live Trading Portfolio Status:")
        print("==================================================")
        print(f"Error loading portfolio data: {e}")
        print("==================================================")

@app.route('/webhook', methods=['POST'])
def handle_webhook():
    """SIMPLIFIED WEBHOOK - Event Forwarder Only (Phase 2 Refactor)
    
    This webhook now ONLY:
    1. Parses incoming transactions
    2. Checks if they're from tracked wallets
    3. Forwards relevant events to local main.py via HTTP
    4. Optionally saves to cloud database as backup
    
    NO MORE TRADING LOGIC IN WEBHOOK!
    """
    try:
        # Parse incoming webhook data
        request_data = request.get_json()
        if not request_data:
            return jsonify({"status": "error", "message": "No JSON data provided"}), 400
        
        # Handle both list and dict formats
        events = request_data if isinstance(request_data, list) else [request_data]
        logger.info(f"üì• Webhook received: {len(events)} events")
        
        # Process events to find tracked wallet transactions
        relevant_events = []
        for event in events:
            try:
                # Extract transaction data
                transaction = event.get('transaction', {})
                account_data = event.get('accountData', [])
                
                # Check if this involves a tracked wallet
                for account in account_data:
                    address = account.get('account', '')
                    if address in WALLETS_TO_TRACK:
                        # Create simplified event for local processing
                        processed_event = {
                            'type': event.get('type', 'unknown'),
                            'transaction': {
                                'signature': transaction.get('signatures', ['unknown'])[0] if transaction.get('signatures') else 'unknown',
                                'timestamp': transaction.get('timestamp', int(time.time())),
                                'accounts': account_data
                            },
                            'tracked_wallet': address,
                            'processed_at': datetime.now().isoformat()
                        }
                        relevant_events.append(processed_event)
                        logger.info(f"üéØ Found tracked wallet transaction: {address[:8]}...")
                        break
                        
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error processing event: {e}")
                continue
        
        # Forward relevant events to local main.py
        if relevant_events:
            # Save to cloud database as backup (optional)
            try:
                from src.scripts.database.cloud_database import get_cloud_database_manager
                db = get_cloud_database_manager()
                for event in relevant_events:
                    # Save event to cloud DB for backup/recovery
                    pass  # TODO: Implement if needed
            except Exception as e:
                logger.warning(f"Cloud save failed: {e}")
            
            # Forward to local main.py via HTTP
            try:
                local_endpoint = "http://localhost:8080/webhook"  # Local main.py endpoint
                response = requests.post(
                    local_endpoint, 
                    json=relevant_events, 
                    timeout=5,
                    headers={'Content-Type': 'application/json'}
                )
                
                if response.status_code == 200:
                    logger.info(f"‚úÖ Forwarded {len(relevant_events)} events to local system")
                else:
                    logger.warning(f"‚ö†Ô∏è Local forward failed with status {response.status_code}")
                    
            except requests.exceptions.RequestException as e:
                logger.warning(f"‚ö†Ô∏è Local forward failed: {e} - events would be in cloud DB as backup")
        
        # Return success response quickly
        return jsonify({
            "status": "ok", 
            "message": "Events processed",
            "received": len(events),
            "relevant": len(relevant_events),
            "forwarded": len(relevant_events) if relevant_events else 0
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Webhook error: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

# DISABLED: Old complex webhook processing function - replaced with simple forwarder above
# The old _process_webhook_events function has been removed - all that complex trading
# logic is now handled by the local main.py coordinator instead of in the webhook.

def _process_webhook_events(events):
    """DISABLED: Old complex webhook processing function (Phase 2 Refactor)
    
    This massive function (450+ lines) contained all the complex trading logic that was causing problems:
    - Agent initialization and coordination  
    - Complex validation layers
    - Direct trading execution via execute_paper_trade() and execute_live_copy_trade()
    - Portfolio management and monitoring
    - Risk agent triggers
    - Harvesting agent triggers
    - Complex allocation checks
    
    All of this complexity has been moved to the local main.py coordinator.
    The webhook now only forwards events - it doesn't trade!
    """
    logger.warning("‚ö†Ô∏è _process_webhook_events is DISABLED - webhook now only forwards events to local main.py")
    return False

# END OF DISABLED FUNCTION - All complex trading logic removed

@app.route('/queue/status', methods=['GET'])
def get_queue_status():
        total_transfers_found = 0
        total_transfers_processed = 0
        
        for i, event in enumerate(events):
            # Skip failed transactions to avoid false positives/noise
            try:
                if isinstance(event, dict) and event.get('meta', {}).get('err'):
                    logger.info("‚è≠Ô∏è Skipping failed transaction (meta.err present)")
                    continue
            except Exception:
                pass
            logger.info(f"üîç Processing event {i+1}/{len(events)}")
            logger.info(f"üìã Event keys: {list(event.keys()) if isinstance(event, dict) else 'Not a dict'}")
            logger.info(f"üìã Event structure analysis for event {i+1}:")
            logger.info(f"  Event keys: {list(event.keys())}")
            
            # Always parse SPL and SOL transfers
            token_transfers = parse_solana_transaction(event)
            logger.info(f"  üìä Parsed {len(token_transfers)} token transfers from event {i+1}")
            total_transfers_found += len(token_transfers)
            
            for k, transfer in enumerate(token_transfers):
                logger.info(f"    üîç Processing parsed token transfer {k+1}")
                
                # CRITICAL: Check for duplicate events to prevent over-execution
                if _is_duplicate_event(transfer):
                    logger.warning(f"üö´ Skipping duplicate token transfer {k+1} - already processed")
                    continue
                
                # Log the execution attempt
                try:
                    from src.scripts.database.execution_tracker import log_execution
                    log_execution(
                        agent_type="webhook_handler",
                        wallet_address=transfer.get('toUserAccount', 'unknown'),
                        action="PROCESS_TRANSFER",
                        token_mint=transfer.get('tokenMint'),
                        amount=float(transfer.get('amount', 0)) / (10 ** transfer.get('decimals', 0)),
                        metadata={"transfer_data": transfer, "event_type": "token_transfer"}
                    )
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to log execution: {e}")
                
                result = process_token_transfer(transfer)
                if result:
                    logger.info(f"    ‚úÖ Parsed token transfer processed successfully")
                    processed_events.append(result)
                    total_transfers_processed += 1
                    
                    # CRITICAL FIX: Mark transaction as confirmed to prevent re-execution
                    if 'signature' in transfer:
                        _mark_transaction_confirmed(transfer['signature'])
                else:
                    logger.info(f"    ‚ùå Parsed token transfer not processed")
            
            sol_transfers = parse_native_sol_transfers(event)
            logger.info(f"  üìä Parsed {len(sol_transfers)} SOL transfers from event {i+1}")
            total_transfers_found += len(sol_transfers)
            
            for k, transfer in enumerate(sol_transfers):
                logger.info(f"    üîç Processing parsed SOL transfer {k+1}")
                
                # CRITICAL: Check for duplicate events to prevent over-execution
                if _is_duplicate_event(transfer):
                    logger.warning(f"üö´ Skipping duplicate SOL transfer {k+1} - already processed")
                    continue
                
                result = process_token_transfer(transfer)
                if result:
                    logger.info(f"    ‚úÖ Parsed SOL transfer processed successfully")
                    processed_events.append(result)
                    total_transfers_processed += 1
                    
                    # CRITICAL FIX: Mark transaction as confirmed to prevent re-execution
                    if 'signature' in transfer:
                        _mark_transaction_confirmed(transfer['signature'])
                else:
                    logger.info(f"    ‚ùå Parsed SOL transfer not processed")
            
            # CRITICAL FIX: Detect tracked wallet activity from balance changes
            tracked_transfers = detect_tracked_wallet_activity(event)
            logger.info(f"  üéØ Found {len(tracked_transfers)} tracked wallet transfers from event {i+1}")
            total_transfers_found += len(tracked_transfers)
            
            for k, transfer in enumerate(tracked_transfers):
                logger.info(f"    üéØ Processing tracked wallet transfer {k+1}")
                
                # CRITICAL: Check for duplicate events to prevent over-execution
                if _is_duplicate_event(transfer):
                    logger.warning(f"üö´ Skipping duplicate tracked wallet transfer {k+1} - already processed")
                    continue
                
                result = process_token_transfer(transfer)
                if result:
                    logger.info(f"    ‚úÖ Tracked wallet transfer processed successfully")
                    processed_events.append(result)
                    total_transfers_processed += 1
                else:
                    logger.info(f"    ‚ùå Tracked wallet transfer not processed")
            
            # Also check for legacy fields
            if 'transaction' in event and 'tokenTransfers' in event['transaction']:
                logger.info(f"  üîÑ Found legacy tokenTransfers: {len(event['transaction']['tokenTransfers'])}")
                total_transfers_found += len(event['transaction']['tokenTransfers'])
                for k, transfer in enumerate(event['transaction']['tokenTransfers']):
                        logger.info(f"    üîç Processing legacy token transfer {k+1}")
                        result = process_token_transfer(transfer)
                        if result:
                            logger.info(f"    ‚úÖ Legacy token transfer processed successfully")
                            processed_events.append(result)
                            total_transfers_processed += 1
                        else:
                            logger.info(f"    ‚ùå Legacy token transfer not processed")
            if 'transaction' in event and 'nativeTransfers' in event['transaction']:
                logger.info(f"  üîÑ Found legacy nativeTransfers: {len(event['transaction']['nativeTransfers'])}")
                total_transfers_found += len(event['transaction']['nativeTransfers'])
                for k, transfer in enumerate(event['transaction']['nativeTransfers']):
                        logger.info(f"    üîç Processing legacy native transfer {k+1}")
                        sol_transfer = {
                            'tokenMint': 'So11111111111111111111111111111111111111112',
                            'fromUserAccount': transfer['fromUserAccount'],
                            'toUserAccount': transfer['toUserAccount'],
                            'amount': transfer['amount'],
                            'decimals': 9,
                            'tokenName': 'Solana',
                            'tokenSymbol': 'SOL'
                        }
                        result = process_token_transfer(sol_transfer)
                        if result:
                            logger.info(f"    ‚úÖ Legacy native transfer processed successfully")
                            processed_events.append(result)
                            total_transfers_processed += 1
                        else:
                            logger.info(f"    ‚ùå Legacy native transfer not processed")
            if 'accountData' in event:
                logger.info(f"üìä Found accountData in event {i+1}")
                for j, account in enumerate(event['accountData']):
                    logger.info(f"  üìã Account {j+1} keys: {list(account.keys())}")
                    if 'tokenTransfers' in account:
                        logger.info(f"  üîÑ Found {len(account['tokenTransfers'])} token transfers")
                        total_transfers_found += len(account['tokenTransfers'])
                        for k, transfer in enumerate(account['tokenTransfers']):
                            logger.info(f"    üîç Processing token transfer {k+1}")
                            result = process_token_transfer(transfer)
                            if result:
                                logger.info(f"    ‚úÖ Token transfer processed successfully")
                                processed_events.append(result)
                                total_transfers_processed += 1
                            else:
                                logger.info(f"    ‚ùå Token transfer not processed")
                    if 'nativeTransfers' in account:
                        logger.info(f"  üîÑ Found {len(account['nativeTransfers'])} native transfers")
                        total_transfers_found += len(account['nativeTransfers'])
                        for k, transfer in enumerate(account['nativeTransfers']):
                            logger.info(f"    üîç Processing native transfer {k+1}")
                            sol_transfer = {
                                'tokenMint': 'So11111111111111111111111111111111111111112',
                                'fromUserAccount': transfer['fromUserAccount'],
                                'toUserAccount': transfer['toUserAccount'],
                                'amount': transfer['amount'],
                                'decimals': 9,
                                'tokenName': 'Solana',
                                'tokenSymbol': 'SOL'
                            }
                            result = process_token_transfer(sol_transfer)
                            if result:
                                logger.info(f"    ‚úÖ Native transfer processed successfully")
                                processed_events.append(result)
                                total_transfers_processed += 1
                            else:
                                logger.info(f"    ‚ùå Native transfer not processed")
            if 'meta' in event:
                meta = event['meta']
                logger.info(f"üìä Found meta data with keys: {list(meta.keys())}")
                if 'postTokenBalances' in meta or 'preTokenBalances' in meta:
                    logger.info(f"  üîÑ Found token balance changes in meta")
                    if 'transaction' in event:
                        token_transfers = parse_solana_transaction(event)
                        logger.info(f"  üìä Meta parsing found {len(token_transfers)} token transfers")
                        total_transfers_found += len(token_transfers)
                        for k, transfer in enumerate(token_transfers):
                            logger.info(f"    üîç Processing parsed token transfer {k+1}")
                            
                            # Backfill owner addresses from meta data if missing
                            if not transfer.get('fromUserAccountOwner') and not transfer.get('toUserAccountOwner'):
                                meta = event.get('meta', {})
                                if 'preTokenBalances' in meta and 'postTokenBalances' in meta:
                                    # Try to resolve from account index
                                    from_account = transfer.get('fromUserAccount')
                                    to_account = transfer.get('toUserAccount')
                                    
                                    # Look for account index in pre/post balances
                                    for balance in meta.get('preTokenBalances', []):
                                        if balance.get('mint') == transfer.get('tokenMint'):
                                            account_index = balance.get('accountIndex')
                                            if account_index is not None:
                                                owner = _owner_for_account(account_index, event)
                                                if owner:
                                                    if from_account == balance.get('owner'):
                                                        transfer['fromUserAccountOwner'] = owner
                                                    if to_account == balance.get('owner'):
                                                        transfer['toUserAccountOwner'] = owner
                                    
                                    for balance in meta.get('postTokenBalances', []):
                                        if balance.get('mint') == transfer.get('tokenMint'):
                                            account_index = balance.get('accountIndex')
                                            if account_index is not None:
                                                owner = _owner_for_account(account_index, event)
                                                if owner:
                                                    if from_account == balance.get('owner'):
                                                        transfer['fromUserAccountOwner'] = owner
                                                    if to_account == balance.get('owner'):
                                                        transfer['toUserAccountOwner'] = owner
                            
                            result = process_token_transfer(transfer)
                            if result:
                                logger.info(f"    ‚úÖ Parsed token transfer processed successfully")
                                processed_events.append(result)
                                total_transfers_processed += 1
                            else:
                                logger.info(f"    ‚ùå Parsed token transfer not processed")
                        sol_transfers = parse_native_sol_transfers(event)
                        logger.info(f"  üìä Meta parsing found {len(sol_transfers)} SOL transfers")
                        total_transfers_found += len(sol_transfers)
                        for k, transfer in enumerate(sol_transfers):
                            logger.info(f"    üîç Processing parsed SOL transfer {k+1}")
                            result = process_token_transfer(transfer)
                            if result:
                                logger.info(f"    ‚úÖ Parsed SOL transfer processed successfully")
                                processed_events.append(result)
                                total_transfers_processed += 1
                            else:
                                logger.info(f"    ‚ùå Parsed SOL transfer not processed")
                    if 'postTokenBalances' in meta:
                        for balance in meta['postTokenBalances']:
                            logger.info(f"    üìä Post balance for mint: {balance.get('mint', 'Unknown')} - Amount: {balance.get('uiTokenAmount', {}).get('uiAmount', 'Unknown')}")
                    if 'preTokenBalances' in meta:
                        for balance in meta['preTokenBalances']:
                            logger.info(f"    üìä Pre balance for mint: {balance.get('mint', 'Unknown')} - Amount: {balance.get('uiTokenAmount', {}).get('uiAmount', 'Unknown')}")
            if 'tokenTransfers' in event:
                logger.info(f"üìä Found tokenTransfers directly in event")
                logger.info(f"üìä Full tokenTransfers: {json.dumps(event['tokenTransfers'], indent=2)}")
                total_transfers_found += len(event['tokenTransfers'])
                for k, transfer in enumerate(event['tokenTransfers']):
                    logger.info(f"    üîç Processing token transfer {k+1}")
                    result = process_token_transfer(transfer)
                    if result:
                        logger.info(f"    ‚úÖ Token transfer processed successfully")
                        processed_events.append(result)
                        total_transfers_processed += 1
                    else:
                        logger.info(f"    ‚ùå Token transfer not processed")
            if 'nativeTransfers' in event:
                logger.info(f"üìä Found nativeTransfers directly in event")
                logger.info(f"üìä Full nativeTransfers: {json.dumps(event['nativeTransfers'], indent=2)}")
                total_transfers_found += len(event['nativeTransfers'])
                for k, transfer in enumerate(event['nativeTransfers']):
                    logger.info(f"    üîç Processing native transfer {k+1}")
                    sol_transfer = {
                        'tokenMint': 'So11111111111111111111111111111111111111112',
                        'fromUserAccount': transfer['fromUserAccount'],
                        'toUserAccount': transfer['toUserAccount'],
                        'amount': transfer['amount'],
                        'decimals': 9,
                        'tokenName': 'Solana',
                        'tokenSymbol': 'SOL'
                    }
                    result = process_token_transfer(sol_transfer)
                    if result:
                        logger.info(f"    ‚úÖ Native transfer processed successfully")
                        processed_events.append(result)
                        total_transfers_processed += 1
                    else:
                        logger.info(f"    ‚ùå Native transfer not processed")
        
        # CRITICAL FIX: Enhanced logging for transfer processing summary
        logger.info(f"üìä TRANSFER PROCESSING SUMMARY:")
        logger.info(f"  Total transfers found: {total_transfers_found}")
        logger.info(f"  Total transfers processed: {total_transfers_processed}")
        logger.info(f"  Processing success rate: {(total_transfers_processed/total_transfers_found*100):.1f}%" if total_transfers_found > 0 else "N/A")
        logger.info(f"üìä Total processed events: {len(processed_events)}")
        
        wallet_events = {}
        for event in processed_events:
            wallet = event['wallet']
            if wallet not in wallet_events:
                wallet_events[wallet] = []
            wallet_events[wallet].append(event)
        logger.info(f"üìã Affected wallets: {list(wallet_events.keys())}")
        
        # AGENT TRIGGER PATCH: Always trigger agents for each wallet and event
        for wallet, events in wallet_events.items():
            logger.info(f"üîç Processing {len(events)} events for wallet {wallet[:8]}...")
            if is_personal_wallet(wallet):
                logger.info(f"üõ°Ô∏è Personal wallet activity detected: {wallet[:8]}...")
                if WEBHOOK_ACTIVE_AGENTS.get('risk', False):
                    if not risk_agent:
                        logger.info("üîÑ Initializing Risk Agent...")
                        initialize_risk_agent()
                    if risk_agent:
                        risk_agent.last_webhook_time = time.time()
                        for event in events:
                            try:
                                logger.info(f"üõ°Ô∏è Triggering Risk Agent for event")
                                risk_agent.handle_webhook_trigger(event)
                            except Exception as e:
                                logger.error(f"‚ùå Error in risk agent webhook trigger: {e}")
                                logger.info("üîÑ Risk agent continuing to monitor despite error")
                if WEBHOOK_ACTIVE_AGENTS.get('harvesting', False):
                    if not harvesting_agent:
                        logger.info("üîÑ Initializing Harvesting Agent...")
                        initialize_harvesting_agent()
                    if harvesting_agent:
                        for event in events:
                            try:
                                logger.info(f"üåæ Triggering Harvesting Agent for event")
                                harvesting_agent.handle_webhook_trigger(event)
                            except Exception as e:
                                logger.error(f"‚ùå Error in harvesting agent webhook trigger: {e}")
                
                # Trigger staking agent for personal wallet transactions (if staking operations are needed)
                if WEBHOOK_ACTIVE_AGENTS.get('staking', False):
                    if not staking_agent:
                        logger.info("üîÑ Initializing Staking Agent...")
                        initialize_staking_agent()
                    if staking_agent:
                        for event in events:
                            try:
                                logger.info(f"üîí Triggering Staking Agent for event")
                                if hasattr(staking_agent, 'handle_webhook_trigger'):
                                    staking_agent.handle_webhook_trigger(event)
                                else:
                                    logger.info("‚ÑπÔ∏è Staking agent webhook trigger method not available")
                            except Exception as e:
                                logger.error(f"‚ùå Error in staking agent webhook trigger: {e}")
            else:
                logger.info(f"üë• Copybot wallet activity detected: {wallet[:8]}...")
                if copybot_agent:
                    token_changes = {}
                    for event in events:
                        token_changes[event['token']] = {
                            "action": event['action'],
                            "amount": event['amount'],
                            "price": event['price'],
                            "usd_value": event['usd_value'],
                            "symbol": event['symbol'],
                            "name": event['name']
                        }
                    changes = {
                        wallet: {
                            "tokens": token_changes
                        }
                    }
                    logger.info(f"üë• Triggering CopyBot for changes: {changes}")
                    trigger_copybot_for_changes(wallet, changes)
        # CRITICAL ADDITION: Detect and record capital flows for accurate PnL calculations
        try:
            from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
            portfolio_tracker = get_portfolio_tracker()
            
            # Create a consolidated transaction data structure for capital flow detection
            consolidated_transaction = {
                'transfers': []
            }
            
            # Add all processed transfers to the consolidated structure
            for event in processed_events:
                if 'token' in event and 'action' in event:
                    transfer = {
                        'fromUserAccount': event.get('from_wallet', 'unknown'),
                        'toUserAccount': event.get('wallet', 'unknown'),
                        'tokenMint': event['token'],
                        'amount': event.get('amount', 0),
                        'decimals': event.get('decimals', 9),
                        'signature': event.get('signature', 'unknown')
                    }
                    
                    # Adjust for BUY/SELL actions
                    if event['action'] == 'BUY':
                        transfer['fromUserAccount'] = 'unknown'  # External source
                        transfer['toUserAccount'] = event['wallet']
                    elif event['action'] == 'SELL':
                        transfer['fromUserAccount'] = event['wallet']
                        transfer['toUserAccount'] = 'unknown'  # External destination
                    
                    consolidated_transaction['transfers'].append(transfer)
            
            # Detect and record capital flows
            if consolidated_transaction['transfers']:
                portfolio_tracker.detect_and_record_capital_flows(consolidated_transaction)
                
        except Exception as e:
            logger.error(f"‚ùå Error detecting capital flows: {e}")
        
        logger.info("Post-Event Portfolio State:")
        safe_print_paper_trading_status()
        response_data = {
            "status": "success", 
            "processed_events": len(processed_events),
            "affected_wallets": list(wallet_events.keys()),
            "total_transfers_found": total_transfers_found,
            "total_transfers_processed": total_transfers_processed
        }
        logger.info(f"üì§ Webhook response: {response_data}")
        return jsonify(response_data), 200
    except Exception as e:
        logger.error(f"‚ùå Error handling webhook: {e}")
        logger.error(f"Request data: {request.json if request.is_json else 'Not JSON'}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/queue/status', methods=['GET'])
def get_queue_status():
    """Get request queue status and statistics"""
    try:
        # Check if queue processor is running
        processor_alive = _queue_processor_thread.is_alive() if _queue_processor_thread else False
        
        # If not running, try to start it
        if not processor_alive:
            logger.warning("‚ö†Ô∏è Queue processor not running, attempting to restart...")
            try:
                _start_queue_processor()
                processor_alive = _queue_processor_thread.is_alive() if _queue_processor_thread else False
                logger.info(f"‚úÖ Queue processor restart {'successful' if processor_alive else 'failed'}")
            except Exception as e:
                logger.error(f"‚ùå Failed to restart queue processor: {e}")
        
        return jsonify({
            "status": "success",
            "queue_stats": _queue_stats,
            "queue_size": _request_queue.qsize(),
            "queue_processing": _queue_processing,
            "processor_alive": processor_alive,
            "processor_thread": str(_queue_processor_thread) if _queue_processor_thread else None
        })
    except Exception as e:
        logger.error(f"‚ùå Error getting queue status: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/queue/clear', methods=['POST'])
def clear_queue():
    """Clear the request queue"""
    try:
        cleared_count = 0
        while not _request_queue.empty():
            try:
                _request_queue.get_nowait()
                _request_queue.task_done()
                cleared_count += 1
            except queue.Empty:
                break
        
        _queue_stats['current_queue_size'] = 0
        logger.info(f"üßπ Cleared {cleared_count} requests from queue")
        
        return jsonify({
            "status": "success",
            "cleared_count": cleared_count,
            "message": f"Cleared {cleared_count} requests from queue"
        })
    except Exception as e:
        logger.error(f"‚ùå Error clearing queue: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/', methods=['GET'])
def health_check():
    """Enhanced health check endpoint with agent status"""
    # Get fresh wallet list
    current_wallets = get_current_wallets_to_track()
    personal_wallet = get_personal_wallet_address()
    
    # WebSocket status
    websocket_status = "available" if realtime_monitoring_available else "unavailable"
    monitoring_status = "active" if _realtime_monitoring_active else "inactive"
    
    return jsonify({
        "status": "healthy",
        "service": "Webhook Handler v2.0",
        "timestamp": time.time(),
        "wallets_tracked": len(current_wallets),
        "personal_wallet": f"{personal_wallet[:8]}..." if personal_wallet else "not configured",
        "personal_wallet_tracked": personal_wallet in current_wallets if personal_wallet else False,
        "agents": {
            "copybot": copybot_agent is not None,
            "risk": risk_agent is not None,
            "harvesting": harvesting_agent is not None,
            "staking": staking_agent is not None
        },
        "pending_changes": len(wallet_changes) if 'wallet_changes' in globals() else 0,
        "paper_trading": True,
        "websocket_status": websocket_status,
        "realtime_monitoring": monitoring_status,
        "websocket_endpoint": WEBSOCKET_ENDPOINT if 'WEBSOCKET_ENDPOINT' in locals() else None,
        "request_queue": {
            "enabled": True,
            "size": _request_queue.qsize(),
            "processing": _queue_processing,
            "stats": _queue_stats
        }
    })

@app.route('/test', methods=['GET'])
def test_connectivity():
    """Basic connectivity test endpoint"""
    return jsonify({
        "status": "success",
        "message": "Webhook server is running and responding",
        "timestamp": time.time(),
        "endpoints": {
            "health": "/",
            "test_webhook": "/test-webhook",
            "test_live": "/test-live", 
            "test_solana": "/test-solana",
            "test_status": "/test-status",
            "test_websocket": "/test-websocket"
        }
    })

@app.route('/test-webhook', methods=['POST'])
def test_webhook_event():
    """Test endpoint that simulates a webhook event"""
    try:
        # Create a test webhook event
        test_event = {
            "blockTime": int(time.time()),
            "indexWithinBlock": 0,
            "meta": {
                "preTokenBalances": [
                    {
                        "mint": "So11111111111111111111111111111111111111112",
                        "owner": "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt",
                        "uiTokenAmount": {
                            "uiAmount": 1.0,
                            "decimals": 9
                        }
                    }
                ],
                "postTokenBalances": [
                    {
                        "mint": "So11111111111111111111111111111111111111112", 
                        "owner": "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt",
                        "uiTokenAmount": {
                            "uiAmount": 0.5,
                            "decimals": 9
                        }
                    }
                ]
            },
            "slot": 354740529,
            "transaction": {
                "message": {
                    "accountKeys": [
                        "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt",
                        "4D35YvGcpAeZZ72kXV7UwJDdyyVfoSckLiUWQNE2tZDs"
                    ],
                    "instructions": [
                        {
                            "programIdIndex": 0,
                            "accounts": [0, 1],
                            "data": "3Bxs412MvVNQj175..."
                        }
                    ]
                },
                "signatures": ["test_signature_123456789"]
            },
            "version": "legacy"
        }
        
        # Process the test event
        logger.info("üß™ TEST: Processing test webhook event")
        result = handle_webhook_test([test_event])
        
        return jsonify({
            "status": "success",
            "message": "Test webhook event processed",
            "test_event": test_event,
            "result": result,
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in test webhook: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/test-ui', methods=['GET'])
def test_ui():
    """Simple HTML page with buttons to POST to test endpoints and manage wallets."""
    try:
        return (
            """
            <!doctype html>
            <html lang="en">
            <head>
                <meta charset="utf-8" />
                <title>Webhook Test UI & Wallet Management</title>
                <style>
                  body { font-family: Arial, sans-serif; margin: 24px; }
                  button { padding: 8px 14px; margin: 6px 0; }
                  .card { border: 1px solid #ddd; padding: 16px; margin-bottom: 16px; border-radius: 6px; }
                  pre { background: #f8f8f8; padding: 12px; border-radius: 6px; overflow:auto; }
                  input { padding: 6px; margin: 4px; width: 300px; }
                  .wallet-input { display: flex; align-items: center; gap: 8px; }
                  .success { color: green; }
                  .error { color: red; }
                  .warning { color: orange; }
                </style>
                <script>
                  async function post(path, data = null) {
                    const options = { method: 'POST' };
                    if (data) {
                      options.headers = { 'Content-Type': 'application/json' };
                      options.body = JSON.stringify(data);
                    }
                    const res = await fetch(path, options);
                    const text = await res.text();
                    const out = document.getElementById('output');
                    out.textContent = text;
                  }
                  
                  async function addWallet() {
                    const wallet = document.getElementById('newWallet').value.trim();
                    if (!wallet) {
                      alert('Please enter a wallet address');
                      return;
                    }
                    await post('/add-wallet', { wallet: wallet });
                    document.getElementById('newWallet').value = '';
                  }
                  
                  async function removeWallet() {
                    const wallet = document.getElementById('removeWallet').value.trim();
                    if (!wallet) {
                      alert('Please enter a wallet address');
                      return;
                    }
                    await post('/remove-wallet', { wallet: wallet });
                    document.getElementById('removeWallet').value = '';
                  }
                  
                  async function listWallets() {
                    const res = await fetch('/list-wallets');
                    const data = await res.json();
                    const out = document.getElementById('output');
                    if (data.status === 'success') {
                      out.textContent = `Tracked Wallets (${data.total_tracked}):\\n${data.wallets.join('\\n')}`;
                    } else {
                      out.textContent = `Error: ${data.message}`;
                    }
                  }
                  
                  async function refreshWallets() {
                    await post('/refresh-wallets');
                  }
                  
                  async function fetchWalletData() {
                    const wallet = document.getElementById('fetchWallet').value.trim();
                    if (!wallet) {
                      alert('Please enter a wallet address');
                      return;
                    }
                    await post('/fetch-wallet-data', { wallet: wallet });
                    document.getElementById('fetchWallet').value = '';
                  }
                  
                  async function checkWalletStatus() {
                    const res = await fetch('/wallet-status');
                    const data = await res.json();
                    const out = document.getElementById('output');
                    if (data.status === 'success') {
                      const config = data.wallet_configuration;
                      out.textContent = `Wallet Status:\\n\\nPersonal Wallet: ${config.personal_wallet}\\nTracked Wallets: ${config.total_tracked}\\nHelius Status: ${config.helius_webhook_status}\\n\\nTracked Addresses:\\n${config.tracked_wallets.join('\\n')}`;
                    } else {
                      out.textContent = `Error: ${data.message}`;
                    }
                  }
                </script>
            </head>
            <body>
              <h2>Webhook Test UI & Wallet Management</h2>
              
              <div class="card">
                <h3>üîÑ Dynamic Wallet Management</h3>
                <div class="wallet-input">
                  <input type="text" id="newWallet" placeholder="Enter wallet address to add..." />
                  <button onclick="addWallet()">Add Wallet</button>
                </div>
                <div class="wallet-input">
                  <input type="text" id="removeWallet" placeholder="Enter wallet address to remove..." />
                  <button onclick="removeWallet()">Remove Wallet</button>
                </div>
                <div class="wallet-input">
                  <input type="text" id="fetchWallet" placeholder="Enter wallet address to fetch data..." />
                  <button onclick="fetchWalletData()">Fetch Data</button>
                </div>
                <button onclick="listWallets()">üìã List Current Wallets</button>
                <button onclick="refreshWallets()">üîÑ Refresh Wallet List</button>
                <button onclick="checkWalletStatus()">üìä Check Wallet Status</button>
              </div>
              
              <div class="card">
                <h3>üß™ Agent Testing</h3>
                <button onclick="post('/test-live')">Run Live Test (/test-live)</button>
                <button onclick="post('/test-webhook')">Send Test Webhook (/test-webhook)</button>
                <a href="/test-status" target="_blank"><button>Check Test Status</button></a>
              </div>
              
              <h3>Response</h3>
              <pre id="output">Click a button to run a test or manage wallets‚Ä¶</pre>
            </body>
            </html>
            """,
            200,
            {"Content-Type": "text/html"}
        )
    except Exception as e:
        logger.error(f"‚ùå Error rendering test UI: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/test-live', methods=['POST', 'GET'])
def test_live_agent_trigger():
    """Test endpoint that triggers live agent actions"""
    try:
        # Get tracked wallets
        tracked_wallets = get_current_wallets_to_track()
        personal_wallet = get_personal_wallet_address()
        
        # Create a realistic test event that will trigger agents
        test_events = []
        
        # Test 1: SOL transfer from tracked wallet (should trigger CopyBot)
        if tracked_wallets:
            test_wallet = list(tracked_wallets)[0]
            sol_event = {
                "blockTime": int(time.time()),
                "slot": 354740529,
                "transaction": {
                    "message": {
                        "accountKeys": [
                            test_wallet,
                            "4D35YvGcpAeZZ72kXV7UwJDdyyVfoSckLiUWQNE2tZDs"
                        ]
                    },
                    "signatures": [f"test_sol_transfer_{int(time.time())}"]
                },
                "meta": {
                    "preBalances": [1000000000, 0],  # 1 SOL, 0 SOL
                    "postBalances": [500000000, 500000000],  # 0.5 SOL each
                    "preTokenBalances": [],
                    "postTokenBalances": []
                }
            }
            test_events.append(sol_event)
        
        # Test 2: Native SOL transfer to personal wallet (guarantees Risk/Harvesting trigger)
        if personal_wallet and tracked_wallets:
            source_wallet = list(tracked_wallets)[0]
            sol_to_personal = {
                "blockTime": int(time.time()),
                "slot": 354740530,
                "transaction": {
                    "message": {
                        "accountKeys": [
                            source_wallet,
                            personal_wallet
                        ]
                    },
                    "signatures": [f"test_sol_to_personal_{int(time.time())}"]
                },
                "meta": {
                    "preBalances": [600000000, 0],  # 0.6 SOL, 0 SOL
                    "postBalances": [500000000, 100000000],  # 0.5 SOL, 0.1 SOL
                    "preTokenBalances": [],
                    "postTokenBalances": []
                }
            }
            test_events.append(sol_to_personal)
        
        logger.info(f"üß™ LIVE TEST: Processing {len(test_events)} test events to trigger agents")
        
        # Process events through the main webhook handler
        result = handle_webhook_test(test_events)
        
        return jsonify({
            "status": "success",
            "message": f"Live test completed with {len(test_events)} events",
            "events_processed": len(test_events),
            "result": result,
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in live test: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/test-solana', methods=['POST'])
def test_solana_transaction():
    """Test endpoint that simulates a real Solana transaction"""
    try:
        # Create a realistic Solana transaction event
        solana_event = {
            "blockTime": int(time.time()),
            "indexWithinBlock": 0,
            "meta": {
                "err": None,
                "fee": 5000,
                "preBalances": [1000000000, 0],  # 1 SOL, 0 SOL
                "postBalances": [500000000, 500000000],  # 0.5 SOL each
                "preTokenBalances": [
                    {
                        "accountIndex": 2,
                        "mint": "6jtS916EFxUXtjPUDFn6pKSuVezX6vQ2S3FrQVBM98ZG",
                        "owner": "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt",
                        "uiTokenAmount": {
                            "uiAmount": 29447360.0,
                            "decimals": 6
                        }
                    }
                ],
                "postTokenBalances": [
                    {
                        "accountIndex": 3,
                        "mint": "6jtS916EFxUXtjPUDFn6pKSuVezX6vQ2S3FrQVBM98ZG", 
                        "owner": "WLHv2UAZm6z4KyaaELi5pjdbJh6RESMva1Rnn8pJVVh",
                        "uiTokenAmount": {
                            "uiAmount": 29447360.0,
                            "decimals": 6
                        }
                    }
                ],
                "innerInstructions": [],
                "logMessages": [
                    "Program 11111111111111111111111111111111 invoke [1]",
                    "Program 11111111111111111111111111111111 success"
                ]
            },
            "slot": 354740529,
            "transaction": {
                "message": {
                    "accountKeys": [
                        "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt",
                        "WLHv2UAZm6z4KyaaELi5pjdbJh6RESMva1Rnn8pJVVh",
                        "TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA",
                        "11111111111111111111111111111111"
                    ],
                    "header": {
                        "numReadonlySignedAccounts": 0,
                        "numReadonlyUnsignedAccounts": 1,
                        "numRequiredSignatures": 1
                    },
                    "instructions": [
                        {
                            "accounts": [0, 1, 2, 3],
                            "data": "3Bxs412MvVNQj175...",
                            "programIdIndex": 2
                        }
                    ],
                    "recentBlockhash": "test_blockhash_123456789"
                },
                "signatures": [f"test_solana_tx_{int(time.time())}"]
            },
            "version": "legacy"
        }
        
        logger.info("üß™ SOLANA TEST: Processing realistic Solana transaction")
        result = handle_webhook_test([solana_event])
        
        return jsonify({
            "status": "success", 
            "message": "Solana transaction test completed",
            "transaction": solana_event,
            "result": result,
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in Solana test: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/test-status', methods=['GET'])
def test_webhook_status():
    """Test endpoint to check webhook registration status"""
    try:
        status = {
            "webhook_server": {
                "status": "running",
                "port": WEBHOOK_PORT,
                "host": WEBHOOK_HOST,
                "url": f"http://{WEBHOOK_HOST}:{WEBHOOK_PORT}",
                "webhook_url": webhook_url
            },
            "helius_integration": {
                "api_key_configured": bool(HELIUS_API_KEY),
                "api_key_preview": HELIUS_API_KEY[:8] + "..." if HELIUS_API_KEY else "not set"
            },
            "wallets": {
                "personal_wallet": get_personal_wallet_address(),
                "tracked_wallets": list(get_current_wallets_to_track()),
                "total_tracked": len(get_current_wallets_to_track())
            },
            "agents": {
                "copybot": copybot_agent is not None,
                "risk": risk_agent is not None,
                "harvesting": harvesting_agent is not None,
                "staking": staking_agent is not None
            },
            "paper_trading": {
                "enabled": PAPER_TRADING_ENABLED,
                "available": paper_trading_available
            }
        }
        
        # Check Helius webhook status if API key is available
        if HELIUS_API_KEY:
            try:
                logger.info("üîç Checking Helius webhook status...")
                current_addresses = get_current_webhook_addresses()
                logger.info(f"üîç Current addresses returned: {current_addresses}")
                status["helius_integration"]["webhook_registered"] = current_addresses is not None
                status["helius_integration"]["tracked_addresses"] = list(current_addresses) if current_addresses else []
                
                # DEBUG: Get all webhooks from Helius to see what's registered
                try:
                    list_url = "https://api.helius.xyz/v0/webhooks"
                    list_response = requests.get(
                        f"{list_url}?api-key={HELIUS_API_KEY}",
                        timeout=10
                    )
                    if list_response.status_code == 200:
                        existing_webhooks = list_response.json()
                        status["helius_integration"]["all_webhooks"] = [
                            {
                                "id": webhook.get('webhookID'),
                                "url": webhook.get('webhookURL'),
                                "addresses": len(webhook.get('accountAddresses', []))
                            }
                            for webhook in existing_webhooks
                        ]
                        # Add more detailed debug info
                        status["helius_integration"]["debug_details"] = {
                            "response_status": list_response.status_code,
                            "total_webhooks_found": len(existing_webhooks),
                            "our_webhook_url": webhook_url,
                            "webhook_match_found": any(
                                webhook.get('webhookURL') == webhook_url 
                                for webhook in existing_webhooks
                            )
                        }
                    else:
                        status["helius_integration"]["debug_error"] = f"HTTP {list_response.status_code}: {list_response.text}"
                except Exception as e:
                    status["helius_integration"]["debug_error"] = f"Exception: {str(e)}"
                    import traceback
                    status["helius_integration"]["debug_traceback"] = traceback.format_exc()
                    
            except Exception as e:
                status["helius_integration"]["webhook_registered"] = False
                status["helius_integration"]["error"] = str(e)
        
        return jsonify({
            "status": "success",
            "data": status,
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error getting test status: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/test-websocket', methods=['GET'])
def test_websocket_connection():
    """Test WebSocket connection for real-time monitoring"""
    try:
        if not realtime_monitoring_available:
            return jsonify({
                "status": "error",
                "message": "WebSocket monitoring not available",
                "reason": "WEBSOCKET_ENDPOINT not configured"
            }), 400
        
        if not WEBSOCKET_ENDPOINT:
            return jsonify({
                "status": "error",
                "message": "WebSocket endpoint not configured",
                "reason": "WEBSOCKET_ENDPOINT environment variable not set"
            }), 400
        
        # Test WebSocket connection
        import asyncio
        import websockets
        
        async def test_websocket():
            try:
                async with websockets.connect(WEBSOCKET_ENDPOINT) as websocket:
                    # Send a simple ping
                    await websocket.send(json.dumps({
                        "jsonrpc": "2.0",
                        "id": 1,
                        "method": "getHealth"
                    }))
                    
                    # Wait for response
                    response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                    return True, response
            except Exception as e:
                return False, str(e)
        
        # Run the test
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        success, result = loop.run_until_complete(test_websocket())
        loop.close()
        
        if success:
            return jsonify({
                "status": "success",
                "message": "WebSocket connection test successful",
                "endpoint": WEBSOCKET_ENDPOINT,
                "response": result
            })
        else:
            return jsonify({
                "status": "error",
                "message": "WebSocket connection test failed",
                "endpoint": WEBSOCKET_ENDPOINT,
                "error": result
            }), 500
            
    except Exception as e:
        logger.error(f"‚ùå WebSocket connection test failed: {e}")
        return jsonify({
            "status": "error",
            "message": f"WebSocket connection test failed: {str(e)}"
        }), 500

def handle_webhook_test(events):
    """Internal function to process test webhook events"""
    try:
        logger.info(f"üß™ TEST: Processing {len(events)} test events")
        
        # Use the same processing logic as the main webhook handler
        personal_wallet = get_personal_wallet_address()
        tracked_wallets = get_current_wallets_to_track()
        
        logger.info(f"üîç Test Wallet Configuration:")
        logger.info(f"  Personal Wallet: {personal_wallet}")
        logger.info(f"  Tracked Wallets: {tracked_wallets}")
        logger.info(f"  Total Tracked: {len(tracked_wallets)}")
        
        print("\nüìä Pre-Test Portfolio State:")
        safe_print_paper_trading_status()
        
        processed_events = []
        total_transfers_found = 0
        total_transfers_processed = 0
        
        for i, event in enumerate(events):
            logger.info(f"üß™ TEST: Processing test event {i+1}/{len(events)}")
            logger.info(f"üìã Test event keys: {list(event.keys())}")
            
            # Parse transfers using the same logic
            token_transfers = parse_solana_transaction(event)
            logger.info(f"  üìä TEST: Parsed {len(token_transfers)} token transfers from event {i+1}")
            total_transfers_found += len(token_transfers)
            for k, transfer in enumerate(token_transfers):
                logger.info(f"    üîç TEST: Processing parsed token transfer {k+1}")
                result = process_token_transfer(transfer)
                if result:
                    logger.info(f"    ‚úÖ TEST: Parsed token transfer processed successfully")
                    processed_events.append(result)
                    total_transfers_processed += 1
                else:
                    logger.info(f"    ‚ùå TEST: Parsed token transfer not processed")
            
            sol_transfers = parse_native_sol_transfers(event)
            logger.info(f"  üìä TEST: Parsed {len(sol_transfers)} SOL transfers from event {i+1}")
            total_transfers_found += len(sol_transfers)
            for k, transfer in enumerate(sol_transfers):
                logger.info(f"    üîç TEST: Processing parsed SOL transfer {k+1}")
                result = process_token_transfer(transfer)
                if result:
                    logger.info(f"    ‚úÖ TEST: Parsed SOL transfer processed successfully")
                    processed_events.append(result)
                    total_transfers_processed += 1
                else:
                    logger.info(f"    ‚ùå TEST: Parsed SOL transfer not processed")
        
        logger.info(f"üß™ TEST: TRANSFER PROCESSING SUMMARY:")
        logger.info(f"  Total transfers found: {total_transfers_found}")
        logger.info(f"  Total transfers processed: {total_transfers_processed}")
        logger.info(f"  Processing success rate: {(total_transfers_processed/total_transfers_found*100):.1f}%" if total_transfers_found > 0 else "N/A")
        logger.info(f"üß™ TEST: Total processed events: {len(processed_events)}")
        
        # Group events by wallet and trigger agents
        wallet_events = {}
        for event in processed_events:
            wallet = event['wallet']
            if wallet not in wallet_events:
                wallet_events[wallet] = []
            wallet_events[wallet].append(event)
        
        logger.info(f"üß™ TEST: Affected wallets: {list(wallet_events.keys())}")
        
        # Trigger agents for each wallet
        for wallet, events in wallet_events.items():
            logger.info(f"üß™ TEST: Processing {len(events)} events for wallet {wallet[:8]}...")
            
            if is_personal_wallet(wallet):
                logger.info(f"üß™ TEST: Personal wallet activity detected: {wallet[:8]}...")
                
                # Trigger Risk Agent
                if WEBHOOK_ACTIVE_AGENTS.get('risk', False):
                    if not risk_agent:
                        logger.info("üß™ TEST: Initializing Risk Agent...")
                        initialize_risk_agent()
                    if risk_agent:
                        risk_agent.last_webhook_time = time.time()
                        for event in events:
                            try:
                                logger.info(f"üß™ TEST: Triggering Risk Agent for event")
                                risk_agent.handle_webhook_trigger(event)
                            except Exception as e:
                                logger.error(f"‚ùå TEST: Error in risk agent webhook trigger: {e}")
                
                # Trigger other agents...
                if WEBHOOK_ACTIVE_AGENTS.get('harvesting', False):
                    if not harvesting_agent:
                        initialize_harvesting_agent()
                    if harvesting_agent:
                        for event in events:
                            try:
                                logger.info(f"üß™ TEST: Triggering Harvesting Agent for event")
                                harvesting_agent.handle_webhook_trigger(event)
                            except Exception as e:
                                logger.error(f"‚ùå TEST: Error in harvesting agent webhook trigger: {e}")
                
                # Trigger Staking Agent for personal wallet transactions
                if WEBHOOK_ACTIVE_AGENTS.get('staking', False):
                    if not staking_agent:
                        logger.info("üß™ TEST: Initializing Staking Agent...")
                        initialize_staking_agent()
                    if staking_agent:
                        for event in events:
                            try:
                                logger.info(f"üß™ TEST: Triggering Staking Agent for event")
                                if hasattr(staking_agent, 'handle_webhook_trigger'):
                                    staking_agent.handle_webhook_trigger(event)
                                else:
                                    logger.info("üß™ TEST: Staking agent webhook trigger method not available")
                            except Exception as e:
                                logger.error(f"‚ùå TEST: Error in staking agent webhook trigger: {e}")
            else:
                logger.info(f"üß™ TEST: Copybot wallet activity detected: {wallet[:8]}...")
                # Ensure CopyBot is initialized in test mode as well
                if not copybot_agent:
                    try:
                        initialize_copybot_agent()
                    except Exception as e:
                        logger.error(f"‚ùå TEST: Failed to initialize CopyBot agent: {e}")
                if copybot_agent:
                    token_changes = {}
                    for event in events:
                        token_changes[event['token']] = {
                            "action": event['action'],
                            "amount": event['amount'],
                            "price": event['price'],
                            "usd_value": event['usd_value'],
                            "symbol": event['symbol'],
                            "name": event['name']
                        }
                    
                    changes = {
                        wallet: {
                            "tokens": token_changes
                        }
                    }
                    logger.info(f"üß™ TEST: Triggering CopyBot for changes: {changes}")
                    trigger_copybot_for_changes(wallet, changes)
        
        logger.info("üß™ TEST: Post-Test Portfolio State:")
        safe_print_paper_trading_status()
        
        return {
            "processed_events": len(processed_events),
            "affected_wallets": list(wallet_events.keys()),
            "total_transfers_found": total_transfers_found,
            "total_transfers_processed": total_transfers_processed,
            "events": processed_events
        }
        
    except Exception as e:
        logger.error(f"‚ùå TEST: Error in test webhook processing: {e}")
        return {"error": str(e)}

def start_webhook_server():
    """Start the webhook server"""
    try:
        # Log wallet configuration at startup
        logger.info(f"üëÄ WALLETS_TO_TRACK: {list(WALLETS_TO_TRACK)}")
        logger.info(f"üëÄ Personal wallet: {get_personal_wallet_address()}")
        
        # Verify Flask routes first
        if not verify_flask_routes():
            logger.error("‚ùå Flask route verification failed - cannot start server")
            return False
        
        # Initialize required services
        if not setup_personal_wallet_monitoring():
            logger.error("Failed to set up personal wallet monitoring")
            return False
        
        # Validate trading mode configuration
        logger.info("üîß Validating trading mode configuration...")
        validate_trading_mode_config()
        
        # Validate critical function calls
        logger.info("üîß Validating critical function calls...")
        validate_function_calls()
        
        # Check cloud database health
        logger.info("üîç Checking cloud database health...")
        db_healthy, db_status = check_cloud_database_health()
        logger.info(f"Cloud database status: {db_status}")
        
        # Initialize paper trading if enabled
        if PAPER_TRADING_ENABLED and paper_trading_available:
            init_paper_trading_db()
            logger.info("Paper trading initialized")
        elif PAPER_TRADING_ENABLED and not paper_trading_available:
            logger.warning("‚ö†Ô∏è Paper trading enabled but module not available - system will use live trading mode")
        
        # DISABLED: Queue processor not needed with simplified webhook handling
        logger.info("‚ÑπÔ∏è Using simplified webhook processing (no queue processor needed)")
            
        # CRITICAL FIX: Auto-update Helius webhook to current local IP address and sync addresses
        # ONLY for local development, not for Render deployment
        if HELIUS_API_KEY and not os.environ.get('RENDER'):
            logger.info("üîÑ Auto-updating Helius webhook to current local IP...")
            if auto_update_helius_webhook():
                logger.info("‚úÖ Successfully auto-updated Helius webhook")
            else:
                logger.warning("‚ö†Ô∏è Failed to auto-update webhook - continuing with existing configuration")
            
            # CRITICAL FIX: Sync webhook addresses with current configuration
            logger.info("üîÑ Syncing webhook addresses with current wallet configuration...")
            if sync_webhook_addresses_with_config():
                logger.info("‚úÖ Successfully synced webhook addresses")
            else:
                logger.warning("‚ö†Ô∏è Failed to sync webhook addresses - continuing with existing configuration")
                
            # ADDITIONAL FIX: Force refresh wallet cache and retry sync if needed
            logger.info("üîÑ Forcing wallet cache refresh and retrying sync...")
            if hasattr(get_current_wallets_to_track, '_cached_wallets'):
                get_current_wallets_to_track._cached_wallets = None
                get_current_wallets_to_track._cache_time = 0
                logger.info("‚úÖ Wallet cache cleared")
            
            # Retry sync with fresh wallet data
            if sync_webhook_addresses_with_config():
                logger.info("‚úÖ Successfully synced webhook addresses on retry")
            else:
                logger.warning("‚ö†Ô∏è Webhook address sync failed on retry - manual intervention may be needed")
        elif HELIUS_API_KEY and os.environ.get('RENDER'):
            logger.info("üöÄ Render deployment detected - skipping local IP updates")
            logger.info("Webhook server will use existing Helius configuration")
        else:
            logger.warning("HELIUS_API_KEY not found - skipping webhook auto-update")
            logger.info("Webhook server will run in manual testing mode")
            
        # DISABLED: Queue processor not needed with simplified webhook handling
        logger.info("‚ÑπÔ∏è Simplified webhook processing ready")
            
        # Start Flask server
        port = int(os.environ.get("PORT", WEBHOOK_PORT))
        logger.info(f"Starting webhook server on port {port}")
        app.run(host=WEBHOOK_HOST, port=port, debug=WEBHOOK_DEBUG_MODE)
        return True
        
    except Exception as e:
        logger.error(f"Error starting webhook server: {e}")
        return False

def run_webhook_server_in_thread():
    """Run the webhook server in a background thread"""
    try:
        # Initialize required services
        if not setup_personal_wallet_monitoring():
            logger.error("Failed to set up personal wallet monitoring")
            return None
        
        # Initialize paper trading if enabled
        if PAPER_TRADING_ENABLED and paper_trading_available:
            init_paper_trading_db()
            logger.info("Paper trading initialized")
        
        # Start proactive portfolio monitoring
        if _proactive_monitoring_enabled:
            start_proactive_portfolio_monitoring()
            
        # Register webhook with Helius (free tier) - but don't fail if API key is missing
        # ONLY for local development, not for Render deployment
        if HELIUS_API_KEY and not os.environ.get('RENDER'):
            # First, try to get existing webhooks to avoid hitting the limit
            try:
                list_url = "https://api.helius.xyz/v0/webhooks"
                list_response = requests.get(
                    f"{list_url}?api-key={HELIUS_API_KEY}",
                    timeout=10
                )
                
                if list_response.status_code == 200:
                    existing_webhooks = list_response.json()
                    logger.info(f"Found {len(existing_webhooks)} existing webhooks")
                    
                    # Check if we already have a webhook for this URL
                    existing_webhook = None
                    for webhook in existing_webhooks:
                        if webhook.get('webhookURL') == webhook_url:
                            existing_webhook = webhook
                            break
                    
                    if existing_webhook:
                        logger.info(f"Using existing webhook: {existing_webhook.get('webhookID', 'unknown')}")
                        
                        # Sync webhook addresses with WALLETS_TO_TRACK config
                        logger.info("üîÑ Syncing webhook addresses with WALLETS_TO_TRACK config...")
                        sync_success = sync_webhook_addresses_with_config()
                        if sync_success:
                            logger.info("‚úÖ Webhook addresses synced successfully")
                        else:
                            logger.warning("‚ö†Ô∏è Webhook address sync failed - using existing addresses")
                            # Fallback to current method
                            update_url = f"https://api.helius.xyz/v0/webhooks/{existing_webhook['webhookID']}"
                            update_data = {
                                "webhookURL": webhook_url,
                                "accountAddresses": list(get_current_wallets_to_track()),
                                "transactionTypes": WEBHOOK_TYPES,
                                "webhookType": "raw",
                                "authHeader": None
                            }
                            
                            update_response = requests.put(
                                f"{update_url}?api-key={HELIUS_API_KEY}",
                                json=update_data,
                                timeout=10
                            )
                            logger.info(f"Update payload sent to Helius: {update_data}")
                            logger.info(f"Helius update response status: {update_response.status_code}")
                            logger.info(f"Helius update response: {update_response.text}")
                            
                            if update_response.status_code == 200:
                                logger.info("Successfully updated existing webhook")
                            else:
                                logger.warning(f"Failed to update webhook: {update_response.text}")
                    else:
                        # Create new webhook only if we have room
                        if len(existing_webhooks) >= 1:  # Free tier limit
                            logger.warning("Helius free tier webhook limit reached. Using manual testing mode.")
                            logger.info("To use webhooks, upgrade to paid tier or delete existing webhooks")
                        else:
                            # Create new webhook with synced addresses
                            register_url = "https://api.helius.xyz/v0/webhooks"
                            
                            # Get synced address list
                            personal_wallet = get_personal_wallet_address()
                            try:
                                from src.config import WALLETS_TO_TRACK as config_wallets
                                final_addresses = {personal_wallet} if personal_wallet else set()
                                final_addresses.update(config_wallets)
                            except ImportError:
                                # Fallback to current method
                                final_addresses = get_current_wallets_to_track()
                            
                            webhook_data = {
                                "webhookURL": webhook_url,
                                "accountAddresses": list(final_addresses),
                                "transactionTypes": WEBHOOK_TYPES,
                                "webhookType": "raw",
                                "authHeader": None
                            }
                            
                            logger.info(f"Attempting to register webhook with Helius...")
                            logger.info(f"Webhook URL: {webhook_url}")
                            logger.info(f"API Key: {HELIUS_API_KEY[:8]}...")
                            logger.info(f"Wallets to track: {len(get_current_wallets_to_track())}")
                            
                            response = requests.post(
                                f"{register_url}?api-key={HELIUS_API_KEY}",
                                json=webhook_data,
                                timeout=10
                            )
                            logger.info(f"Registration payload sent to Helius: {webhook_data}")
                            logger.info(f"Helius response status: {response.status_code}")
                            logger.info(f"Helius response: {response.text}")
                            
                            if response.status_code == 200:
                                logger.info("Successfully registered webhook with Helius")
                            else:
                                logger.warning(f"Failed to register webhook with Helius: {response.text}")
                                logger.info("Continuing without webhook registration - manual testing mode")
                else:
                    logger.warning(f"Failed to list existing webhooks: {list_response.text}")
                    logger.info("Continuing without webhook registration - manual testing mode")
                    
            except Exception as e:
                logger.warning(f"Error managing webhooks with Helius: {e}")
                logger.info("Continuing without webhook registration - manual testing mode")
        else:
            logger.warning("HELIUS_API_KEY not found - skipping webhook registration")
            logger.info("Webhook server will run in manual testing mode")
            
        # Verify Flask routes before starting server
        if not verify_flask_routes():
            logger.error("‚ùå Flask route verification failed - cannot start server")
            return None
            
        # Start Flask server in a separate thread
        port = int(os.environ.get("PORT", WEBHOOK_PORT))
        logger.info(f"Starting webhook server on port {port}")
        
        # Use a different approach to run Flask in a thread
        def run_flask():
            try:
                app.run(host=WEBHOOK_HOST, port=port, debug=False, use_reloader=False)
            except Exception as e:
                logger.error(f"‚ùå Flask server error: {e}")
        
        server_thread = Thread(target=run_flask)
        server_thread.daemon = True
        server_thread.start()
        
        # Wait a moment for server to start
        time.sleep(2)
        
        # Verify server is responding
        try:
            response = requests.get(f"http://{WEBHOOK_HOST}:{port}/", timeout=5)
            if response.status_code == 200:
                logger.info("‚úÖ Webhook server started and responding")
            else:
                logger.warning(f"‚ö†Ô∏è Webhook server started but health check returned {response.status_code}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Webhook server started but health check failed: {e}")
        
        return server_thread
        
    except Exception as e:
        logger.error(f"Error starting webhook server: {e}")
        return None

def shutdown_webhook_server():
    """Clean shutdown of webhook resources"""
    global copybot_agent, risk_agent, rebalancing_agent
    
    # ENHANCED: Stop request queue processor
    try:
        _stop_queue_processor()
        logger.info("‚úÖ Request queue processor stopped")
    except Exception as e:
        logger.error(f"‚ùå Error stopping queue processor: {e}")
    
    # Clean up agents
    if copybot_agent:
        if hasattr(copybot_agent, 'shutdown') and callable(getattr(copybot_agent, 'shutdown')):
            try:
                copybot_agent.shutdown()
            except Exception as e:
                logger.error(f"Error shutting down CopyBot: {e}")
        copybot_agent = None
    
    if risk_agent:
        if hasattr(risk_agent, 'shutdown') and callable(getattr(risk_agent, 'shutdown')):
            try:
                risk_agent.shutdown()
            except Exception as e:
                logger.error(f"Error shutting down Risk agent: {e}")
        risk_agent = None
    
    if rebalancing_agent:
        if hasattr(rebalancing_agent, 'shutdown') and callable(getattr(rebalancing_agent, 'shutdown')):
            try:
                rebalancing_agent.shutdown()
            except Exception as e:
                logger.error(f"Error shutting down Rebalancing agent: {e}")
        rebalancing_agent = None
    
    logger.info("Webhook server resources cleaned up")

def sync_webhook_addresses_with_config():
    """
    Automatically sync webhook addresses with WALLETS_TO_TRACK configuration.
    This function ensures that:
    1. Personal wallet is always included (never removed)
    2. New wallets from WALLETS_TO_TRACK are added
    3. Old wallets not in WALLETS_TO_TRACK are removed
    4. Webhook is updated with the correct address list
    """
    try:
        logger.info("üîÑ Starting webhook address sync with config...")
        
        # Get personal wallet address (never remove this)
        personal_wallet = get_personal_wallet_address()
        if not personal_wallet:
            logger.warning("‚ö†Ô∏è No personal wallet configured - skipping webhook sync")
            return False
        
        # Get current WALLETS_TO_TRACK from config
        try:
            from src.config import WALLETS_TO_TRACK as config_wallets
            config_wallets_set = set(config_wallets)
            logger.info(f"üìã Loaded {len(config_wallets_set)} wallets from WALLETS_TO_TRACK config")
        except ImportError:
            logger.error("‚ùå Could not import WALLETS_TO_TRACK from config")
            return False
        
        # Create the final address list: personal wallet + config wallets
        final_addresses = {personal_wallet}  # Always include personal wallet
        final_addresses.update(config_wallets_set)  # Add config wallets
        
        logger.info(f"üìä Final address list ({len(final_addresses)} addresses):")
        logger.info(f"  Personal: {personal_wallet[:8]}...")
        for wallet in config_wallets_set:
            logger.info(f"  Config: {wallet[:8]}...")
        
        # Get current webhook addresses from Helius
        current_webhook_addresses = get_current_webhook_addresses()
        if current_webhook_addresses is None:
            logger.error("‚ùå Could not get current webhook addresses from Helius")
            return False
        
        logger.info(f"üîç Current webhook addresses ({len(current_webhook_addresses)} addresses):")
        for addr in current_webhook_addresses:
            logger.info(f"  {addr[:8]}...")
        
        # Check if sync is needed
        if current_webhook_addresses == final_addresses:
            logger.info("‚úÖ Webhook addresses are already in sync - no update needed")
            return True
        
        # Calculate changes
        addresses_to_add = final_addresses - current_webhook_addresses
        addresses_to_remove = current_webhook_addresses - final_addresses
        
        if addresses_to_add:
            logger.info(f"‚ûï Addresses to add: {[addr[:8] + '...' for addr in addresses_to_add]}")
        if addresses_to_remove:
            logger.info(f"‚ûñ Addresses to remove: {[addr[:8] + '...' for addr in addresses_to_remove]}")
        
        # Update webhook with new address list
        success = update_webhook_addresses(list(final_addresses))
        if success:
            logger.info("‚úÖ Webhook addresses successfully synced with config")
            return True
        else:
            logger.error("‚ùå Failed to sync webhook addresses")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error syncing webhook addresses: {e}")
        return False

def get_current_webhook_addresses() -> Optional[Set[str]]:
    """Get current webhook addresses from Helius"""
    try:
        if not HELIUS_API_KEY:
            logger.warning("‚ö†Ô∏è HELIUS_API_KEY not found - cannot get webhook addresses")
            return None
        
        # List existing webhooks
        list_url = "https://api.helius.xyz/v0/webhooks"
        list_response = requests.get(
            f"{list_url}?api-key={HELIUS_API_KEY}",
            timeout=10
        )
        
        if list_response.status_code == 200:
            existing_webhooks = list_response.json()
            logger.info(f"Found {len(existing_webhooks)} existing webhooks")
            
            # Find our webhook
            logger.info(f"üîç Looking for webhook with URL: {webhook_url}")
            logger.info(f"üîç Environment: RENDER={os.environ.get('RENDER')}, RENDER_SERVICE_NAME={os.environ.get('RENDER_SERVICE_NAME')}")
            
            for webhook in existing_webhooks:
                webhook_url_from_helius = webhook.get('webhookURL')
                logger.info(f"üîç Checking webhook: {webhook_url_from_helius}")
                if webhook_url_from_helius == webhook_url:
                    webhook_id = webhook.get('webhookID')
                    current_addresses = set(webhook.get('accountAddresses', []))
                    logger.info(f"‚úÖ Found webhook {webhook_id} with {len(current_addresses)} addresses")
                    return current_addresses
            
            logger.warning("‚ö†Ô∏è Could not find our webhook in Helius")
            logger.warning(f"‚ö†Ô∏è Our URL: {webhook_url}")
            logger.warning(f"‚ö†Ô∏è Available URLs: {[w.get('webhookURL') for w in existing_webhooks]}")
            logger.warning(f"‚ö†Ô∏è Environment check: RENDER={os.environ.get('RENDER')}")
            return None
        else:
            logger.error(f"‚ùå Failed to list webhooks: {list_response.status_code}")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error getting current webhook addresses: {e}")
        return None

def auto_update_helius_webhook():
    """Automatically update Helius webhook to use current local IP address"""
    try:
        if not HELIUS_API_KEY:
            logger.warning("‚ö†Ô∏è HELIUS_API_KEY not found - cannot auto-update webhook")
            return False
        
        logger.info("üîÑ Auto-updating Helius webhook to current local IP...")
        
        # Get current webhook ID
        list_url = "https://api.helius.xyz/v0/webhooks"
        list_response = requests.get(
            f"{list_url}?api-key={HELIUS_API_KEY}",
            timeout=10
        )
        
        if list_response.status_code != 200:
            logger.error(f"‚ùå Failed to list webhooks: {list_response.status_code}")
            return False
        
        existing_webhooks = list_response.json()
        webhook_id = None
        
        # Find any existing webhook (we'll update it)
        for webhook in existing_webhooks:
            webhook_id = webhook.get('webhookID')
            break
        
        if not webhook_id:
            logger.warning("‚ö†Ô∏è No existing webhook found - creating new one...")
            return create_new_helius_webhook()
        
        # Update existing webhook with current local IP
        update_url = f"https://api.helius.xyz/v0/webhooks/{webhook_id}"
        update_data = {
            "webhookURL": webhook_url,
            "accountAddresses": list(get_current_wallets_to_track()),
            "transactionTypes": WEBHOOK_TYPES,
            "webhookType": "raw",
            "authHeader": None
        }
        
        logger.info(f"üîÑ Updating webhook {webhook_id} to use: {webhook_url}")
        update_response = requests.put(
            f"{update_url}?api-key={HELIUS_API_KEY}",
            json=update_data,
            timeout=10
        )
        
        if update_response.status_code == 200:
            logger.info("‚úÖ Successfully auto-updated Helius webhook to current local IP")
            return True
        else:
            logger.error(f"‚ùå Failed to auto-update webhook: {update_response.text}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error auto-updating Helius webhook: {e}")
        return False

def create_new_helius_webhook():
    """Create a new Helius webhook with current local IP"""
    try:
        if not HELIUS_API_KEY:
            logger.warning("‚ö†Ô∏è HELIUS_API_KEY not found - cannot create webhook")
            return False
        
        logger.info("üÜï Creating new Helius webhook with current local IP...")
        
        create_url = "https://api.helius.xyz/v0/webhooks"
        create_data = {
            "webhookURL": webhook_url,
            "accountAddresses": list(get_current_wallets_to_track()),
            "transactionTypes": WEBHOOK_TYPES,
            "webhookType": "raw",
            "authHeader": None
        }
        
        create_response = requests.post(
            f"{create_url}?api-key={HELIUS_API_KEY}",
            json=create_data,
            timeout=10
        )
        
        if create_response.status_code == 200:
            logger.info("‚úÖ Successfully created new Helius webhook with current local IP")
            return True
        else:
            logger.error(f"‚ùå Failed to create webhook: {create_response.text}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error creating new Helius webhook: {e}")
        return False

def update_webhook_addresses(new_addresses: List[str]) -> bool:
    """Update webhook with new address list"""
    try:
        if not HELIUS_API_KEY:
            logger.warning("‚ö†Ô∏è HELIUS_API_KEY not found - cannot update webhook")
            return False
        
        # Get webhook ID
        list_url = "https://api.helius.xyz/v0/webhooks"
        list_response = requests.get(
            f"{list_url}?api-key={HELIUS_API_KEY}",
            timeout=10
        )
        
        if list_response.status_code != 200:
            logger.error(f"‚ùå Failed to list webhooks: {list_response.status_code}")
            return False
        
        existing_webhooks = list_response.json()
        webhook_id = None
        
        for webhook in existing_webhooks:
            if webhook.get('webhookURL') == webhook_url:
                webhook_id = webhook.get('webhookID')
                break
        
        if not webhook_id:
            logger.error("‚ùå Could not find webhook ID")
            return False
        
        # Update webhook
        update_url = f"https://api.helius.xyz/v0/webhooks/{webhook_id}"
        update_data = {
            "webhookURL": webhook_url,
            "accountAddresses": new_addresses,
            "transactionTypes": WEBHOOK_TYPES,
            "webhookType": "raw",
            "authHeader": None
        }
        
        logger.info(f"üîÑ Updating webhook {webhook_id} with {len(new_addresses)} addresses...")
        update_response = requests.put(
            f"{update_url}?api-key={HELIUS_API_KEY}",
            json=update_data,
            timeout=10
        )
        
        logger.info(f"Update response status: {update_response.status_code}")
        if update_response.status_code == 200:
            logger.info("‚úÖ Webhook successfully updated")
            return True
        else:
            logger.error(f"‚ùå Failed to update webhook: {update_response.text}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error updating webhook addresses: {e}")
        return False

@app.route('/test-transfer-fix', methods=['POST'])
def test_transfer_processing_fix():
    """Test endpoint to verify transfer processing fixes"""
    try:
        # Create a realistic SOL transfer event that should be processed
        test_event = {
            "blockTime": int(time.time()),
            "indexWithinBlock": 0,
            "meta": {
                "err": None,
                "fee": 5000,
                "preBalances": [1000000000, 0],  # 1 SOL, 0 SOL
                "postBalances": [500000000, 500000000],  # 0.5 SOL each
                "preTokenBalances": [],
                "postTokenBalances": [],
                "logMessages": [
                    "Program 11111111111111111111111111111111 invoke [1]",
                    "Program 11111111111111111111111111111111 success"
                ]
            },
            "slot": 354740529,
            "transaction": {
                "message": {
                    "accountKeys": [
                        "6PCniazSc5YpjYSc9e8A7Chx3QpGUqim3L2eU6h7sNf8",  # Tracked wallet
                        "DYAn4XpAkN5mhiXkRB7dGq4Jadnx6XYgu8L5b3WGhbrt"  # Another tracked wallet
                    ],
                    "instructions": [
                        {
                            "accounts": [0, 1],
                            "data": "3Bxs43ZMjSRQLs6o",
                            "programIdIndex": 1
                        }
                    ],
                    "recentBlockhash": "test_blockhash_123456789"
                },
                "signatures": [f"test_sol_transfer_fix_{int(time.time())}"]
            },
            "version": "legacy"
        }
        
        logger.info("üß™ TRANSFER FIX TEST: Testing SOL transfer processing")
        logger.info("üß™ Expected: SOL transfer should be processed despite price service issues")
        
        # Process the test event
        result = handle_webhook_test([test_event])
        
        # Analyze results
        success = False
        if result.get('total_transfers_found', 0) > 0:
            if result.get('total_transfers_processed', 0) > 0:
                success = True
                logger.info("‚úÖ TRANSFER FIX TEST: SUCCESS - Transfers are being processed")
            else:
                logger.error("‚ùå TRANSFER FIX TEST: FAILED - Transfers found but not processed")
        else:
            logger.error("‚ùå TRANSFER FIX TEST: FAILED - No transfers found")
        
        return jsonify({
            "status": "success" if success else "error",
            "message": "Transfer processing fix test completed",
            "test_event": test_event,
            "result": result,
            "fix_working": success,
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in transfer fix test: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

# =============================================================================
# üîÑ DYNAMIC WALLET MANAGEMENT ROUTES
# =============================================================================

@app.route('/add-wallet', methods=['POST'])
def add_wallet():
    """Add a new wallet to track in real-time"""
    try:
        data = request.get_json()
        if not data or 'wallet' not in data:
            return jsonify({
                "status": "error",
                "message": "Missing 'wallet' parameter"
            }), 400
        
        new_wallet = data['wallet'].strip()
        
        # Validate wallet address format
        if len(new_wallet) < 32 or len(new_wallet) > 50:
            return jsonify({
                "status": "error",
                "message": "Invalid wallet address format"
            }), 400
        
        # Get current wallets
        current_wallets = get_current_wallets_to_track()
        
        # Check if wallet already exists
        if new_wallet in current_wallets:
            return jsonify({
                "status": "warning",
                "message": f"Wallet {new_wallet[:8]}... already being tracked",
                "wallet": new_wallet,
                "total_tracked": len(current_wallets)
            }), 200
        
        # Add to wallet config file
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'wallets.json')
        
        try:
            with open(config_path, 'r') as f:
                wallet_data = json.load(f)
        except FileNotFoundError:
            wallet_data = {'wallets': []}
        
        # Add new wallet
        if 'wallets' not in wallet_data:
            wallet_data['wallets'] = []
        
        wallet_data['wallets'].append(new_wallet)
        
        # Save updated config
        with open(config_path, 'w') as f:
            json.dump(wallet_data, f, indent=2)
        
        # Clear cache to force refresh
        if hasattr(get_current_wallets_to_track, '_cached_wallets'):
            get_current_wallets_to_track._cached_wallets = None
            get_current_wallets_to_track._cache_time = 0
        
        # Update Helius webhook addresses
        try:
            current_wallets = get_current_wallets_to_track()
            update_webhook_addresses(list(current_wallets))
            logger.info(f"‚úÖ Updated Helius webhook with new wallet: {new_wallet[:8]}...")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not update Helius webhook: {e}")
        
        # Trigger immediate wallet data fetch for new wallet
        try:
            from src.scripts.wallet_tracker import fetch_wallet_data
            fetch_wallet_data(new_wallet)
            logger.info(f"‚úÖ Fetched initial data for new wallet: {new_wallet[:8]}...")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not fetch initial wallet data: {e}")
        
        logger.info(f"‚úÖ Added wallet {new_wallet[:8]}... to tracking list")
        
        return jsonify({
            "status": "success",
            "message": f"Wallet {new_wallet[:8]}... added successfully",
            "wallet": new_wallet,
            "total_tracked": len(wallet_data['wallets']),
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error adding wallet: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to add wallet: {str(e)}"
        }), 500

@app.route('/remove-wallet', methods=['POST'])
def remove_wallet():
    """Remove a wallet from tracking in real-time"""
    try:
        data = request.get_json()
        if not data or 'wallet' not in data:
            return jsonify({
                "status": "error",
                "message": "Missing 'wallet' parameter"
            }), 400
        
        wallet_to_remove = data['wallet'].strip()
        
        # Get current wallets
        current_wallets = get_current_wallets_to_track()
        
        # Check if wallet exists
        if wallet_to_remove not in current_wallets:
            return jsonify({
                "status": "warning",
                "message": f"Wallet {wallet_to_remove[:8]}... not found in tracking list",
                "wallet": wallet_to_remove,
                "total_tracked": len(current_wallets)
            }), 200
        
        # Remove from wallet config file
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'wallets.json')
        
        try:
            with open(config_path, 'r') as f:
                wallet_data = json.load(f)
        except FileNotFoundError:
            return jsonify({
                "status": "error",
                "message": "Wallet configuration file not found"
            }), 500
        
        # Remove wallet
        if 'wallets' in wallet_data and wallet_to_remove in wallet_data['wallets']:
            wallet_data['wallets'].remove(wallet_to_remove)
            
            # Save updated config
            with open(config_path, 'w') as f:
                json.dump(wallet_data, f, indent=2)
            
            # Clear cache to force refresh
            if hasattr(get_current_wallets_to_track, '_cached_wallets'):
                get_current_wallets_to_track._cached_wallets = None
                get_current_wallets_to_track._cache_time = 0
            
            # Update Helius webhook addresses
            try:
                current_wallets = get_current_wallets_to_track()
                update_webhook_addresses(list(current_wallets))
                logger.info(f"‚úÖ Updated Helius webhook after removing wallet: {wallet_to_remove[:8]}...")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not update Helius webhook: {e}")
            
            logger.info(f"‚úÖ Removed wallet {wallet_to_remove[:8]}... from tracking list")
            
            return jsonify({
                "status": "success",
                "message": f"Wallet {wallet_to_remove[:8]}... removed successfully",
                "wallet": wallet_to_remove,
                "total_tracked": len(wallet_data['wallets']),
                "timestamp": time.time()
            })
        else:
            return jsonify({
                "status": "error",
                "message": f"Wallet {wallet_to_remove[:8]}... not found in configuration"
            }), 404
        
    except Exception as e:
        logger.error(f"‚ùå Error removing wallet: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to remove wallet: {str(e)}"
        }), 500

@app.route('/list-wallets', methods=['GET'])
def list_wallets():
    """Get current list of tracked wallets"""
    try:
        current_wallets = get_current_wallets_to_track()
        
        return jsonify({
            "status": "success",
            "wallets": list(current_wallets),
            "total_tracked": len(current_wallets),
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error listing wallets: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to list wallets: {str(e)}"
        }), 500

@app.route('/refresh-wallets', methods=['POST'])
def refresh_wallets():
    """Force refresh of wallet list from config and update Helius webhook"""
    try:
        # Clear cache to force refresh
        if hasattr(get_current_wallets_to_track, '_cached_wallets'):
            get_current_wallets_to_track._cached_wallets = None
            get_current_wallets_to_track._cache_time = 0
        
        # Get fresh wallet list
        current_wallets = get_current_wallets_to_track()
        
        # Update Helius webhook addresses
        try:
            update_webhook_addresses(list(current_wallets))
            logger.info(f"‚úÖ Refreshed Helius webhook with {len(current_wallets)} wallets")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not update Helius webhook: {e}")
        
        return jsonify({
            "status": "success",
            "message": f"Wallet list refreshed successfully",
            "wallets": list(current_wallets),
            "total_tracked": len(current_wallets),
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error refreshing wallets: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to refresh wallets: {str(e)}"
        }), 500

@app.route('/fetch-wallet-data', methods=['POST'])
def fetch_wallet_data_endpoint():
    """Manually trigger wallet data fetch for specific wallet"""
    try:
        data = request.get_json()
        if not data or 'wallet' not in data:
            return jsonify({
                "status": "error",
                "message": "Missing 'wallet' parameter"
            }), 400
        
        wallet_address = data['wallet'].strip()
        
        # Check if wallet is being tracked
        current_wallets = get_current_wallets_to_track()
        if wallet_address not in current_wallets:
            return jsonify({
                "status": "error",
                "message": f"Wallet {wallet_address[:8]}... not in tracking list"
            }), 400
        
        # Trigger wallet data fetch
        try:
            from src.scripts.wallet_tracker import fetch_wallet_data
            fetch_wallet_data(wallet_address)
            logger.info(f"‚úÖ Manually fetched data for wallet: {wallet_address[:8]}...")
            
            return jsonify({
                "status": "success",
                "message": f"Data fetch triggered for wallet {wallet_address[:8]}...",
                "wallet": wallet_address,
                "timestamp": time.time()
            })
            
        except Exception as e:
            logger.error(f"‚ùå Error fetching wallet data: {e}")
            return jsonify({
                "status": "error",
                "message": f"Failed to fetch wallet data: {str(e)}"
            }), 500
        
    except Exception as e:
        logger.error(f"‚ùå Error in fetch wallet data endpoint: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to process request: {str(e)}"
        }), 500

@app.route('/wallet-status', methods=['GET'])
def wallet_status():
    """Get detailed wallet tracking status"""
    try:
        current_wallets = get_current_wallets_to_track()
        personal_wallet = get_personal_wallet_address()
        
        # Get Helius webhook status
        helius_status = "unknown"
        try:
            current_addresses = get_current_webhook_addresses()
            if current_addresses:
                helius_status = "active"
                webhook_addresses = list(current_addresses)
            else:
                helius_status = "inactive"
                webhook_addresses = []
        except Exception as e:
            helius_status = f"error: {str(e)}"
            webhook_addresses = []
        
        status_data = {
            "status": "success",
            "wallet_configuration": {
                "personal_wallet": personal_wallet,
                "tracked_wallets": list(current_wallets),
                "total_tracked": len(current_wallets),
                "helius_webhook_status": helius_status,
                "webhook_addresses": webhook_addresses
            },
            "timestamp": time.time()
        }
        
        return jsonify(status_data)
        
    except Exception as e:
        logger.error(f"‚ùå Error getting wallet status: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to get wallet status: {str(e)}"
        }), 500

@app.route('/debug-helius', methods=['GET'])
def debug_helius_webhooks():
    """Debug endpoint to directly check Helius webhook status"""
    try:
        if not HELIUS_API_KEY:
            return jsonify({
                "status": "error",
                "message": "HELIUS_API_KEY not configured"
            }), 400
        
        # Get all webhooks from Helius
        list_url = "https://api.helius.xyz/v0/webhooks"
        list_response = requests.get(
            f"{list_url}?api-key={HELIUS_API_KEY}",
            timeout=10
        )
        
        if list_response.status_code != 200:
            return jsonify({
                "status": "error",
                "message": f"Failed to get webhooks: {list_response.status_code}",
                "response": list_response.text
            }), 400
        
        existing_webhooks = list_response.json()
        
        # Find our webhook
        our_webhook = None
        for webhook in existing_webhooks:
            if webhook.get('webhookURL') == webhook_url:
                our_webhook = webhook
                break
        
        return jsonify({
            "status": "success",
            "data": {
                "our_webhook_url": webhook_url,
                "total_webhooks_found": len(existing_webhooks),
                "our_webhook_found": our_webhook is not None,
                "our_webhook_details": our_webhook,
                "all_webhooks": [
                    {
                        "id": webhook.get('webhookID'),
                        "url": webhook.get('webhookURL'),
                        "addresses": webhook.get('accountAddresses', []),
                        "address_count": len(webhook.get('accountAddresses', []))
                    }
                    for webhook in existing_webhooks
                ]
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in debug Helius: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

@app.route('/auto-update-webhook', methods=['POST'])
def auto_update_webhook_endpoint():
    """Manually trigger automatic webhook update to current local IP"""
    try:
        logger.info("üîÑ Manual webhook auto-update triggered...")
        
        success = auto_update_helius_webhook()
        
        if success:
            return jsonify({
                "status": "success",
                "message": "Successfully auto-updated Helius webhook to current local IP",
                "new_webhook_url": webhook_url,
                "timestamp": time.time()
            })
        else:
            return jsonify({
                "status": "error",
                "message": "Failed to auto-update webhook",
                "timestamp": time.time()
            }), 500
        
    except Exception as e:
        logger.error(f"‚ùå Error in auto-update webhook endpoint: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to process request: {str(e)}"
        }), 500

@app.route('/sync-webhook-addresses', methods=['POST'])
def sync_webhook_addresses_endpoint():
    """Manually trigger webhook address synchronization"""
    try:
        logger.info("üîÑ Manual webhook address sync triggered...")
        
        # Force refresh wallet cache first
        if hasattr(get_current_wallets_to_track, '_cached_wallets'):
            get_current_wallets_to_track._cached_wallets = None
            get_current_wallets_to_track._cache_time = 0
            logger.info("‚úÖ Wallet cache cleared")
        
        success = sync_webhook_addresses_with_config()
        
        if success:
            return jsonify({
                "status": "success",
                "message": "Successfully synced webhook addresses with configuration",
                "timestamp": time.time()
            })
        else:
            return jsonify({
                "status": "error",
                "message": "Failed to sync webhook addresses",
                "timestamp": time.time()
            }), 500
        
    except Exception as e:
        logger.error(f"‚ùå Error in sync webhook addresses endpoint: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to process request: {str(e)}"
        }), 500

@app.route('/ip-status', methods=['GET'])
def ip_status_endpoint():
    """Get current IP detection status and webhook configuration"""
    try:
        from src.config import get_local_ip_address
        
        detected_ip = get_local_ip_address()
        current_webhook_url = webhook_url
        
        return jsonify({
            "status": "success",
            "data": {
                "detected_local_ip": detected_ip,
                "current_webhook_url": current_webhook_url,
                "webhook_host": WEBHOOK_HOST,
                "webhook_port": WEBHOOK_PORT,
                "is_local_ip": detected_ip == WEBHOOK_HOST,
                "timestamp": time.time()
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in IP status endpoint: {e}")
        return jsonify({
            "status": "error",
            "message": f"Failed to get IP status: {str(e)}"
        }), 500

def get_usdc_balance(wallet_address: str) -> float:
    """Get USDC balance for a specific wallet address with multiple fallback methods"""
    try:
        # USDC mint address
        usdc_mint = "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"
        
        # Method 1: Direct RPC call (most reliable for USDC)
        try:
            balance = get_token_balance_direct_rpc(usdc_mint, wallet_address)
            if balance and balance > 0:
                logger.info(f"‚úÖ USDC balance via direct RPC: {balance:.6f}")
                return float(balance)
        except Exception as e:
            logger.debug(f"Direct RPC USDC balance failed: {e}")
        
        # Method 2: BirdEye API for USDC
        try:
            import requests
            birdeye_key = os.getenv("BIRDEYE_API_KEY")
            if birdeye_key:
                url = f"https://public-api.birdeye.so/public/tokenbalance?address={wallet_address}&mint={usdc_mint}"
                headers = {"X-API-KEY": birdeye_key}
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    balance = data.get("data", {}).get("balance", 0)
                    if balance and float(balance) > 0:
                        logger.info(f"‚úÖ USDC balance via BirdEye: {float(balance):.6f}")
                        return float(balance)
        except Exception as e:
            logger.debug(f"BirdEye USDC balance failed: {e}")
        
        # Method 3: Portfolio tracker
        try:
            balance = get_balance_from_portfolio(usdc_mint, wallet_address)
            if balance and balance > 0:
                logger.info(f"‚úÖ USDC balance via portfolio: {balance:.6f}")
                return float(balance)
        except Exception as e:
            logger.debug(f"Portfolio USDC balance failed: {e}")
        
        # Method 4: Shared API manager
        try:
            balance = get_balance_from_shared_api(usdc_mint, wallet_address)
            if balance and balance > 0:
                logger.info(f"‚úÖ USDC balance via shared API: {balance:.6f}")
                return float(balance)
        except Exception as e:
            logger.debug(f"Shared API USDC balance failed: {e}")
        
        logger.warning(f"‚ö†Ô∏è All USDC balance methods failed for {wallet_address[:8]}...")
        return 0.0
        
    except Exception as e:
        logger.error(f"‚ùå Error in get_usdc_balance: {e}")
        return 0.0

def get_token_balance_direct_rpc(token_mint: str, wallet_address: str) -> float:
    """Get token balance directly via RPC for most accurate results"""
    try:
        # Note: requests and json are already imported at module level
        
        rpc_endpoint = os.getenv("RPC_ENDPOINT", "https://api.mainnet-beta.solana.com")
        
        # Get token accounts by owner
        payload = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "getTokenAccountsByOwner",
            "params": [
                wallet_address,
                {"mint": token_mint},
                {"encoding": "jsonParsed"}
            ]
        }
        
        response = requests.post(rpc_endpoint, json=payload, timeout=10)
        data = response.json()
        
        if "result" in data and data["result"]["value"]:
            account_info = data["result"]["value"][0]["account"]["data"]["parsed"]["info"]
            balance = float(account_info["tokenAmount"]["uiAmountString"])
            return balance
        
        return 0.0
        
    except Exception as e:
        logger.warning(f"Direct RPC balance fetch failed: {e}")
        return 0.0

# =============================================================================

def start_proactive_portfolio_monitoring():
    """Start proactive portfolio monitoring for opportunity detection"""
    global _portfolio_monitoring_active, _proactive_monitoring_enabled
    
    if not _proactive_monitoring_enabled:
        logger.info("‚ÑπÔ∏è Proactive monitoring disabled - skipping")
        return False
    
    try:
        logger.info("üöÄ Starting proactive portfolio monitoring...")
        _portfolio_monitoring_active = True
        
        # Start monitoring in background thread
        import threading
        monitoring_thread = threading.Thread(target=_portfolio_monitoring_loop, daemon=True)
        monitoring_thread.start()
        
        logger.info("‚úÖ Proactive portfolio monitoring started")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Failed to start proactive monitoring: {e}")
        return False

def _portfolio_monitoring_loop():
    """Background loop for proactive portfolio monitoring"""
    global _last_portfolio_check
    
    while _portfolio_monitoring_active:
        try:
            current_time = time.time()
            
            # Check if it's time for portfolio check
            if current_time - _last_portfolio_check >= _portfolio_check_interval:
                logger.info("üîç Executing proactive portfolio check...")
                
                # Perform comprehensive portfolio analysis
                _execute_proactive_portfolio_check()
                
                _last_portfolio_check = current_time
                
            # Sleep for a short interval
            time.sleep(60)  # Check every minute
            
        except Exception as e:
            logger.error(f"‚ùå Error in portfolio monitoring loop: {e}")
            time.sleep(60)  # Continue despite errors

def _execute_proactive_portfolio_check():
    """Execute comprehensive portfolio check for opportunities"""
    try:
        # Get current portfolio state
        from src.scripts.trading.portfolio_tracker import get_portfolio_tracker
        portfolio_tracker = get_portfolio_tracker()
        
        if not portfolio_tracker or not portfolio_tracker.current_snapshot:
            logger.info("‚ÑπÔ∏è No portfolio data available for proactive check")
            return
        
        current_snapshot = portfolio_tracker.current_snapshot
        logger.info(f"üìä Proactive check - Current portfolio value: ${current_snapshot.total_value_usd:.2f}")
        
        # Check for risk conditions
        _check_proactive_risk_conditions(current_snapshot)
        
        # Check for harvesting opportunities
        _check_proactive_harvesting_opportunities(current_snapshot)
        
        # Check for rebalancing needs
        _check_proactive_rebalancing_needs(current_snapshot)
        
        logger.info("‚úÖ Proactive portfolio check completed")
        
    except Exception as e:
        logger.error(f"‚ùå Error in proactive portfolio check: {e}")

def _check_proactive_risk_conditions(current_snapshot):
    """Check for proactive risk conditions"""
    try:
        if not risk_agent:
            return
        
        logger.info("üõ°Ô∏è Checking proactive risk conditions...")
        
        # Trigger risk agent for comprehensive assessment
        risk_agent.handle_webhook_trigger({
            'type': 'proactive_risk_check',
            'timestamp': time.time(),
            'portfolio_data': current_snapshot
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in proactive risk check: {e}")

def _check_proactive_harvesting_opportunities(current_snapshot):
    """Check for proactive harvesting opportunities"""
    try:
        if not harvesting_agent:
            return
        
        logger.info("üåæ Checking proactive harvesting opportunities...")
        
        # Trigger harvesting agent for opportunity analysis
        harvesting_agent.handle_webhook_trigger({
            'type': 'proactive_harvesting_check',
            'timestamp': time.time(),
            'portfolio_data': current_snapshot
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error in proactive harvesting check: {e}")

def _check_proactive_rebalancing_needs(current_snapshot):
    """Check for proactive rebalancing needs"""
    try:
        logger.info("‚öñÔ∏è Checking proactive rebalancing needs...")
        
        # Analyze current allocation vs targets
        from src import config
        
        # Get target allocations from config (SOL/USDC only)
        target_usdc = USDC_TARGET_PERCENT  # 0.20 (20%)
        target_sol = SOL_TARGET_PERCENT    # 0.10 (10%)
        
        # Calculate current allocations (SOL/USDC only)
        total_value = current_snapshot.total_value_usd
        if total_value <= 0:
            return
        
        current_usdc = current_snapshot.usdc_balance / total_value
        current_sol = current_snapshot.sol_value_usd / total_value
        
        # Check for significant deviations (SOL/USDC only)
        deviation_threshold = 0.05  # 5%
        
        usdc_deviation = abs(current_usdc - target_usdc)
        sol_deviation = abs(current_sol - target_sol)
        
        if usdc_deviation > deviation_threshold or sol_deviation > deviation_threshold:
            logger.info(f"üéØ Rebalancing needed - deviations detected:")
            logger.info(f"  USDC: {current_usdc:.1%} vs {target_usdc:.1%} (dev: {usdc_deviation:.1%})")
            logger.info(f"  SOL: {current_sol:.1%} vs {target_sol:.1%} (dev: {sol_deviation:.1%})")
            
            # Trigger harvesting agent for rebalancing
            if harvesting_agent:
                harvesting_agent.handle_webhook_trigger({
                    'type': 'proactive_rebalancing',
                    'timestamp': time.time(),
                    'portfolio_data': current_snapshot,
                    'deviations': {
                        'usdc': usdc_deviation,
                        'sol': sol_deviation
                    }
                })
        
    except Exception as e:
        logger.error(f"‚ùå Error in proactive rebalancing check: {e}")

@app.route('/webhook/portfolio-change', methods=['POST'])
def handle_portfolio_change_webhook():
    """Handle portfolio change webhooks from main terminal"""
    try:
        logger.info("üìä Portfolio change webhook received from main terminal")
        
        # Parse the portfolio change data
        data = request.json
        if not data:
            return jsonify({"status": "error", "message": "No data received"}), 400
        
        logger.info(f"üìã Portfolio change data: {json.dumps(data, indent=2)}")
        
        # Extract portfolio change information - handle both 'type' and 'change_type' fields
        change_type = data.get('change_type', data.get('type', 'unknown'))
        portfolio_data = data.get('portfolio_data', {})
        timestamp = data.get('timestamp', time.time())
        
        logger.info(f"üîÑ Portfolio change type: {change_type}")
        
        # üåê Save portfolio data to cloud database for synchronization
        try:
            from src.scripts.database.cloud_database import get_cloud_database_manager
            db_manager = get_cloud_database_manager()
            if db_manager:
                # Save portfolio snapshot to cloud database
                ok = db_manager.save_paper_trading_portfolio(portfolio_data)
                if ok:
                    logger.info("‚úÖ Portfolio data saved to cloud database")
                else:
                    logger.warning("‚ö†Ô∏è Failed to save portfolio data to cloud database; using local storage only")
            else:
                logger.debug("Cloud database not available - using local storage only")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to save portfolio data to cloud database: {e}")
        
        # Trigger appropriate agents based on change type
        if change_type in ['balance_change', 'allocation_change', 'position_change']:
            # Trigger risk agent for portfolio changes
            if WEBHOOK_ACTIVE_AGENTS.get('risk', False) and risk_agent:
                if hasattr(risk_agent, 'is_ready') and hasattr(risk_agent, '_in_cooldown'):
                    if not risk_agent.is_ready():
                        logger.info('‚è≥ RiskAgent startup grace - skip')
                    elif risk_agent._in_cooldown():
                        logger.info('üïí RiskAgent cooldown - skip')
                    else:
                        logger.info("‚öñÔ∏è Triggering risk agent for portfolio change")
                        try:
                            risk_agent.handle_webhook_trigger({
                                'type': 'portfolio_change',
                                'change_type': change_type,
                                'timestamp': timestamp,
                                'portfolio_data': portfolio_data
                            })
                            logger.info("‚úÖ Risk agent triggered successfully")
                        except Exception as e:
                            logger.error(f"‚ùå Error triggering risk agent: {e}")
                else:
                    logger.info("‚öñÔ∏è Triggering risk agent for portfolio change")
                    try:
                        risk_agent.handle_webhook_trigger({
                            'type': 'portfolio_change',
                            'change_type': change_type,
                            'timestamp': timestamp,
                            'portfolio_data': portfolio_data
                        })
                        logger.info("‚úÖ Risk agent triggered successfully")
                    except Exception as e:
                        logger.error(f"‚ùå Error triggering risk agent: {e}")
            
            # Trigger harvesting agent for portfolio changes
            if WEBHOOK_ACTIVE_AGENTS.get('harvesting', False) and harvesting_agent:
                logger.info("üåæ Triggering harvesting agent for portfolio change")
                try:
                    harvesting_agent.handle_webhook_trigger({
                        'type': 'portfolio_change',
                        'change_type': change_type,
                        'timestamp': timestamp,
                        'portfolio_data': portfolio_data
                    })
                    logger.info("‚úÖ Harvesting agent triggered successfully")
                except Exception as e:
                    logger.error(f"‚ùå Error triggering harvesting agent: {e}")
            
            # Trigger staking agent for portfolio changes (if staking operations are needed)
            if WEBHOOK_ACTIVE_AGENTS.get('staking', False) and staking_agent:
                logger.info("üîí Triggering staking agent for portfolio change")
                try:
                    if hasattr(staking_agent, 'handle_webhook_trigger'):
                        staking_agent.handle_webhook_trigger({
                            'type': 'portfolio_change',
                            'change_type': change_type,
                            'timestamp': timestamp,
                            'portfolio_data': portfolio_data
                        })
                        logger.info("‚úÖ Staking agent triggered successfully")
                    else:
                        logger.info("‚ÑπÔ∏è Staking agent webhook trigger method not available")
                except Exception as e:
                    logger.error(f"‚ùå Error triggering staking agent: {e}")
        
        elif change_type == 'threshold_breach':
            # Trigger risk agent for threshold breaches
            if WEBHOOK_ACTIVE_AGENTS.get('risk', False) and risk_agent:
                logger.info("üö® Triggering risk agent for threshold breach")
                try:
                    risk_agent.handle_webhook_trigger({
                        'type': 'threshold_breach',
                        'timestamp': timestamp,
                        'portfolio_data': portfolio_data
                    })
                    logger.info("‚úÖ Risk agent triggered for threshold breach")
                except Exception as e:
                    logger.error(f"‚ùå Error triggering risk agent for threshold breach: {e}")
        
        logger.info("‚úÖ Portfolio change webhook processed successfully")
        return jsonify({
            "status": "success",
            "message": "Portfolio change processed",
            "agents_triggered": [
                "risk" if WEBHOOK_ACTIVE_AGENTS.get('risk', False) else None,
                "harvesting" if WEBHOOK_ACTIVE_AGENTS.get('harvesting', False) else None,
                "staking" if WEBHOOK_ACTIVE_AGENTS.get('staking', False) else None
            ]
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error processing portfolio change webhook: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/status/realtime-monitoring', methods=['GET'])
def get_realtime_monitoring_status():
    """Get status of real-time portfolio monitoring"""
    try:
        global _realtime_monitoring_active, _portfolio_tracker_instance
        
        status = {
            "realtime_monitoring_active": _realtime_monitoring_active,
            "monitoring_available": realtime_monitoring_available,
            "websocket_endpoint": WEBSOCKET_ENDPOINT if 'WEBSOCKET_ENDPOINT' in locals() else None,
            "portfolio_tracker_initialized": _portfolio_tracker_instance is not None,
            "last_update": time.time(),
            "monitoring_mode": "websocket" if _realtime_monitoring_active and realtime_monitoring_available else "polling_fallback" if _realtime_monitoring_active else "disabled"
        }
        
        if _portfolio_tracker_instance and _portfolio_tracker_instance.current_snapshot:
            status["current_portfolio_value"] = _portfolio_tracker_instance.current_snapshot.total_value_usd
            status["last_snapshot_time"] = _portfolio_tracker_instance.current_snapshot.timestamp.isoformat()
        
        return jsonify(status)
        
    except Exception as e:
        logger.error(f"‚ùå Error getting real-time monitoring status: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/control/realtime-monitoring', methods=['POST'])
def control_realtime_monitoring():
    """Start or stop real-time portfolio monitoring"""
    try:
        data = request.get_json()
        action = data.get('action', 'status')
        
        if action == 'start':
            if start_realtime_portfolio_monitoring():
                return jsonify({
                    "status": "success",
                    "message": "Real-time monitoring started",
                    "monitoring_active": True
                })
            else:
                return jsonify({
                    "status": "error",
                    "message": "Failed to start real-time monitoring"
                }), 500
                
        elif action == 'stop':
            stop_realtime_portfolio_monitoring()
            return jsonify({
                "status": "success",
                "message": "Real-time monitoring stopped",
                "monitoring_active": False
            })
            
        elif action == 'status':
            return jsonify({
                "status": "success",
                "monitoring_active": _realtime_monitoring_active,
                "monitoring_available": realtime_monitoring_available
            })
            
        else:
            return jsonify({
                "status": "error",
                "message": "Invalid action. Use 'start', 'stop', or 'status'"
            }), 400
            
    except Exception as e:
        logger.error(f"‚ùå Error controlling real-time monitoring: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

# Startup function to initialize real-time monitoring
def initialize_realtime_monitoring():
    """Initialize real-time portfolio monitoring on startup"""
    try:
        logger.info("üöÄ Initializing real-time portfolio monitoring...")
        
        # Start real-time monitoring
        if start_realtime_portfolio_monitoring():
            logger.info("‚úÖ Real-time portfolio monitoring initialized successfully")
            if realtime_monitoring_available:
                logger.info("üîå WebSocket monitoring active - portfolio changes detected instantly")
                logger.info(f"üì° Using WebSocket endpoint: {WEBSOCKET_ENDPOINT}")
            else:
                logger.info("üì° Polling fallback active - portfolio changes detected every 10 seconds")
            logger.info("üì° Agents will be triggered automatically on portfolio changes")
        else:
            logger.warning("‚ö†Ô∏è Real-time portfolio monitoring failed to start")
            
    except Exception as e:
        logger.error(f"‚ùå Error initializing real-time monitoring: {e}")

# Auto-start real-time monitoring when module is imported
try:
    # Start real-time monitoring in background
    threading.Thread(
        target=initialize_realtime_monitoring,
        daemon=True
    ).start()
    logger.info("üîÑ Real-time monitoring initialization started in background")
    
    # DISABLED: Proactive portfolio monitoring to reduce excessive health checks
    # The harvesting agent should only trigger on actual portfolio changes via webhooks
    def run_proactive_monitoring():
        """DISABLED: Proactive portfolio monitoring - agents should only trigger on webhook events"""
        import time
        
        logger.info("üö´ Proactive portfolio monitoring DISABLED - agents will only trigger on webhook events")
        logger.info("üì° Portfolio changes will trigger webhooks to agents automatically")
        
        # Keep the thread alive but do nothing
        while True:
            time.sleep(3600)  # Sleep for 1 hour (minimal resource usage)
    
    # Start minimal monitoring thread (no actual proactive checks)
    proactive_thread = threading.Thread(target=run_proactive_monitoring, daemon=True)
    proactive_thread.start()
    logger.info("‚úÖ Minimal monitoring thread started (proactive checks disabled)")
    
except Exception as e:
    logger.error(f"‚ùå Failed to start real-time monitoring initialization: {e}")

if __name__ == "__main__":
    # Start the webhook server directly if this file is run
    try:
        start_webhook_server()
    except KeyboardInterrupt:
        logger.info("Shutting down webhook server...")
        shutdown_webhook_server() 