"""
ðŸŒ™ Anarcho Capital's Shared API Manager
Handles rate limiting and API coordination across all agents
Built with love by Anarcho Capital ðŸš€
"""

import threading
import time
import requests
import os
from typing import Dict, Optional, List, Any, Callable
# Removed unused datetime alias
from concurrent.futures import ThreadPoolExecutor
import queue
# Remove unused json import (was only needed for older code paths)
from dataclasses import dataclass
from enum import Enum
# Local imports with fallback for relative imports
try:
    from src.scripts.shared_services.logger import debug, info, warning, error
except ImportError:
    # Try relative imports when running from test directory
    from src.scripts.shared_services.logger import debug, info, warning, error
from dotenv import load_dotenv

load_dotenv()

class APIEndpoint(Enum):
    """Enum for different API endpoints"""
    HELIUS_RPC = "helius_rpc"
    JUPITER_PRICE = "jupiter_price"
    JUPITER_SWAP = "jupiter_swap"
    JUPITER_TOKENS = "jupiter_tokens"  # NEW: For JupSOL token data
    BIRDEYE_PRICE = "birdeye_price"
    BIRDEYE_METADATA = "birdeye_metadata"
    PUMPFUN_PRICE = "pumpfun_price"
    COINGECKO_PRICE = "coingecko_price"
    # NEW: Staking Protocol APIs
    BLAZESTAKE_APY = "blazestake_apy"
    BLAZESTAKE_BALANCE = "blazestake_balance"
    JUPITER_LST_TOKENS = "jupiter_lst_tokens"
    SANCTUM_LST_DATA = "sanctum_lst_data"

@dataclass
class APIConfig:
    """Configuration for API endpoints"""
    max_calls_per_minute: int
    max_calls_per_second: int
    retry_attempts: int
    retry_delay: float
    timeout: int

class SharedAPIManager:
    """
    Singleton shared API manager that coordinates all API calls across agents
    Prevents rate limiting conflicts and manages shared resources
    """
    
    _instance = None
    _lock = threading.Lock()
    
    # API configurations for different endpoints
    API_CONFIGS = {
        APIEndpoint.HELIUS_RPC: APIConfig(
            max_calls_per_minute=100,
            max_calls_per_second=5,
            retry_attempts=3,
            retry_delay=1.0,
            timeout=10
        ),
        APIEndpoint.JUPITER_PRICE: APIConfig(
            max_calls_per_minute=100,
            max_calls_per_second=3,
            retry_attempts=3,
            retry_delay=0.5,
            timeout=10
        ),
        APIEndpoint.JUPITER_SWAP: APIConfig(
            max_calls_per_minute=60,
            max_calls_per_second=2,
            retry_attempts=3,
            retry_delay=1.0,
            timeout=15
        ),
        APIEndpoint.JUPITER_TOKENS: APIConfig(
            max_calls_per_minute=200,  # HIGH: Token data is cached well
            max_calls_per_second=5,
            retry_attempts=3,
            retry_delay=0.2,
            timeout=8
        ),
        APIEndpoint.BIRDEYE_PRICE: APIConfig(
            max_calls_per_minute=900,  # Utilize paid tier fully
            max_calls_per_second=15,   # 900/60 = 15/sec
            retry_attempts=3,
            retry_delay=0.1,          # Faster retries
            timeout=5                  # Faster timeout
        ),
        APIEndpoint.BIRDEYE_METADATA: APIConfig(
            max_calls_per_minute=300,  # Increase from 30 to utilize paid tier
            max_calls_per_second=5,
            retry_attempts=3,
            retry_delay=0.2,
            timeout=5
        ),
        APIEndpoint.PUMPFUN_PRICE: APIConfig(
            max_calls_per_minute=100,
            max_calls_per_second=2,
            retry_attempts=3,
            retry_delay=0.5,
            timeout=10
        ),
        APIEndpoint.COINGECKO_PRICE: APIConfig(
            max_calls_per_minute=50,
            max_calls_per_second=1,
            retry_attempts=3,
            retry_delay=1.0,
            timeout=10
        ),
        # NEW: Optimized Staking Protocol APIs
        APIEndpoint.BLAZESTAKE_APY: APIConfig(
            max_calls_per_minute=120,  # HIGH: BlazeStake is very reliable
            max_calls_per_second=3,
            retry_attempts=2,
            retry_delay=0.3,
            timeout=8
        ),
        APIEndpoint.BLAZESTAKE_BALANCE: APIConfig(
            max_calls_per_minute=60,
            max_calls_per_second=2,
            retry_attempts=2,
            retry_delay=0.5,
            timeout=10
        ),
        APIEndpoint.JUPITER_LST_TOKENS: APIConfig(
            max_calls_per_minute=300,  # VERY HIGH: Jupiter LST data is static
            max_calls_per_second=10,
            retry_attempts=2,
            retry_delay=0.1,
            timeout=5
        ),
        APIEndpoint.SANCTUM_LST_DATA: APIConfig(
            max_calls_per_minute=100,  # MEDIUM: Sanctum data is cached
            max_calls_per_second=3,
            retry_attempts=2,
            retry_delay=0.3,
            timeout=8
        )
    }
    
    def __new__(cls):
        """Singleton pattern implementation"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """Initialize the shared API manager"""
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        
        # Rate limiting tracking
        self.call_history = {endpoint: [] for endpoint in APIEndpoint}
        self.rate_limit_locks = {endpoint: threading.Lock() for endpoint in APIEndpoint}
        
        # Request deduplication to prevent concurrent API calls
        self.active_requests = {}
        self.request_lock = threading.Lock()
        
        # Request queue for batching
        self.request_queues = {endpoint: queue.Queue() for endpoint in APIEndpoint}
        self.batch_processors = {}
        
        # CRITICAL FIX: Separate thread pools to prevent starvation
        # RPC calls (wallet tracking, blockchain queries)
        self.rpc_executor = ThreadPoolExecutor(max_workers=8, thread_name_prefix="RPC")
        # Price/quote calls (Jupiter, Birdeye, CoinGecko)
        self.price_executor = ThreadPoolExecutor(max_workers=6, thread_name_prefix="Price")
        # Webhook processing (lightweight, high priority)
        self.webhook_executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="Webhook")
        # General API calls (metadata, etc.)
        self.general_executor = ThreadPoolExecutor(max_workers=6, thread_name_prefix="General")
        
        # Legacy executor for backward compatibility
        self.executor = self.general_executor
        
        # Error tracking and backoff
        self.error_counts = {endpoint: 0 for endpoint in APIEndpoint}
        self.backoff_until = {endpoint: None for endpoint in APIEndpoint}
        
        # API keys and endpoints
        self.api_keys = {
            'helius': os.getenv('HELIUS_API_KEY'),
            'birdeye': os.getenv('BIRDEYE_API_KEY'),
            'jupiter': os.getenv('JUPITER_API_KEY'),
            'pumpfun': os.getenv('PUMPFUN_API_KEY'),
            'coingecko': os.getenv('COINGECKO_API_KEY')
        }
        
        self.endpoints = {
            APIEndpoint.HELIUS_RPC: os.getenv('RPC_ENDPOINT'),
            APIEndpoint.JUPITER_PRICE: "https://price.jup.ag/v4/price",
            APIEndpoint.JUPITER_SWAP: "https://lite-api.jup.ag/swap/v1/swap",
            APIEndpoint.JUPITER_TOKENS: "https://lite-api.jup.ag/tokens/v2/tag",
            APIEndpoint.BIRDEYE_PRICE: "https://public-api.birdeye.so/defi/price",
            APIEndpoint.BIRDEYE_METADATA: "https://public-api.birdeye.so/defi/token_overview",
            APIEndpoint.PUMPFUN_PRICE: "https://api.pumpfunapi.org/price",
            APIEndpoint.COINGECKO_PRICE: "https://api.coingecko.com/api/v3/simple/price",
            # NEW: Staking Protocol Endpoints
            APIEndpoint.BLAZESTAKE_APY: "https://stake.solblaze.org/api/v1/apy",
            APIEndpoint.BLAZESTAKE_BALANCE: "https://stake.solblaze.org/api/v1/cls_user_target",
            APIEndpoint.JUPITER_LST_TOKENS: "https://lite-api.jup.ag/tokens/v2/tag?query=lst",
            APIEndpoint.SANCTUM_LST_DATA: "https://api.sanctum.so/v1/lst"  # Placeholder - Sanctum may not have public API
        }
        
        # RPC endpoint configuration with priority and fallback
        self.rpc_endpoints = {
            'primary': os.getenv('QUICKNODE_RPC_ENDPOINT'),
            'fallback': os.getenv('RPC_ENDPOINT'),  # Changed from HELIUS_RPC_ENDPOINT to RPC_ENDPOINT
            'legacy': os.getenv('RPC_ENDPOINT')     # Keep legacy as RPC_ENDPOINT
        }
        
        # Track RPC endpoint health
        self.rpc_health = {
            'primary': {'healthy': True, 'last_failure': 0, 'failure_count': 0},
            'fallback': {'healthy': True, 'last_failure': 0, 'failure_count': 0},
            'legacy': {'healthy': True, 'last_failure': 0, 'failure_count': 0}
        }
        
        # RPC circuit breaker settings
        self.rpc_circuit_breaker = {
            'failure_threshold': 3,
            'recovery_timeout': 300,  # 5 minutes
            'current_endpoint': 'primary'
        }
        
        # Start batch processors for high-frequency endpoints
        self._start_batch_processors()
        
        # Print in yellow using termcolor
        from termcolor import cprint
        cprint("INFO: Shared API Manager initialized successfully", "yellow")
        info("Shared API Manager initialized successfully", file_only=True)
    
    def _start_batch_processors(self):
        """Start batch processors for endpoints that benefit from batching"""
        batch_endpoints = [APIEndpoint.JUPITER_PRICE, APIEndpoint.BIRDEYE_PRICE]
        
        for endpoint in batch_endpoints:
            processor_thread = threading.Thread(
                target=self._batch_processor_worker,
                args=(endpoint,),
                daemon=True
            )
            processor_thread.start()
            self.batch_processors[endpoint] = processor_thread
    
    def _batch_processor_worker(self, endpoint: APIEndpoint):
        """Worker thread for batch processing requests"""
        # OPTIMIZATION: Optimized batch sizes for different endpoints
        if endpoint == APIEndpoint.BIRDEYE_PRICE:
            batch_size = 50  # Higher batch size for paid tier
            batch_timeout = 0.2  # Faster processing for Birdeye
        else:  # Jupiter
            batch_size = 50
            batch_timeout = 0.5  # Keep reasonable timeout for Jupiter
        
        while True:
            try:
                batch = []
                start_time = time.time()
                
                # Collect requests for batching
                while len(batch) < batch_size and (time.time() - start_time) < batch_timeout:
                    try:
                        request = self.request_queues[endpoint].get(timeout=0.05)  # Reduced timeout
                        if request is None:  # Shutdown signal
                            return
                        batch.append(request)
                    except queue.Empty:
                        if batch:  # If we have some requests, process them
                            break
                        continue
                
                if batch:
                    self._process_batch(endpoint, batch)
                    
            except Exception as e:
                error(f"Error in batch processor for {endpoint}: {str(e)}")
                time.sleep(0.5)  # OPTIMIZATION: Reduced from 1 second to 0.5 seconds
    
    def _process_batch(self, endpoint: APIEndpoint, batch: List[Dict]):
        """Process a batch of requests for an endpoint"""
        if endpoint == APIEndpoint.JUPITER_PRICE:
            self._process_jupiter_price_batch(batch)
        elif endpoint == APIEndpoint.BIRDEYE_PRICE:
            self._process_birdeye_price_batch(batch)
    
    def _process_jupiter_price_batch(self, batch: List[Dict]):
        """Process a batch of Jupiter price requests"""
        try:
            # Extract token addresses from batch
            token_addresses = [req['params']['token'] for req in batch]
            
            # Make batch API call
            url = f"{self.endpoints[APIEndpoint.JUPITER_PRICE]}?ids={','.join(token_addresses)}"
            response = requests.get(url, timeout=self.API_CONFIGS[APIEndpoint.JUPITER_PRICE].timeout)
            
            if response.status_code == 200:
                data = response.json()
                
                # Distribute results back to original requests
                for req in batch:
                    token = req['params']['token']
                    price = data.get('data', {}).get(token, {}).get('price')
                    req['callback'](price)
            else:
                # Handle error for all requests in batch
                for req in batch:
                    req['callback'](None)
                    
        except Exception as e:
            error(f"Error processing Jupiter price batch: {str(e)}")
            for req in batch:
                req['callback'](None)
    
    def _process_birdeye_price_batch(self, batch: List[Dict]):
        """Process a batch of BirdEye price requests - DISABLED
        
        DISABLED in Phase 1 refactor - This sequential processing was consuming
        excessive Birdeye API credits. Use OptimizedPriceService instead.
        """
        warning("SharedAPIManager BirdEye price batch processing is disabled. Use OptimizedPriceService instead.")
        
        # DISABLED: Sequential BirdEye processing that was draining API credits
        # try:
        #     # BirdEye doesn't support batch requests, so process sequentially with rate limiting
        #     for req in batch:
        #         if self._check_rate_limit(APIEndpoint.BIRDEYE_PRICE):
        #             token = req['params']['token']
        #             url = f"{self.endpoints[APIEndpoint.BIRDEYE_PRICE]}?address={token}"
        #             headers = {'X-API-KEY': self.api_keys['birdeye']} if self.api_keys['birdeye'] else {}
        #             
        #             response = requests.get(url, headers=headers, timeout=self.API_CONFIGS[APIEndpoint.BIRDEYE_PRICE].timeout)
        #             
        #             if response.status_code == 200:
        #                 data = response.json()
        #                 price = data.get('data', {}).get('value')
        #                 req['callback'](price)
        #             else:
        #                 req['callback'](None)
        #         else:
        #             req['callback'](None)
        #             
        # except Exception as e:
        #     error(f"Error processing BirdEye price batch: {str(e)}")
        
        # Return None for all requests since this is disabled
        for req in batch:
            req['callback'](None)
    
    def _check_rate_limit(self, endpoint: APIEndpoint) -> bool:
        """DEADLOCK-SAFE: Check if we can make a request to the endpoint without exceeding rate limits"""
        # DEADLOCK FIX: Use timeout on lock acquisition
        try:
            if not self.rate_limit_locks[endpoint].acquire(timeout=2.0):
                debug(f"Rate limit check timeout for {endpoint.value}", file_only=True)
                return False
        except:
            debug(f"Rate limit lock error for {endpoint.value}", file_only=True)
            return False
        
        try:
            now = time.time()
            config = self.API_CONFIGS[endpoint]
            
            # Check if we're in backoff period
            if self.backoff_until[endpoint] and now < self.backoff_until[endpoint]:
                debug(f"Rate limit backoff active for {endpoint.value}", file_only=True)
                return False
            
            # Clean old entries from call history - MEMORY LEAK FIX
            old_count = len(self.call_history[endpoint])
            self.call_history[endpoint] = [
                call_time for call_time in self.call_history[endpoint]
                if now - call_time < 60  # Keep last minute of calls
            ]
            
            # Log cleanup if significant
            cleaned_count = old_count - len(self.call_history[endpoint])
            if cleaned_count > 20:
                debug(f"Cleaned {cleaned_count} old API calls for {endpoint.value}", file_only=True)
            
            # Check per-minute limit
            if len(self.call_history[endpoint]) >= config.max_calls_per_minute:
                debug(f"Per-minute rate limit exceeded for {endpoint.value}", file_only=True)
                return False
            
            # Check per-second limit
            recent_calls = [
                call_time for call_time in self.call_history[endpoint]
                if now - call_time < 1  # Last second
            ]
            
            if len(recent_calls) >= config.max_calls_per_second:
                debug(f"Per-second rate limit exceeded for {endpoint.value}", file_only=True)
                return False
            
            # Record this call
            self.call_history[endpoint].append(now)
            return True
            
        finally:
            # DEADLOCK FIX: Always release lock
            self.rate_limit_locks[endpoint].release()
    
    def _handle_rate_limit_error(self, endpoint: APIEndpoint):
        """Handle rate limit errors by implementing backoff"""
        self.error_counts[endpoint] += 1
        backoff_seconds = min(2 ** self.error_counts[endpoint], 60)  # Exponential backoff, max 60 seconds
        self.backoff_until[endpoint] = time.time() + backoff_seconds
        warning(f"Rate limit hit for {endpoint.value}, backing off for {backoff_seconds} seconds")
    
    def make_request(self, endpoint: APIEndpoint, method: str = 'GET', 
                    params: Optional[Dict] = None, data: Optional[Dict] = None,
                    headers: Optional[Dict] = None, callback: Optional[Callable] = None) -> Optional[Any]:
        """
        Make a rate-limited API request with proper error handling
        
        Args:
            endpoint: API endpoint to use
            method: HTTP method
            params: Query parameters
            data: Request body
            headers: Request headers
            callback: Optional callback for async requests
            
        Returns:
            Response data or None if failed
        """
        try:
            # Check rate limits
            if not self._check_rate_limit(endpoint):
                if callback:
                    callback(None)
                return None
            
            # Check if endpoint is in backoff
            if self.backoff_until[endpoint] and time.time() < self.backoff_until[endpoint]:
                remaining = self.backoff_until[endpoint] - time.time()
                debug(f"Endpoint {endpoint.value} in backoff for {remaining:.1f}s", file_only=True)
                if callback:
                    callback(None)
                return None
            
            # Get endpoint URL
            url = self.endpoints.get(endpoint)
            if not url:
                error(f"No URL configured for endpoint {endpoint.value}")
                if callback:
                    callback(None)
                return None
            
            # Prepare request
            request_headers = headers or {}
            if endpoint == APIEndpoint.HELIUS_RPC:
                # Add API key to headers for Helius RPC
                if self.api_keys.get('helius'):
                    request_headers['Authorization'] = f'Bearer {self.api_keys["helius"]}'
            elif endpoint == APIEndpoint.BIRDEYE_PRICE or endpoint == APIEndpoint.BIRDEYE_METADATA:
                # Add API key to headers for BirdEye
                if self.api_keys.get('birdeye'):
                    request_headers['X-API-KEY'] = self.api_keys['birdeye']
            
            # Make request with retry logic
            config = self.API_CONFIGS[endpoint]
            for attempt in range(config.retry_attempts):
                try:
                    if method.upper() == 'GET':
                        response = requests.get(
                            url, 
                            params=params, 
                            headers=request_headers, 
                            timeout=config.timeout
                        )
                    else:
                        response = requests.post(
                            url, 
                            params=params, 
                            json=data, 
                            headers=request_headers, 
                            timeout=config.timeout
                        )
                    
                    # Handle different response codes
                    if response.status_code == 200:
                        # Success - reset error count
                        self.error_counts[endpoint] = 0
                        self.backoff_until[endpoint] = None
                        
                        # Parse response
                        try:
                            result = response.json()
                        except:
                            result = response.text
                        
                        # Record successful call
                        self.call_history[endpoint].append(time.time())
                        
                        if callback:
                            callback(result)
                        return result
                    
                    elif response.status_code == 401:
                        # Authentication failed - this is expected for free RPC endpoints
                        if endpoint == APIEndpoint.HELIUS_RPC:
                            warning("Authentication failed for RPC endpoint. This is normal if using a free RPC endpoint.")
                            # Don't count this as an error for RPC endpoints
                            if callback:
                                callback(None)
                            return None
                        else:
                            error(f"Authentication failed for {endpoint.value}: {response.text}")
                            self._handle_rate_limit_error(endpoint)
                    
                    elif response.status_code == 429:
                        # Rate limited
                        error(f"Rate limited for {endpoint.value}: {response.text}")
                        self._handle_rate_limit_error(endpoint)
                    
                    elif response.status_code >= 500:
                        # Server error - retry
                        error(f"Server error for {endpoint.value} (attempt {attempt + 1}): {response.status_code}")
                        if attempt < config.retry_attempts - 1:
                            time.sleep(config.retry_delay * (attempt + 1))
                        continue
                    
                    else:
                        # Other client errors
                        error(f"Request failed for {endpoint.value}: {response.status_code} - {response.text}")
                        if callback:
                            callback(None)
                        return None
                        
                except requests.exceptions.Timeout:
                    error(f"Timeout for {endpoint.value} (attempt {attempt + 1})")
                    if attempt < config.retry_attempts - 1:
                        time.sleep(config.retry_delay * (attempt + 1))
                    continue
                    
                except requests.exceptions.RequestException as e:
                    error(f"Request exception for {endpoint.value} (attempt {attempt + 1}): {str(e)}")
                    if attempt < config.retry_attempts - 1:
                        time.sleep(config.retry_delay * (attempt + 1))
                    continue
            
            # All retries failed
            self._handle_rate_limit_error(endpoint)
            if callback:
                callback(None)
            return None
            
        except Exception as e:
            error(f"Unexpected error in make_request for {endpoint.value}: {str(e)}")
            if callback:
                callback(None)
            return None
    
    def get_price(self, token_address: str, callback: Optional[Callable] = None) -> Optional[float]:
        """
        Get price for a token using the most appropriate endpoint
        
        Args:
            token_address: Token address to get price for
            callback: Optional callback for async requests
            
        Returns:
            Price as float or None if failed
        """
        # Check configuration for price source preference
        try:
            from src.config import PRICE_SOURCE_MODE
            use_birdeye_first = PRICE_SOURCE_MODE.lower() == "birdeye"
        except ImportError:
            try:
                from config import PRICE_SOURCE_MODE
                use_birdeye_first = PRICE_SOURCE_MODE.lower() == "birdeye"
            except ImportError:
                use_birdeye_first = False
            
        if use_birdeye_first:
            # Try BirdEye first when configured
            if callback:
                def birdeye_callback(result):
                    if result and 'data' in result and 'value' in result['data']:
                        price = result['data']['value']
                        callback(price)
                    else:
                        # Fallback to Jupiter if BirdEye fails
                        def jupiter_fallback(jupiter_result):
                            if jupiter_result and 'data' in jupiter_result and token_address in jupiter_result['data']:
                                price = jupiter_result['data'][token_address].get('price')
                                callback(price)
                            else:
                                callback(None)
                        
                        self.make_request(
                            APIEndpoint.JUPITER_PRICE,
                            params={'ids': token_address},
                            callback=jupiter_fallback
                        )
                
                self.make_request(
                    APIEndpoint.BIRDEYE_PRICE,
                    params={'address': token_address},
                    callback=birdeye_callback
                )
                return None  # Async request
            else:
                # Synchronous request - try BirdEye first
                result = self.make_request(
                    APIEndpoint.BIRDEYE_PRICE,
                    params={'address': token_address}
                )
                
                if result and 'data' in result and 'value' in result['data']:
                    return result['data']['value']
                
                # Fallback to Jupiter
                debug(f"BirdEye price fetch failed for {token_address[:8]}..., trying Jupiter", file_only=True)
                result = self.make_request(
                    APIEndpoint.JUPITER_PRICE,
                    params={'ids': token_address}
                )
                
                if result and 'data' in result and token_address in result['data']:
                    return result['data'][token_address].get('price')
                
                debug(f"All price sources failed for {token_address[:8]}...", file_only=True)
                return None
        else:
            # Try Jupiter first (default behavior)
            if callback:
                def jupiter_callback(result):
                    if result and 'data' in result and token_address in result['data']:
                        price = result['data'][token_address].get('price')
                        callback(price)
                    else:
                        # Fallback to BirdEye if Jupiter fails
                        self.make_request(
                            APIEndpoint.BIRDEYE_PRICE,
                            params={'address': token_address},
                            callback=lambda result: callback(
                                result.get('data', {}).get('value') if result else None
                            )
                        )
                
                self.make_request(
                    APIEndpoint.JUPITER_PRICE,
                    params={'ids': token_address},
                    callback=jupiter_callback
                )
                return None  # Async request
            else:
                # Synchronous request
                result = self.make_request(
                    APIEndpoint.JUPITER_PRICE,
                    params={'ids': token_address}
                )
                
                if result and 'data' in result and token_address in result['data']:
                    return result['data'][token_address].get('price')
                
                # Fallback to BirdEye
                debug(f"Jupiter price fetch failed for {token_address[:8]}..., trying BirdEye", file_only=True)
                result = self.make_request(
                    APIEndpoint.BIRDEYE_PRICE,
                    params={'address': token_address}
                )
                
                if result and 'data' in result:
                    return result['data'].get('value')
                
                debug(f"All price sources failed for {token_address[:8]}...", file_only=True)
                return None
    
    def get_token_balance(self, wallet_address: str, token_address: str, callback: Optional[Callable] = None) -> Optional[float]:
        """
        Get token balance for a wallet using RPC with fallback
        
        Args:
            wallet_address: Wallet address
            token_address: Token address
            callback: Optional callback for async requests
            
        Returns:
            Balance as float or None if failed
        """
        params = [
            wallet_address,
            {"mint": token_address},
            {"encoding": "jsonParsed"}
        ]
        
        if callback:
            def balance_callback(result):
                if result and 'result' in result and result['result']['value']:
                    account_info = result['result']['value'][0]['account']['data']['parsed']['info']
                    # CRITICAL FIX: Use unified token balance parsing
                    from src.nice_funcs import parse_token_balance_with_decimals
                    balance, decimals = parse_token_balance_with_decimals(account_info)
                    callback(balance)
                else:
                    callback(0.0)
            
            # Use the new RPC fallback system
            result = self.make_rpc_request("getTokenAccountsByOwner", params, wallet_address)
            balance_callback(result)
            return None  # Async request
        else:
            result = self.make_rpc_request("getTokenAccountsByOwner", params, wallet_address)
            
            if result and 'result' in result and result['result']['value']:
                account_info = result['result']['value'][0]['account']['data']['parsed']['info']
                # CRITICAL FIX: Use unified token balance parsing
                from src.nice_funcs import parse_token_balance_with_decimals
                balance, decimals = parse_token_balance_with_decimals(account_info)
                return balance
            
            return 0.0
    
    def get_wallet_token_accounts(self, wallet_address: str, callback: Optional[Callable] = None) -> Optional[List[Dict]]:
        """
        Get all token accounts for a wallet with RPC fallback
        
        Args:
            wallet_address: Wallet address
            callback: Optional callback for async requests
            
        Returns:
            List of token account info or None if failed
        """
        params = [
            wallet_address,
            {"programId": "TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA"},
            {"encoding": "jsonParsed"}
        ]
        
        if callback:
            def accounts_callback(result):
                if result and 'result' in result and result['result']['value']:
                    accounts = []
                    for account in result['result']['value']:
                        account_info = account['account']['data']['parsed']['info']
                        if float(account_info['tokenAmount']['amount']) > 0:
                            accounts.append({
                                'mint': account_info['mint'],
                                'amount': float(account_info['tokenAmount']['uiAmountString']),
                                'decimals': account_info['tokenAmount']['decimals']
                            })
                    callback(accounts)
                else:
                    callback([])
            
            # Use the new RPC fallback system
            result = self.make_rpc_request("getTokenAccountsByOwner", params, wallet_address)
            accounts_callback(result)
            return None  # Async request
        else:
            result = self.make_rpc_request("getTokenAccountsByOwner", params, wallet_address)
            
            if result and 'result' in result and result['result']['value']:
                accounts = []
                for account in result['result']['value']:
                    account_info = account['account']['data']['parsed']['info']
                    if float(account_info['tokenAmount']['amount']) > 0:
                        accounts.append({
                            'mint': account_info['mint'],
                            'amount': float(account_info['tokenAmount']['uiAmountString']),
                            'decimals': account_info['tokenAmount']['decimals']
                        })
                return accounts
            
            # If RPC call fails, return empty list but don't error
            debug(f"RPC call failed for wallet {wallet_address[:8]}..., returning empty token accounts", file_only=True)
            return []
    
    def shutdown(self):
        """Shutdown the shared API manager"""
        info("Shutting down Shared API Manager...")
        
        # Signal batch processors to stop
        for endpoint in self.batch_processors:
            self.request_queues[endpoint].put(None)
        
        # Wait for batch processors to finish
        for thread in self.batch_processors.values():
            thread.join(timeout=2.0)
        
        # Shutdown thread pool
        self.executor.shutdown(wait=True)
        
        info("Shared API Manager shutdown complete")

    def test_birdeye_api(self) -> bool:
        """Test Birdeye API connectivity"""
        try:
            api_key = self.api_keys.get('birdeye')
            if not api_key:
                debug("Birdeye API key not configured")
                return False

            url = f"{self.endpoints[APIEndpoint.BIRDEYE_PRICE]}?address=So11111111111111111111111111111111111111112"
            headers = {"X-API-KEY": api_key}

            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get("success") and data.get("data", {}).get("value"):
                    debug("Birdeye API connectivity test passed")
                    return True

            debug(f"Birdeye API test failed: HTTP {response.status_code}")
            return False

        except Exception as e:
            debug(f"Birdeye API test error: {str(e)}")
            return False

    def get_rpc_endpoint(self) -> str:
        """
        Get the best available RPC endpoint with fallback logic
        
        Returns:
            The URL of the best available RPC endpoint
        """
        current_time = time.time()
        
        # Check if current endpoint is healthy
        current = self.rpc_circuit_breaker['current_endpoint']
        health = self.rpc_health[current]
        
        # If current endpoint is healthy and not in recovery timeout, use it
        if health['healthy']:
            if current_time - health['last_failure'] > self.rpc_circuit_breaker['recovery_timeout']:
                endpoint_url = self.rpc_endpoints[current]
                if endpoint_url:
                    debug(f"Using {current} RPC endpoint: {endpoint_url[:50]}...", file_only=True)
                    return endpoint_url
        
        # Try to find a healthy endpoint
        for endpoint_type in ['primary', 'fallback', 'legacy']:
            health = self.rpc_health[endpoint_type]
            endpoint_url = self.rpc_endpoints[endpoint_type]
            
            if endpoint_url and health['healthy']:
                if current_time - health['last_failure'] > self.rpc_circuit_breaker['recovery_timeout']:
                    self.rpc_circuit_breaker['current_endpoint'] = endpoint_type
                    debug(f"Switched to {endpoint_type} RPC endpoint: {endpoint_url[:50]}...", file_only=True)
                    return endpoint_url
        
        # If no healthy endpoints, use primary as last resort
        primary_url = self.rpc_endpoints['primary']
        if primary_url:
            warning(f"All RPC endpoints unhealthy, using primary as last resort: {primary_url[:50]}...")
            return primary_url
        
        # Ultimate fallback to legacy endpoint
        legacy_url = self.rpc_endpoints['legacy']
        if legacy_url:
            warning(f"Using legacy RPC endpoint as ultimate fallback: {legacy_url[:50]}...")
            return legacy_url
        
        # If all else fails, return a default
        error("No RPC endpoints available!")
        return "https://api.mainnet-beta.solana.com"
    
    def mark_rpc_failure(self, endpoint_type: str = None):
        """
        Mark an RPC endpoint as failed and potentially switch to fallback
        
        Args:
            endpoint_type: The type of endpoint that failed (primary/fallback/legacy)
        """
        if endpoint_type is None:
            endpoint_type = self.rpc_circuit_breaker['current_endpoint']
        
        current_time = time.time()
        health = self.rpc_health[endpoint_type]
        
        health['failure_count'] += 1
        health['last_failure'] = current_time
        
        if health['failure_count'] >= self.rpc_circuit_breaker['failure_threshold']:
            health['healthy'] = False
            warning(f"RPC endpoint {endpoint_type} marked as unhealthy after {health['failure_count']} failures")
            
            # Switch to next available endpoint
            if endpoint_type == 'primary':
                self.rpc_circuit_breaker['current_endpoint'] = 'fallback'
            elif endpoint_type == 'fallback':
                self.rpc_circuit_breaker['current_endpoint'] = 'legacy'
            else:
                self.rpc_circuit_breaker['current_endpoint'] = 'primary'  # Cycle back
    
    def mark_rpc_success(self, endpoint_type: str = None):
        """
        Mark an RPC endpoint as successful and reset failure count
        
        Args:
            endpoint_type: The type of endpoint that succeeded (primary/fallback/legacy)
        """
        if endpoint_type is None:
            endpoint_type = self.rpc_circuit_breaker['current_endpoint']
        
        health = self.rpc_health[endpoint_type]
        health['failure_count'] = 0
        health['healthy'] = True
        debug(f"RPC endpoint {endpoint_type} marked as healthy", file_only=True)
    
    def make_rpc_request(self, method: str, params: list, wallet_address: str = None, timeout: int = 8) -> Optional[dict]:
        """
        Enhanced RPC request with hybrid strategy and request deduplication:
        - Personal wallet: QuickNode first, then Helius
        - Tracked wallets: Helius first, then QuickNode
        - Prevents concurrent duplicate requests
        """
        # Create a unique request identifier
        request_id = f"{method}_{hash(str(params))}_{wallet_address or 'global'}"
        
        # Check if this request is already in progress
        with self.request_lock:
            if request_id in self.active_requests:
                # Wait for the existing request to complete
                existing_future = self.active_requests[request_id]
                try:
                    return existing_future.result(timeout=timeout)
                except TimeoutError:
                    warning(f"â° Duplicate request {request_id} timed out - removing from inflight and retrying")
                    # CRITICAL FIX: Remove timed-out request so future calls don't wait on it
                    del self.active_requests[request_id]
                except Exception as e:
                    warning(f"Error waiting for duplicate request {request_id}: {e}")
                    # Remove failed request and continue with new one
                    del self.active_requests[request_id]
            
            # Create new request using RPC-specific executor
            future = self.rpc_executor.submit(self._execute_rpc_request, method, params, wallet_address, timeout)
            self.active_requests[request_id] = future
        
        try:
            result = future.result(timeout=timeout)
            return result
        except TimeoutError:
            # CRITICAL FIX: Clean up timed-out request immediately
            with self.request_lock:
                if request_id in self.active_requests:
                    del self.active_requests[request_id]
            error(f"â° RPC request {method} timed out after {timeout}s")
            raise
        except Exception as e:
            # Clean up failed request
            with self.request_lock:
                if request_id in self.active_requests:
                    del self.active_requests[request_id]
            raise
        finally:
            # Clean up completed request
            with self.request_lock:
                if request_id in self.active_requests:
                    del self.active_requests[request_id]
    
    def _execute_rpc_request(self, method: str, params: list, wallet_address: str = None, timeout: int = 8) -> Optional[dict]:
        """
        Internal method to execute the actual RPC request
        """
        payload = {
            "jsonrpc": "2.0",
            "id": f"anarcho-capital-{int(time.time())}",
            "method": method,
            "params": params
        }
        
        # Determine endpoint priority based on wallet type
        personal_wallet = os.getenv('DEFAULT_WALLET_ADDRESS')
        
        if wallet_address == personal_wallet:
            # Personal wallet: QuickNode first, then Helius
            endpoints = [
                ('quicknode', self.rpc_endpoints['primary'], 'primary'),
                ('helius', self.rpc_endpoints['fallback'], 'fallback')
            ]
        else:
            # Tracked wallets: Helius first, then QuickNode
            endpoints = [
                ('helius', self.rpc_endpoints['fallback'], 'fallback'),
                ('quicknode', self.rpc_endpoints['primary'], 'primary')
            ]
        
        for endpoint_name, endpoint_url, health_key in endpoints:
            if not endpoint_url:
                continue
                
            try:
                debug(f"Hybrid RPC request to {endpoint_name} for wallet {wallet_address[:8] if wallet_address else 'unknown'}...", file_only=True)
                
                response = requests.post(
                    endpoint_url,
                    json=payload,
                    timeout=timeout,
                    headers={'Content-Type': 'application/json'}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Check for RPC error in response
                    if 'error' in data:
                        error_msg = data['error'].get('message', 'Unknown RPC error')
                        warning(f"RPC error from {endpoint_name}: {error_msg}")
                        self.mark_rpc_failure(health_key)
                        continue
                    
                    # Success - mark endpoint as healthy
                    self.mark_rpc_success(health_key)
                    debug(f"âœ… {endpoint_name} RPC request successful", file_only=True)
                    return data
                
                elif response.status_code == 401:
                    # Authentication failed - try next endpoint
                    debug(f"Auth failed for {endpoint_name}, trying next endpoint", file_only=True)
                    self.mark_rpc_failure(health_key)
                    continue
                    
                else:
                    warning(f"HTTP {response.status_code} from {endpoint_name} RPC")
                    self.mark_rpc_failure(health_key)
                    continue
                    
            except requests.exceptions.Timeout:
                warning(f"Timeout from {endpoint_name} RPC endpoint")
                self.mark_rpc_failure(health_key)
                continue
                
            except requests.exceptions.RequestException as e:
                warning(f"Request error from {endpoint_name} RPC: {str(e)}")
                self.mark_rpc_failure(health_key)
                continue
        
        # All endpoints failed
        error(f"All RPC endpoints failed for method: {method}")
        return None

    # =====================================================================
    # Trading helpers used by agents (minimal SOLâ†”USDC support)
    # =====================================================================
    def swap_tokens(self, input_mint: str, output_mint: str, amount_usd: float,
                    slippage_bps: int, priority_fee: int) -> bool:
        """
        Execute a swap using existing trading utilities.

        Supported paths (live mode):
        - USDC -> SOL: buy SOL with USDC using Jupiter via nice_funcs.market_buy
        - SOL -> USDC: sell SOL to USDC using Jupiter via nice_funcs.market_sell

        In paper trading mode, this returns True after logging.
        """
        try:
            # Lazy imports to avoid circulars
            try:
                from src import config
                from src import nice_funcs as n
                from src.scripts.shared_services.optimized_price_service import get_optimized_price_service
            except ImportError:
                import src.config as config
                from src import nice_funcs as n
                from src.scripts.shared_services.optimized_price_service import get_optimized_price_service

            # Paper trading short-circuit
            if getattr(config, 'PAPER_TRADING_ENABLED', False):
                info(f"PAPER TRADING: swap {input_mint[:8]}... -> {output_mint[:8]}... for ${amount_usd:.2f}")
                return True

            # Only support SOL<->USDC here to unblock allocation flows
            if input_mint == config.USDC_ADDRESS and output_mint == config.SOL_ADDRESS:
                # amount for market_buy is in USDC minor units (6 decimals)
                usdc_amount_minor = int(max(amount_usd, 0.0) * 1_000_000)
                if usdc_amount_minor <= 0:
                    warning("swap_tokens: non-positive USDC amount")
                    return False
                info(f"ðŸ’± Swapping ${amount_usd:.2f} USDC -> SOL via Jupiter")
                sig = n.market_buy(config.SOL_ADDRESS, usdc_amount_minor, slippage_bps, allow_excluded=True)
                if sig:
                    try:
                        try:
                            from src.scripts.trade_log import log_live_trade
                        except ImportError:
                            from src.scripts.trade_log import log_live_trade
                        price = self.price_service.get_price(config.SOL_ADDRESS) or 0
                        log_live_trade(signature=sig, side='BUY', size=usdc_amount_minor, price_usd=price, usd_value=amount_usd, agent='harvesting', token=config.SOL_ADDRESS)
                        
                        # Also log to cloud database
                        try:
                            from src.scripts.cloud_database import get_cloud_database_manager
                            dbm = get_cloud_database_manager()
                            if dbm:
                                dbm.add_live_trade(
                                    signature=sig,
                                    side='BUY',
                                    size=usdc_amount_minor,
                                    price_usd=price,
                                    usd_value=amount_usd,
                                    agent='harvesting',
                                    token_mint=config.SOL_ADDRESS,
                                    metadata={'source': 'harvesting'}
                                )
                        except Exception as e:
                            logger.warning(f'Failed to replicate harvesting trade to cloud: {e}')
                    except Exception:
                        pass
                return bool(sig)

            if input_mint == config.SOL_ADDRESS and output_mint == config.USDC_ADDRESS:
                # Convert USD to SOL lamports using price service
                price_service = get_optimized_price_service()
                sol_price = price_service.get_price(config.SOL_ADDRESS) or 0.0
                if sol_price <= 0:
                    error("swap_tokens: could not fetch SOL price")
                    return False
                sol_amount = amount_usd / sol_price
                lamports = int(max(sol_amount, 0.0) * 1_000_000_000)
                if lamports <= 0:
                    warning("swap_tokens: non-positive SOL amount")
                    return False
                info(f"ðŸ’± Swapping ${amount_usd:.2f} SOL -> USDC via Jupiter (~{sol_amount:.6f} SOL)")
                sig = n.market_sell(config.SOL_ADDRESS, lamports, slippage_bps, allow_excluded=True, agent="shared_api_manager")
                if sig:
                    try:
                        try:
                            from src.scripts.trade_log import log_live_trade
                        except ImportError:
                            from src.scripts.trade_log import log_live_trade
                        price = self.price_service.get_price(config.SOL_ADDRESS) or 0
                        log_live_trade(signature=sig, side='SELL', size=lamports, price_usd=price, usd_value=amount_usd, agent='harvesting', token=config.SOL_ADDRESS)
                        
                        # Also log to cloud database
                        try:
                            from src.scripts.cloud_database import get_cloud_database_manager
                            dbm = get_cloud_database_manager()
                            if dbm:
                                dbm.add_live_trade(
                                    signature=sig,
                                    side='SELL',
                                    size=lamports,
                                    price_usd=price,
                                    usd_value=amount_usd,
                                    agent='harvesting',
                                    token_mint=config.SOL_ADDRESS,
                                    metadata={'source': 'harvesting'}
                                )
                        except Exception as e:
                            logger.warning(f'Failed to replicate harvesting trade to cloud: {e}')
                    except Exception:
                        pass
                return bool(sig)

            warning(f"swap_tokens: unsupported route {input_mint[:8]}...->{output_mint[:8]}...")
            return False
        except Exception as e:
            error(f"swap_tokens error: {str(e)}")
            return False

    def transfer_sol(self, amount: float, destination_address: str, priority_fee: int) -> bool:
        """
        Transfer SOL to another address using solana-py (solders types under the hood).

        amount: SOL amount (not lamports)
        destination_address: base58 public key
        priority_fee: lamports (used as compute unit price via recent fee rules â€” here we
                      set as a simple TxOpts override when available)
        """
        try:
            try:
                from src import config
                from src import nice_funcs as n
            except ImportError:
                import src.config as config
                from src import nice_funcs as n
            from solana.rpc.api import Client
            from solana.rpc.types import TxOpts
            from solana.transaction import Transaction
            from solana.system_program import TransferParams, transfer
            from solders.pubkey import Pubkey

            # Paper trading short-circuit
            if getattr(config, 'PAPER_TRADING_ENABLED', False):
                info(f"PAPER TRADING: transfer {amount:.6f} SOL to {destination_address[:8]}...")
                return True

            # Basic validation
            if amount <= 0:
                warning("transfer_sol: non-positive amount")
                return False
            if not destination_address or len(destination_address) < 32:
                error("transfer_sol: invalid destination address")
                return False

            key = n.get_key()
            client: Client = n.get_client()
            if not key or not client:
                error("transfer_sol: missing wallet key or RPC client")
                return False

            lamports = int(amount * 1_000_000_000)
            to_pub = Pubkey.from_string(destination_address)

            ix = transfer(TransferParams(from_pubkey=key.pubkey(), to_pubkey=to_pub, lamports=lamports))
            tx = Transaction().add(ix)

            # Note: priority_fee is best set with CU price; here we just use default opts
            opts = TxOpts(skip_preflight=False, max_retries=3)
            sig = client.send_transaction(tx, key, opts=opts)

            info(f"âœ… SOL transfer submitted: {sig.value}")
            return True
        except Exception as e:
            error(f"transfer_sol error: {str(e)}")
            return False

    def stake_sol(self, amount: float, protocol: str, priority_fee: int) -> bool:
        """
        Stake SOL via selected protocol using existing helpers in nice_funcs.

        amount: SOL amount
        protocol: one of 'marinade', 'jito', 'lido' (case-insensitive)
        """
        try:
            try:
                from src import config
                from src import nice_funcs as n
            except ImportError:
                import src.config as config
                from src import nice_funcs as n

            if getattr(config, 'PAPER_TRADING_ENABLED', False):
                info(f"PAPER TRADING: stake {amount:.6f} SOL via {protocol}")
                return True

            protocol_l = (protocol or '').lower()
            info(f"ðŸ¦ Staking {amount:.6f} SOL via {protocol_l}")

            if protocol_l == 'marinade':
                result = n.stake_sol_marinade(amount)
            elif protocol_l == 'jito':
                result = n.stake_sol_jito(amount)
            elif protocol_l == 'lido':
                result = n.stake_sol_lido(amount)
            else:
                warning(f"stake_sol: unsupported protocol '{protocol}'")
                return False

            if result:
                info("âœ… Staking transaction submitted")
                return True
            error("stake_sol: staking helper returned falsy result")
            return False
        except Exception as e:
            error(f"stake_sol error: {str(e)}")
            return False
    
    # NEW: Optimized Staking API Methods
    def get_staking_apy_data(self, callback: Optional[Callable] = None) -> Optional[Dict[str, float]]:
        """
        Get staking APY data from all protocols efficiently using concurrent requests
        
        Args:
            callback: Optional callback function
            
        Returns:
            Dictionary of protocol -> APY data
        """
        try:
            # Use concurrent requests for faster data gathering
            import concurrent.futures
            
            staking_data = {}
            
            def fetch_blazestake_apy():
                """Fetch BlazeStake APY"""
                try:
                    result = self.make_request(
                        APIEndpoint.BLAZESTAKE_APY,
                        method='GET',
                        headers={'Content-Type': 'application/json'}
                    )
                    if result:
                        apy = float(result.get("apy", 0))
                        return {"blazestake": apy}
                except Exception as e:
                    debug(f"BlazeStake APY fetch error: {str(e)}")
                return {}
            
            def fetch_jupsol_data():
                """Fetch JupSOL data from Jupiter"""
                try:
                    result = self.make_request(
                        APIEndpoint.JUPITER_LST_TOKENS,
                        method='GET',
                        headers={'Content-Type': 'application/json'}
                    )
                    if result:
                        # Find JupSOL in the response
                        tokens_list = result if isinstance(result, list) else result.get("tokens", [])
                        for token in tokens_list:
                            if token.get("symbol", "").lower() == "jupsol":
                                return {"jupsol": 9.5}  # JupSOL APY
                except Exception as e:
                    debug(f"JupSOL data fetch error: {str(e)}")
                return {}
            
            def fetch_sanctum_data():
                """Fetch Sanctum LST data"""
                try:
                    # Sanctum LSTs have different APYs based on underlying validators
                    sanctum_lsts = {
                        "stepSOL": 8.2,
                        "laineSOL": 9.1,
                        "alphaSOL": 8.8,
                        "jupSOL": 9.5
                    }
                    best_apy = max(sanctum_lsts.values())
                    return {"sanctum": best_apy}
                except Exception as e:
                    debug(f"Sanctum data fetch error: {str(e)}")
                return {}
            
            def fetch_native_staking_data():
                """Fetch native staking data"""
                try:
                    return {
                        "everstake": 7.0,
                        "community_validators": 7.2
                    }
                except Exception as e:
                    debug(f"Native staking data fetch error: {str(e)}")
                return {}
            
            # Execute all requests concurrently for maximum speed
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                futures = [
                    executor.submit(fetch_blazestake_apy),
                    executor.submit(fetch_jupsol_data),
                    executor.submit(fetch_sanctum_data),
                    executor.submit(fetch_native_staking_data)
                ]
                
                # Collect results
                for future in concurrent.futures.as_completed(futures):
                    try:
                        result = future.result()
                        staking_data.update(result)
                    except Exception as e:
                        debug(f"Staking data fetch error: {str(e)}")
            
            if callback:
                callback(staking_data)
            
            return staking_data
            
        except Exception as e:
            error(f"Error getting staking APY data: {str(e)}")
            return {}
    
    def get_staking_balance(self, wallet_address: str, protocol: str, callback: Optional[Callable] = None) -> Optional[Dict[str, float]]:
        """
        Get staking balance for a specific protocol
        
        Args:
            wallet_address: Wallet address to check
            protocol: Staking protocol name
            callback: Optional callback function
            
        Returns:
            Dictionary with staked amount and rewards
        """
        try:
            if protocol == "blazestake":
                result = self.make_request(
                    APIEndpoint.BLAZESTAKE_BALANCE,
                    method='GET',
                    params={'address': wallet_address},
                    headers={'Content-Type': 'application/json'}
                )
                
                if result:
                    staked_amount = result.get("totalStaked", 0)
                    rewards = result.get("rewards", 0)
                    return {
                        "staked_amount": staked_amount,
                        "rewards": rewards,
                        "protocol": protocol
                    }
            
            # For other protocols, return placeholder data
            return {
                "staked_amount": 0,
                "rewards": 0,
                "protocol": protocol
            }
            
        except Exception as e:
            error(f"Error getting staking balance for {protocol}: {str(e)}")
            return None

# Global instance
_shared_api_manager = None

def get_shared_api_manager() -> SharedAPIManager:
    """Get the global shared API manager instance"""
    global _shared_api_manager
    if _shared_api_manager is None:
        _shared_api_manager = SharedAPIManager()
    return _shared_api_manager 